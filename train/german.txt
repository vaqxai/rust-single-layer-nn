Ein Computer (englisch; deutsche Aussprache [kɔmˈpjuːtɐ]) oder Rechner ist ein Gerät, das mittels programmierbarer Rechenvorschriften Daten verarbeitet. Dementsprechend werden vereinzelt auch die abstrahierenden beziehungsweise veralteten, synonym gebrauchten Begriffe Rechenanlage, Datenverarbeitungsanlage oder elektronische Datenverarbeitungsanlage sowie Elektronengehirn verwendet.

Charles Babbage und Ada Lovelace gelten durch die von Babbage 1837 entworfene Rechenmaschine Analytical Engine als Vordenker des modernen universell programmierbaren Computers. Konrad Zuse (Z3, 1941 und Z4, 1945) in Berlin, John Presper Eckert und John William Mauchly (ENIAC, 1946) bauten die ersten funktionstüchtigen Geräte dieser Art. Bei der Klassifizierung eines Geräts als universell programmierbarer Computer spielt die Turing-Vollständigkeit eine wesentliche Rolle. Sie ist benannt nach dem englischen Mathematiker Alan Turing, der 1936 das logische Modell der Turingmaschine eingeführt hatte.[1][2]

Die frühen Computer wurden auch (Groß-)Rechner genannt; ihre Ein- und Ausgabe der Daten war zunächst auf Zahlen beschränkt. Zwar verstehen sich moderne Computer auf den Umgang mit weiteren Daten, beispielsweise mit Buchstaben und Tönen. Diese Daten werden jedoch innerhalb des Computers in Zahlen umgewandelt und als solche verarbeitet, weshalb ein Computer auch heute eine Rechenmaschine ist.

Mit zunehmender Leistungsfähigkeit eröffneten sich neue Einsatzbereiche. Computer sind heute in allen Bereichen des täglichen Lebens vorzufinden, meistens in spezialisierten Varianten, die auf einen vorliegenden Anwendungszweck zugeschnitten sind. So dienen integrierte Kleinstcomputer (eingebettetes System) zur Steuerung von Alltagsgeräten wie Waschmaschinen und Videorekordern oder zur Münzprüfung in Warenautomaten; in modernen Automobilen dienen sie beispielsweise zur Anzeige von Fahrdaten und steuern in „Fahrassistenten“ diverse Manöver selbst.

Universelle Computer finden sich in Smartphones und Spielkonsolen. Personal Computer (engl. für Persönliche Computer, als Gegensatz zu von vielen genutzten Großrechnern) dienen der Informationsverarbeitung in Wirtschaft und Behörden sowie bei Privatpersonen; Supercomputer werden eingesetzt, um komplexe Vorgänge zu simulieren, z. B. in der Klimaforschung oder für medizinische Berechnungen.


Inhaltsverzeichnis
1	Begriffsgeschichte
1.1	Rechner
1.2	Computer
2	Grundlagen
2.1	Hardwarearchitektur
2.2	Softwarearchitektur
2.3	Computersystem
3	Geschichte
4	Arten
4.1	Basierend auf Arbeitsweise des Computers
4.2	Basierend auf der Größe
5	Zukunftsperspektiven
6	Zeitleiste
7	Weltweite Marktanteile der Computerhersteller
8	Bekannte Computerhersteller
8.1	Aktuelle Hersteller
8.2	Bekannte ehemalige Computerhersteller
9	Literatur
10	Weblinks
11	Einzelnachweise
Begriffsgeschichte
Rechner
Der deutsche Begriff Rechner ist abgeleitet vom Verb rechnen. Zur Etymologie siehe Rechnen#Etymologie.

Computer
Das englische Substantiv computer ist abgeleitet von dem englischen Verb to compute. Jenes ist abgeleitet von dem lateinischen Verb computare, was zusammenrechnen bedeutet.

Der englische Begriff computer war ursprünglich eine Berufsbezeichnung für Hilfskräfte, die immer wiederkehrende Berechnungen (z. B. für die Astronomie, für die Geodäsie oder für die Ballistik) im Auftrag von Mathematikern ausführten und damit Tabellen wie z. B. eine Logarithmentafel füllten. Dieser Beruf wurde vorwiegend von Frauen ausgeübt.[3]

In der frühen Kirchengeschichte erfolgte eine Ablösung des jüdischen Kalenders durch den Julianischen Kalender. Die hieraus resultierenden Berechnungsschwierigkeiten des Osterdatums dauerten bis zum Mittelalter an und waren Gegenstand zahlreicher Publikationen, häufig betitelt mit Computus Ecclesiasticus. Doch finden sich noch weitere Titel, z. B. von Sigismund Suevus 1574, die sich mit arithmetischen Fragestellungen auseinandersetzen. Der früheste Text, in dem das Wort Computer isoliert verwendet wird, stammt von 1613.[4]

In der Zeitung The New York Times tauchte das Wort erstmals am 2. Mai 1892 in einer Kleinanzeige der United States Navy mit dem Titel A Computer Wanted ‚Ein Rechner gesucht‘ auf, in der Kenntnisse in Algebra, Geometrie, Trigonometrie und Astronomie vorausgesetzt worden sind.[5]

An der University of Pennsylvania in Philadelphia wurden im Auftrag der United States Army ballistische Tabellen berechnet. Das Ergebnis waren Bücher für die Artillerie, die für unterschiedliche Geschütze Flugbahnen unterschiedlicher Geschosse vorhersagten. Diese Berechnungen erfolgten größtenteils von Hand. Die einzige Hilfe war eine Tabelliermaschine, die zu multiplizieren und zu dividieren vermochte. Die Angestellten, die dort rechneten, wurden „computer“ (im Sinne eines menschlichen Computers) genannt.[6][7] Erstmals wurde der Begriff 1946 bei der dort entwickelten elektronischen Rechenanlage Electronic Numerical Integrator and Computer (ENIAC) für ein technisches Gerät verwendet. Seit 1962 ist der Begriff in Deutschland belegt.[8]

Grundlagen
Grundsätzlich unterscheiden sich zwei Bauweisen: Ein Rechner ist ein Digitalrechner, wenn er mit digitalen Geräteeinheiten digitale Daten verarbeitet (also Zahlen und Textzeichen); er ist ein Analogrechner, wenn er mit analogen Geräteeinheiten analoge Daten verarbeitet (also kontinuierlich verlaufende elektrische Messgrößen wie Spannung oder Strom).

Heute werden fast ausschließlich Digitalrechner eingesetzt. Diese folgen gemeinsamen Grundprinzipien, mit denen ihre freie Programmierung ermöglicht wird. Bei einem Digitalrechner werden dabei zwei grundsätzliche Bestandteile unterschieden: Die Hardware, die aus den elektronischen, physisch anfassbaren Teilen des Computers gebildet wird, sowie die Software, die die Programmierung des Computers beschreibt.

Ein Digitalrechner besteht zunächst nur aus Hardware. Die Hardware stellt erstens einen Speicher bereit, in dem Daten portionsweise wie auf den nummerierten Seiten eines Buches gespeichert und jederzeit zur Verarbeitung oder Ausgabe abgerufen werden können. Zweitens verfügt das Rechenwerk der Hardware über grundlegende Bausteine für eine freie Programmierung, mit denen jede beliebige Verarbeitungslogik für Daten dargestellt werden kann: Diese Bausteine sind im Prinzip die Berechnung, der Vergleich und der bedingte Sprung. Ein Digitalrechner kann beispielsweise zwei Zahlen addieren, das Ergebnis mit einer dritten Zahl vergleichen und dann abhängig vom Ergebnis entweder an der einen oder der anderen Stelle des Programms fortfahren. In der Informatik wird dieses Modell theoretisch durch die eingangs erwähnte Turing-Maschine abgebildet; die Turing-Maschine stellt die grundsätzlichen Überlegungen zur Berechenbarkeit dar.

Erst durch eine Software wird der Digitalcomputer jedoch nützlich. Jede Software ist im Prinzip eine definierte, funktionale Anordnung der oben geschilderten Bausteine Berechnung, Vergleich und bedingter Sprung, wobei die Bausteine beliebig oft verwendet werden können. Diese Anordnung der Bausteine, die als Programm bezeichnet wird, wird in Form von Daten im Speicher des Computers abgelegt. Von dort kann sie von der Hardware ausgelesen und abgearbeitet werden. Dieses Funktionsprinzip der Digitalcomputer hat sich seit seinen Ursprüngen in der Mitte des 20. Jahrhunderts nicht wesentlich verändert, wenngleich die Details der Technologie erheblich verbessert wurden.

Analogrechner funktionieren nach einem anderen Prinzip. Bei ihnen ersetzen analoge Bauelemente (Verstärker, Kondensatoren) die Logikprogrammierung. Analogrechner wurden früher häufiger zur Simulation von Regelvorgängen eingesetzt (siehe: Regelungstechnik), sind heute aber fast vollständig von Digitalcomputern abgelöst worden. In einer Übergangszeit gab es auch Hybridrechner, die einen Analog- mit einem digitalen Computer kombinierten.

Mögliche Einsatzmöglichkeiten für Computer sind:

Mediengestaltung (Bild- und Textverarbeitung)
Verwaltungs- und Archivierungsanwendungen
Steuerung von Maschinen und Abläufen (Drucker, Produktion in der Industrie durch z. B. Roboter, eingebettete Systeme)
Berechnungen und Simulationen (z. B. BOINC)
Medienwiedergabe (Internet, Fernsehen, Videos, Unterhaltungsanwendungen wie Computerspiele, Lernsoftware)
Kommunikation (Chat, E-Mail, soziale Netzwerke)
Softwareentwicklung
Hardwarearchitektur
Das heute allgemein angewandte Prinzip, das nach seiner Beschreibung durch John von Neumann von 1946 als Von-Neumann-Architektur bezeichnet wird, definiert für einen Computer fünf Hauptkomponenten:

das Rechenwerk (im Wesentlichen die arithmetisch-logische Einheit (ALU)),
das Steuerwerk,
die Buseinheit,
das Speicherwerk sowie
die Eingabe-/Ausgabewerk(e).
In den heutigen Computern sind die ALU und die Steuereinheit meistens zu einem Baustein verschmolzen, der so genannten CPU (Central Processing Unit, zentraler Prozessor).

Der Speicher ist eine Anzahl von durchnummerierten, adressierbaren „Zellen“; jede von ihnen kann ein einzelnes Stück Information aufnehmen. Diese Information wird als Binärzahl, also eine Abfolge von ja/nein-Informationen im Sinne von Einsen und Nullen, in der Speicherzelle abgelegt.

Bezüglich des Speicherwerks ist eine wesentliche Designentscheidung der Von-Neumann-Architektur, dass sich Programm und Daten einen Speicherbereich teilen (dabei belegen die Daten in aller Regel den unteren und die Programme den oberen Speicherbereich). Demgegenüber stehen in der Harvard-Architektur Daten und Programmen eigene (physikalisch getrennte) Speicherbereiche zur Verfügung. Der Zugriff auf die Speicherbereiche kann parallel realisiert werden, was zu Geschwindigkeitsvorteilen führt. Aus diesem Grund werden digitale Signalprozessoren häufig in Harvard-Architektur ausgeführt. Weiterhin können Daten-Schreiboperationen in der Harvard-Architektur keine Programme überschreiben (Informationssicherheit).

In der Von-Neumann-Architektur ist das Steuerwerk für die Speicherverwaltung in Form von Lese- und Schreibzugriffen zuständig.

Die ALU hat die Aufgabe, Werte aus Speicherzellen zu kombinieren. Sie bekommt die Werte von der Steuereinheit geliefert, verrechnet sie (addiert beispielsweise zwei Zahlen) und gibt den Wert an die Steuereinheit zurück, die den Wert dann für einen Vergleich verwenden oder in eine andere Speicherzelle schreiben kann.

Die Ein-/Ausgabeeinheiten schließlich sind dafür zuständig, die initialen Programme in die Speicherzellen einzugeben und dem Benutzer die Ergebnisse der Berechnung anzuzeigen.

Softwarearchitektur
Die Von-Neumann-Architektur ist gewissermaßen die unterste Ebene des Funktionsprinzips eines Computers oberhalb der elektrophysikalischen Vorgänge in den Leiterbahnen. Die ersten Computer wurden auch tatsächlich so programmiert, dass man die Nummern von Befehlen und von bestimmten Speicherzellen so, wie es das Programm erforderte, nacheinander in die einzelnen Speicherzellen schrieb. Um diesen Aufwand zu reduzieren, wurden Programmiersprachen entwickelt. Diese generieren die Zahlen innerhalb der Speicherzellen, die der Computer letztlich als Programm abarbeitet, aus Textbefehlen heraus automatisch, die auch für den Programmierer einen semantisch verständlichen Inhalt darstellen (z. B. GOTO für den „unbedingten Sprung“).

Später wurden bestimmte sich wiederholende Prozeduren in so genannten Bibliotheken zusammengefasst, um nicht jedes Mal das Rad neu erfinden zu müssen, z. B.: das Interpretieren einer gedrückten Tastaturtaste als Buchstabe „A“ und damit als Zahl „65“ (im ASCII-Code). Die Bibliotheken wurden in übergeordneten Bibliotheken gebündelt, welche Unterfunktionen zu komplexen Operationen verknüpfen (Beispiel: die Anzeige eines Buchstabens „A“, bestehend aus 20 einzelnen schwarzen und 50 einzelnen weißen Punkten auf dem Bildschirm, nachdem der Benutzer die Taste „A“ gedrückt hat).

In einem modernen Computer arbeiten sehr viele dieser Programmebenen über- bzw. untereinander. Komplexere Aufgaben werden in Unteraufgaben zerlegt, die von anderen Programmierern bereits bearbeitet wurden, die wiederum auf die Vorarbeit weiterer Programmierer aufbauen, deren Bibliotheken sie verwenden. Auf der untersten Ebene findet sich aber immer der so genannte Maschinencode – jene Abfolge von Zahlen, mit der der Computer auch tatsächlich gesteuert wird.

Computersystem
Als Computersystem bezeichnet man:

ein Netzwerk oder einen Verbund aus mehreren Computern, die individuell gesteuert werden und auf gemeinsam genutzte Daten und Geräte zugreifen können;
die einen einzelnen voll funktionstüchtigen Rechner in ihrem Zusammenspiel bedingende Gesamtheit von externen und internen Komponenten, d. h. Hardware, Software wie auch angeschlossenen Peripheriegeräten;
ein System von Programmen zur Steuerung und Überwachung von Computern.[9]
Geschichte
→ Hauptartikel: Geschichte des Computers
Arten
Basierend auf Arbeitsweise des Computers
Analogrechner
Digitalrechner
Hybridrechner
Basierend auf der Größe
Smartphone
Personal Digital Assistant oder PDA, waren die Vorläufer der Smartphones.
Tabletcomputer
Eingebettetes System, z. B. im Auto, Fernseher, Waschmaschine usw.
Einplatinencomputer, z. B. Raspberry Pi, billigste, sehr kleine Computer. Werden meist als eingebettete System verwendet.
Personal computer oder PC, hier als Desktop-Computer oder auch Arbeitsplatzrechner verstanden.
Hostrechner oder auch Server, eingebunden in einem Rechnernetz, meist ohne eigenen Display, Tastatur usw.
Thin Client sind Rechner, die nur in Zusammenarbeit mit einem größeren Rechner, meist server, richtig funktionieren.
Heimcomputer (veraltet), der Vorläufer des PC.
Spielkonsole
Smart-TV
Netbook, ein kleines Notebook.
Laptop oder Notebook
Minicomputer (veraltet)
Superminicomputer (veraltet)
Mikrocomputer (veraltet)
Mainframe computer oder Großrechner.
Supercomputer, die schnellsten Rechner ihrer Zeit, brauchen den Platz einer Turnhalle, die Energie einer Kleinstadt und sind sehr teuer.
Zukunftsperspektiven

Auch in wenig entwickelten Ländern immer wichtiger: Computerkurs in Osttimor
Zukünftige Entwicklungen bestehen voraussichtlich aus der möglichen Nutzung biologischer Systeme (Biocomputer), weiteren Verknüpfungen zwischen biologischer und technischer Informationsverarbeitung, optischer Signalverarbeitung und neuen physikalischen Modellen (Quantencomputer).

Ein Megatrend ist derzeit (2017) die Entwicklung künstlicher Intelligenz. Hier simuliert man die Vorgänge im menschlichen Gehirn und erschafft so selbstlernende Computer, die nicht mehr wie bislang programmiert werden, sondern mit Daten trainiert werden ähnlich einem Gehirn. Den Zeitpunkt, an dem künstliche Intelligenz die menschliche Intelligenz übertrifft, nennt man technologische Singularität. Künstliche Intelligenz wird heute (2017) bereits in vielen Anwendungen, auch alltäglichen, eingesetzt (s. Anwendungen der künstlichen Intelligenz). Hans Moravec bezifferte die Rechenleistung des Gehirns auf 100 Teraflops, Raymond Kurzweil auf 10.000 Teraflops. Diese Rechenleistung haben Supercomputer bereits deutlich überschritten. Zum Vergleich liegt eine Grafikkarte für 800 Euro (5/2016) bei einer Leistung von 10 Teraflops.[10] Vier Jahre später (Dezember 2020) besitzen bereits Videospielkonsolen für ca. 500 € vergleichbare Leistung.

Für weitere Entwicklungen und Trends, von denen viele noch den Charakter von Schlagwörtern bzw. Hypes haben, siehe Autonomic Computing (= Rechnerautonomie), Grid Computing, Cloud Computing, Pervasive Computing, ubiquitäres Computing (= Rechnerallgegenwart) und Wearable Computing.

Die weltweite Websuche nach dem Begriff „Computer“ nimmt seit Beginn der Statistik 2004 stetig ab. In den zehn Jahren bis 2014 war diese Zugriffszahl auf ein Drittel gefallen.[11]

Die Digitaltechnik ist ein Teilgebiet der technischen Informatik und befasst sich mit digitalen Schaltungen. In diesen erfolgt die Signalverarbeitung mit digitalen Signalen, d. h. mit Signalen, die diskretisiert (zeitdiskret) wie auch quantisiert (wertediskret) sind. Sie stellt das Gegenstück zur Analogtechnik dar. Durch technologische Innovationen seit 1900 konnte sie zunehmend Funktionen aus der Analogtechnik ersetzen und vor allem neue ermöglichen. Die Digitaltechnik hat unsere Welt derart verändert, dass der Begriff „Postdigital“ entstand.


Inhaltsverzeichnis
1	Allgemeines
2	Wertigkeiten
3	Informationsübertragung
4	Bauteile
5	Entwicklungswerkzeuge
6	Vorteile
7	Nachteile
8	Historisches
9	Rezeption in der Öffentlichkeit
Allgemeines
In der realen, physischen Welt verhält sich vieles stufenlos (analog). Seit dem letzten Jahrhundert hat die Wissenschaft Technologien entwickelt, mit denen sich manche Aufgaben leichter und besser lösen lassen. Das geschieht mit Hilfe der Digitaltechnik, indem alle ursprünglich analogen Werte quantisiert werden. Diese können leichter verarbeitet werden, weil damit kleine Nuancen eines Signals nicht immer beachtet werden müssen. Um die Ergebnisse dieses Vorgangs wieder in der realen Welt nutzen zu können, ist meist eine Umwandlung zurück in die analoge Form nötig (Mikrofon mit Analog-Digital-Umsetzer → Speicherung → Lautsprecher mit Digital-Analog-Umsetzer). Das einfachste Beispiel für analog und digital ist eine Rampe und eine Treppe. Natürlich kann man mit steigendem Aufwand die Stufen der Treppe immer kleiner machen, bis der Unterschied unkenntlich wird. Seit 1950 kann man diese Fortschritte am deutlichsten am Leistungsumfang von Mikroprozessoren nachvollziehen, siehe auch Mooresches Gesetz.

Wertigkeiten
einzelnes Bit
Ein Bit kann je nach Technologie verschieden viele Werte darstellen:
Elektronisch: Es gibt nur 2 Zustände des Signals: Ein/Aus, oder 1/0, High/Low, Wahr/Falsch
Biologisch: Bei DNA-Sequenzen sind mit den 4 Basenpaaren 16 Zustände möglich
Organisch: Peptide können mit 20 Zuständen rechnen
QuantenBit: 2 Zustände, wobei die Wahrscheinlichkeit jedes Messwertes durch den vor der Messung vorliegenden Zustand bestimmt wird.
Wortlängen
Durch Kaskadierung werden Bits zu Worten zusammengefasst. Ein einzelnes Wort kann je nach Technologie verschieden große Werte darstellen. Diese Werte werden je nach Anwendung auf verschiedene Arten interpretiert.
Elektronisch:
4 Bits: Dezimal 0–9 (Digit), Hexadezimal 0–15
8 Bits: Hexadezimal 0–255, Codierung von Textzeichen
16 Bits: Hexadezimal 0–65535, Codierung von Textzeichen in Unicode (internationale Zeichen)
32, 64, 80, 128 Bits: Hexadezimal oder Gleitkommazahlen-Formate
Biologisch: DNA-Sequenzen können fast unbegrenzte Längen erreichen
QuantenBits: Der technologische Aufwand begrenzt die Bit-Anzahl noch sehr
Gepackte Worte
In einem Wortfeld können mehrere Bitgruppen verschiedener Länge Informationen unterschiedlicher Bedeutung beinhalten. Ein Beispiel sind OP-Codes von Mikroprozessoren.
Informationsübertragung
Parallel
Über mehrere Leitungen (Datenbus) können mehrere Bits gleichzeitig übertragen werden.
Seriell
Über eine einzelne Leitung wird nacheinander ein Bit des Wortes nach dem anderen gesendet. In der Regel sind immer mehrere Worte zu senden. Für den zeitlichen Ablauf der Übertragung gibt es verschiedene Verfahren (Protokolle).
Mischformen
Durchaus können über mehrere Leitungen Teile eines Wortes parallel übertragen werden, bis das ganze Wort seriell ankommt. Die Übertragungsdauer dividiert sich dann um die Anzahl der Leitungen.
Bauteile
Hier eine Übersicht der wichtigsten Teile, die in der Digitaltechnik Verwendung finden.

Sensoren
AD- und DA-Wandler
Transistoren
Logikgatter, FlipFlops, Register und Treiber
Komprimierte Logik designed in FPGAS oder Gatearrays.
Mikroprozessoren und Speicher (ROM, RAM, Flash u.s.w)
Transputer
Massendatenträger (Festplatten, Solidstatememory, Wechseldatenträger wie USB-Sticks und CD-Roms)
Anzeigen und Displays
Interfaceanschlüsse für externe Geräte, Diagnose und Internet.
Entwicklungswerkzeuge
Während bis ca. 1970 Schaltpläne noch von Hand entworfen und gezeichnet wurden, haben heute neuere Werkzeuge Anwendung gefunden. Schaltpläne werden am Computer entworfen und ihre Funktionalität dann im Simulator getestet. Schaltpläne wurden ersetzt durch Hardwarebeschreibungssprachen wie VHDL, die dann den Schaltplan (Netzliste) und die Bauteilliste compilierten. Vorteil: Diese Daten können dann auch gleich genutzt werden, um das Layout der Leiterbahnen auf der Platine zu erzeugen (Floorplanning).

Vorteile
Vorteile der digitalen Signalverarbeitung gegenüber der analogen Technik sind die geringeren Kosten der Bauteile aufgrund hoher Integrationsdichte und vereinfachter Entwicklung und in der höheren Flexibilität. Mit Hilfe spezieller Signalprozessoren oder Computer können Schaltungen in Software und programmierbarer Hardware (PLDs) realisiert werden. Dadurch lassen sich Funktionen leichter an veränderte Anforderungen anpassen. Außerdem sind komplexe Algorithmen einfach anwendbar, die analog nur mit hohem Aufwand oder gar nicht realisierbar wären.

Durch stetige Verkleinerung der Bauelemente wurden die Geräte immer kleiner und kompakter. Die Technologie ist robuster gegenüber Temperatureinflüssen, Alterung, Schwankungen der Spannungsversorgung, und elektromechanischen Störungen. Durch sparsamen Strombedarf wird langer Batteriebetrieb möglich.

Mit der Einführung der Musik-CD (1980) entstand eine Diskussion, ob diese digital-gespeicherte Musik die hörbare Qualität erreicht, die die analoge Schallplatte bietet (Live-Musik sowieso). Die Musikindustrie fürchtete Verluste durch Raubkopien, was durch das folgende MP3 Format noch verstärkt wurde. Seit 2020 ist die Schallplatte wieder deutlich im Kommen. Trotzdem ist die CD und MP3 die meistgenutzte Möglichkeit.

Nachteile
Durch den schnellen Entwicklungsfortschritt sind die Produkte schnell überholt, und es gibt oft bessere. Das führt zu mehr Elektronikschrott, der die Umwelt belastet.

Historisches
Obwohl noch nicht als Digitaltechnik eingeordnet, erfüllte der Morsecode als erstes Signal 1837 die Anforderungen an eine serielle Datenübertragung. Ab 1938 wurden die ersten Rechner von Konrad Zuse mit Relais oder elektronischen Röhren gebaut. Alan Turing hat ebenfalls Bahnbrechendes entwickelt. Nach der Erfindung des Transistors 1925 ersetzte dieser langsam die Röhren und wurde zunächst für analoge Zwecke eingesetzt, dann aber immer öfter für digitale Aufgaben. Dies führte dann immer schneller zur Entwicklung integrierter Schaltkreise und dann zum Mikroprozessor.

Rezeption in der Öffentlichkeit
2020 ist das Wort „digital“ so gebräuchlich geworden, dass es stellvertretend für fast alle elektronischen Geräte und Vorgänge steht. Ja, es gibt schon digitale Währungen obwohl diese eher virtuell sind. Konten werden digital geführt, nicht mehr durch Bankangestellte. Vieles wird mit Smartphone und Internet geregelt. Das hat viele ältere Menschen abgehängt, die die Anwendung der neuen Technologien nicht so schnell erlernen konnten oder wollten.

Bei der Informatik handelt es sich um die Wissenschaft von der systematischen Darstellung, Speicherung, Verarbeitung und Übertragung von Informationen, wobei besonders die automatische Verarbeitung mit Digitalrechnern betrachtet wird.[1] Sie ist zugleich Grundlagen- und Formalwissenschaft als auch Ingenieurdisziplin.[2]


Inhaltsverzeichnis
1	Geschichte der Informatik
1.1	Ursprung
1.2	Etymologie
1.3	Entwicklung der Informatik zur Wissenschaft
1.4	Organisationen
1.5	Rechenmaschinen – Vorläufer des Computers
1.6	Entwicklung moderner Rechenmaschinen
1.7	Programmiersprachen
2	Disziplinen der Informatik
2.1	Theoretische Informatik
2.1.1	Automatentheorie und Formale Sprachen
2.1.2	Berechenbarkeitstheorie
2.1.3	Komplexitätstheorie
2.1.4	Theorie der Programmiersprachen
2.1.5	Theorie der formalen Methoden
2.2	Praktische Informatik
2.3	Technische Informatik
2.3.1	Mikroprozessortechnik, Rechnerentwurfsprozess
2.3.2	Architekturen
2.3.3	Modellierung und Bewertung
2.3.4	Beziehungen zu anderen Informatikgebieten und weiteren Fachdisziplinen
2.4	Informatik in interdisziplinären Wissenschaften
2.4.1	Computational sciences
2.4.2	Ingenieurinformatik, Maschinenbauinformatik
2.4.3	Wirtschaftsinformatik, Informationsmanagement
2.4.4	Sozioinformatik
2.4.5	Sozialinformatik
2.4.6	Medieninformatik
2.4.7	Computerlinguistik
2.4.8	Umweltinformatik, Geoinformatik
2.4.9	Andere Informatikdisziplinen
2.5	Künstliche Intelligenz
2.6	Informatik und Gesellschaft
3	Siehe auch
4	Literatur
5	Weblinks
6	Einzelnachweise
Geschichte der Informatik
Ursprung
Bereits Gottfried Wilhelm Leibniz hatte sich mit binären Zahlendarstellungen beschäftigt. Gemeinsam mit der Booleschen Algebra, die zuerst 1847 von George Boole ausgearbeitet wurde, bilden sie die wichtigsten mathematischen Grundlagen späterer Rechensysteme. 1937 veröffentlicht Alan Turing seine Arbeit On Computable Numbers with an application to the Entscheidungsproblem, in welcher die nach ihm benannte Turingmaschine vorgestellt wird, ein mathematisches Maschinenmodell, das bis heute für die Theoretische Informatik von größter Bedeutung ist. Dem Begriff der Berechenbarkeit liegen bis heute universelle Modelle, wie die Turingmaschine und die Komplexitätstheorie zu Grunde, die sich ab den 1960er Jahren zu entwickeln begann. Die Berechenbarkeit greift bis in die Gegenwart auf Varianten dieser Modelle zurück.

Etymologie
Das Wort Informatik entstand durch das Anhängen des Suffix -ik an den Wortstamm von Information. Karl Steinbuch prägte die Bezeichnung Informatik zusammen mit Helmut Gröttrup[3] und verwendete sie in seiner ersten Publikation „Informatik: Automatische Informationsverarbeitung“[4] im April 1957, die er bei Standard Elektrik AG (SEG) veröffentlichte.[5][6] Um die Bedeutung der Automation oder Mathematik für die Informatik zu betonen, wird Informatik manchmal auch als Kofferwort aus Information und Automatik oder Information und Mathematik ausgegeben.[7]

Nach einem internationalen Kolloquium in Dresden am 26. Februar 1968 setzte sich Informatik als Bezeichnung für die Wissenschaft nach französischem (informatique) und russischem Vorbild (Информатика) auch im deutschen Sprachraum durch.[8][9] Im Juli des gleichen Jahres wurde der Begriff Informatik erstmals als deutscher Name für ein neu einzurichtendes Studienfach in einer Berliner Rede des Ministers Gerhard Stoltenberg verwendet.[10] Während im englischen Sprachraum die Bezeichnung Computer Science üblich ist, konnte sich die deutsche Entsprechung Computerwissenschaften nicht durchsetzen. Jedoch wird der Ausdruck Informatics im Englischen für bestimmte Teile der Angewandten Informatik verwendet – etwa im Falle der Bioinformatics oder der Geoinformatics. Bei Übersetzungen ins Englische wird im deutschen Sprachraum teilweise die Bezeichnung Informatics gegenüber Computer Science bevorzugt.[11]

Entwicklung der Informatik zur Wissenschaft
In Deutschland gehen die Anfänge der Informatik als Wissenschaft bis ins Jahr 1952 zurück, als im Juli an der RWTH Aachen die erste deutsche Informatik-Tagung zum Thema programmgesteuerte Rechengeräte und Integrieranlagen mit Konrad Zuse und Heinz Nixdorf stattfand.[12] 1953 folgte ein Kolloquium zu Rechenanlagen in Göttingen, nachdem dort der erste deutsche Elektronenrechner, die G1, in Betrieb ging. Die TU München entwickelte unter Leitung von Hans Piloty und Robert Sauer ebenfalls einen Röhrenrechner, die PERM, die 1956 in Betrieb ging, und lud 1954 zu einem Rundtischgespräch ein.[13] Am Institut für praktische Mathematik (IPM) der Technischen Hochschule Darmstadt (TH Darmstadt), das der Mathematiker Alwin Walther seit 1928 aufbaute[14], konnten sich dann 1956 die ersten Studenten am Darmstädter Elektronischen Rechenautomaten mit den Problemen von Rechenautomaten befassen. Zeitgleich wurden an der TH Darmstadt die ersten Programmiervorlesungen- und praktika angeboten. Aufgrund des Renommees, das die TH Darmstadt zu dem Zeitpunkt in der Rechenautomatenforschung hatte, fand ein Kongress zum Fachgebiet Informatik (elektronische Rechenmaschinen und Informationsverarbeitung) mit internationaler Beteiligung im Oktober 1955 an der TH Darmstadt statt, der als Geburtsstätte der Programmiersprache ALGOL gilt.[15]

Deutschland mangelte es in den 1960er Jahren an Wettbewerbsfähigkeit im Gebiet der Datenverarbeitung (DV). Um dem entgegenzuwirken, verabschiedete der Bundesausschuss für wissenschaftliche Forschung am 26. April 1967 das Programm für die Förderung der Forschung und Entwicklung auf dem Gebiet der Datenverarbeitung für öffentliche Aufgaben. Für die Umsetzung war der sogenannte „Fachbeirat für Datenverarbeitung“ zuständig, der überwiegend aus Vertretern der Hochschulen und außeruniversitären Forschungseinrichtungen bestand. Auf der siebten Sitzung des Fachbeirates am 15. November 1967 signalisierte Karl Ganzhorn, der zu dem Zeitpunkt für Forschung und Entwicklung bei IBM Deutschland zuständig war, die Probleme der Industrie, Fachpersonal zu finden. Der Direktor des Instituts für Nachrichtenverarbeitung an der TH Darmstadt, Robert Piloty, wies darauf hin, dass die deutschen Hochschulen dafür zuständig seien, qualifiziertes Personal auszubilden. Daraufhin bildete sich der Ausschuss „DV-Lehrstühle und -Ausbildung“. Den Vorsitz übernahm Piloty. Der Ausschuss formulierte Empfehlungen für die Ausbildung von Informatikern, welche die Einrichtung eines Studiengangs der Informatik an mehreren Universitäten und Technischen Hochschulen vorsahen.[14]

1967 bot die TU München mit dem Studienzweig Informationsverarbeitung den ersten Informatikstudiengang in Deutschland im Rahmen des Mathematikstudiums auf Initiative Friedrich Ludwig Bauers an.[14][16][17] 1968 führte die TH Darmstadt einen Studienplan "Informatik" an der Fakultät für Elektrotechnik ein. 1969 folgte der Studiengang "Datentechnik (Technische Informatik)" des Fachbereiches Regulierungs- und Datentechnik und 1970 ein Mathematikstudiengang, der mit dem Grad "Diplomingenieur im Fach Mathematik mit Schwerpunkt Informatik" abschloss.[14] Am 1. September 1969 begann die Technische Universität Dresden als erste Hochschule der DDR mit der Ausbildung von Dipl.-Ing. für Informationsverarbeitung. Ebenfalls 1969 begann die Ingenieurschule Furtwangen (später Fachhochschule Furtwangen) mit der Ausbildung, hier noch Informatorik genannt.[18] Im Wintersemester 1969/70 bot die Universität Karlsruhe (heute Karlsruher Institut für Technologie) als erste bundesdeutsche Hochschule ein Informatikstudium an, der mit dem Grad "Diplom-Informatiker" abschloss.[19]

Die Johannes Kepler Universität (JKU) Linz startete im Wintersemester 1969/70 als erste österreichische Universität mit der Studienrichtung Informatik und der Ausbildung zum Diplomingenieur.[20] Im Wintersemester 1970/71 folgte die Technische Universität Wien.[21] Wenige Jahre darauf gründeten sich die ersten Fakultäten für Informatik, nachdem bereits seit 1962 an der Purdue University ein Department of Computer Science bestanden hatte.

In englischsprachigen Ländern wird die Einzelwissenschaft als computer science bezeichnet. Der erste universitäre Abschluss war das Diploma in Numerical Analysis and Automatic Computing an der University of Cambridge. Das einjährige postgraduale Studium konnte ab Oktober 1953 aufgenommen werden.[22][23]

Organisationen
Die Gesellschaft für Informatik (GI) wurde 1969 gegründet und ist die größte Fachvertretung im deutschsprachigen Raum. International bedeutend sind vor allem die beiden großen amerikanischen Vereinigungen Association for Computing Machinery (ACM) seit 1947 und das Institute of Electrical and Electronics Engineers (IEEE) seit 1963. Die bedeutendste deutschsprachige Organisation, die sich mit ethischen und gesellschaftlichen Effekten der Informatik auseinandersetzt ist, das Forum InformatikerInnen für Frieden und gesellschaftliche Verantwortung. Die Association for Computing Machinery vergibt jährlich den Turing Award, der vom Rang her in der Informatik in etwa vergleichbar mit dem Nobelpreis ist.

Rechenmaschinen – Vorläufer des Computers

Ein japanischer Soroban
Als erste Vorläufer der Informatik jenseits der Mathematik können die Bestrebungen angesehen werden, zwei Arten von Maschinen zu entwickeln: solche, mit deren Hilfe mathematische Berechnungen ausgeführt oder vereinfacht werden können („Rechenmaschinen“), und solche, mit denen logische Schlüsse gezogen und Argumente überprüft werden können („Logische Maschinen“). Als einfache Rechengeräte leisteten Abakus und später der Rechenschieber unschätzbare Dienste. 1641 konstruierte Blaise Pascal eine mechanische Rechenmaschine, die Additionen und Subtraktionen inklusive Überträgen durchführen konnte. Nur wenig später stellte Gottfried Wilhelm Leibniz eine Rechenmaschine vor, die alle vier Grundrechenarten beherrschte. Diese Maschinen basieren auf ineinandergreifenden Zahnrädern. Einen Schritt in Richtung größerer Flexibilität ging ab 1838 Charles Babbage, der eine Steuerung der Rechenoperationen mittels Lochkarten anstrebte. Erst Herman Hollerith war dank dem technischen Fortschritt ab 1886 in der Lage, diese Idee gewinnbringend umzusetzen. Seine auf Lochkarten basierenden Zählmaschinen wurden unter anderem bei der Auswertung einer Volkszählung in den USA eingesetzt.

Die Geschichte der logischen Maschinen wird oft bis ins 13. Jahrhundert zurückverfolgt und auf Ramon Llull zurückgeführt. Auch wenn seine rechenscheibenähnlichen Konstruktionen, bei denen mehrere gegeneinander drehbare Scheiben unterschiedliche Begriffskombinationen darstellen konnten, mechanisch noch nicht sehr komplex waren, war er wohl derjenige, der die Idee einer logischen Maschine bekannt gemacht hat. Von diesem sehr frühen Vorläufer abgesehen, verläuft die Geschichte logischer Maschinen eher sogar zeitversetzt zu jener der Rechenmaschinen: Auf 1777 datiert ein rechenschieberähnliches Gerät des dritten Earl Stanhope, dem zugeschrieben wird, die Gültigkeit von Syllogismen (im aristotelischen Sinn) zu prüfen. Eine richtige „Maschine“ ist erstmals in der Gestalt des „Logischen Pianos“ von Jevons für das späte 19. Jahrhundert überliefert. Nur wenig später wurde die Mechanik durch elektromechanische und elektrische Schaltungen abgelöst. Ihren Höhepunkt erlebten die logischen Maschinen in den 1940er und 1950er Jahren, zum Beispiel mit den Maschinen des englischen Herstellers Ferranti. Mit der Entwicklung universeller digitaler Computer nahm – im Gegensatz zu den Rechenmaschinen – die Geschichte selbständiger logischen Maschinen ein jähes Ende, indem die von ihnen bearbeiteten und gelösten Aufgaben zunehmend in Software auf genau jenen Computern realisiert wurden, zu deren hardwaremäßigen Vorläufern sie zu zählen sind.

Entwicklung moderner Rechenmaschinen
Siehe auch: Der Siegeszug des elektronischen Digitalrechners im Artikel Computer

Konrad Zuse
Eine der ersten größeren Rechenmaschinen ist die von Konrad Zuse erstellte, noch immer rein mechanisch arbeitende Z1 von 1937. Zu dieser Zeit waren in großen Verwaltungen Tabelliermaschinen die herrschende Technik, wobei Zuse der Einsatz im Ingenieursbereich vorschwebte. Vier Jahre später realisierte Zuse seine Idee mittels elektrischer Relais: Die Z3 von 1941 trennte als weltweit erster funktionsfähiger frei programmierbarer Digitalrechner[24] bereits Befehls- und Datenspeicher und Ein-/Ausgabepult.

Etwas später wurden in England die Bemühungen zum Bau von Rechenmaschinen zum Knacken von deutschen Geheimbotschaften unter maßgeblicher Leitung von Alan Turing (Turingbombe) und von Thomas Flowers (Colossus) mit großem Erfolg vorangetrieben. Parallel entwickelte Howard Aiken mit Mark I (1944) den ersten programmgesteuerten Relaisrechner der USA, wo die weitere Entwicklung maßgeblich vorangetrieben wurde. Weitere Relaisrechner entstanden in den Bell-Labors (George Stibitz). Als erster Röhrenrechner gilt der Atanasoff-Berry-Computer. Einer der Hauptakteure ist hier John von Neumann, nach dem die bis heute bedeutende Von-Neumann-Architektur benannt ist. 1946 erfolgte die Entwicklung des Röhrenrechners ENIAC, 1949 wurde der EDSAC gebaut – mit erstmaliger Implementation der Von-Neumann-Architektur.

Ab 1948 stieg IBM in die Entwicklung von Computern ein und wurde innerhalb von zehn Jahren Marktführer. Einen Meilenstein in der Firmengeschichte stellte 1964 die Einführung des System/360 dar. Der Großrechner ist der Urahn der heutigen Z-Systems-Mainframes und folgte zeitlich den IBM 700/7000 series. Bereits 1959 wurde mit der IBM 1401 ein Rechner auch für mittelgroße Unternehmen eingeführt, der oftmals wegen seinen Verkaufszahlen als der Ford Modell T der Computerindustrie bezeichnet wird. Mit der Entwicklung der Transistortechnik und der Mikroprozessortechnik wurden Computer immer leistungsfähiger und preisgünstiger. Im Jahre 1982 öffnete die Firma Commodore schließlich mit dem C64 den Massenmarkt speziell für Heimanwender, aber auch weit darüber hinaus.

Programmiersprachen
→ Hauptartikel: Programmiersprachen
Bedeutsam für die Entwicklung der Programmiersprachen war die Erfindung der "automatischen Programmierung" durch Heinz Rutishauser (1951). 1956 beschrieb Noam Chomsky eine Hierarchie formaler Grammatiken, mit denen formale Sprachen und jeweils spezielle Maschinenmodelle korrespondieren. Diese Formalisierungen erlangten für die Entwicklung der Programmiersprachen große Bedeutung. Wichtige Meilensteine waren die Entwicklung von Fortran (aus Englisch: "FORmula TRANslation", Formelübersetzung; erste höhere Programmiersprache, 1957), ALGOL (aus englisch: "ALGOrithmic Language", Algorithmensprache; strukturiert/imperativ; 1958/1960/1968), Lisp (aus englisch: "LISt Processing", Verarbeitung von Listen; funktional, 1959), COBOL (aus englisch: "COmmon Business Orientated Language", Programmiersprache für kaufmännische Anwendungen, 1959), Smalltalk (objektorientiert, 1971), Prolog (logisch, 1972) und SQL (Relationale Datenbanken, 1976). Einige dieser Sprachen stehen für typische Programmierparadigmen ihrer jeweiligen Zeit. Weitere über lange Zeit in der Praxis eingesetzte Programmiersprachen sind BASIC (seit 1960), C (seit 1970), Pascal (seit 1971), Objective-C (objektorientiert, 1984), C++ (objektorientiert, generisch, multi-paradigma, seit 1985), Java (objektorientiert, seit 1995) und C# (objektorientiert, um 2000). Sprachen und Paradigmenwechsel wurden von der Informatik-Forschung intensiv begleitet oder vorangetrieben.

Wie bei anderen Wissenschaften gibt es auch einen zunehmenden Trend zur Spezialisierung.

Disziplinen der Informatik

Alan-Turing-Gedenkstatue im Sackville Park in Manchester
Die Informatik unterteilt sich in die Teilgebiete der Theoretischen Informatik, der Praktischen Informatik und der Technischen Informatik.

Die Anwendungen der Informatik in den verschiedenen Bereichen des täglichen Lebens sowie in anderen Fachgebieten, wie beispielsweise der Wirtschaftsinformatik, Geoinformatik und Medizininformatik werden unter dem Begriff der Angewandten Informatik geführt. Auch die Auswirkungen auf die Gesellschaft werden interdisziplinär untersucht.

Architektur der Informatik
Die Theoretische Informatik bildet die theoretische Grundlage für die anderen Teilgebiete. Sie liefert fundamentale Erkenntnisse für die Entscheidbarkeit von Problemen, für die Einordnung ihrer Komplexität und für die Modellierung von Automaten und Formalen Sprachen.

Auf diese Erkenntnisse stützen sich Disziplinen der Praktischen und der Technischen Informatik. Sie beschäftigen sich mit zentralen Problemen der Informationsverarbeitung und suchen anwendbare Lösungen.

Die Resultate finden schließlich Verwendung in der Angewandten Informatik. Diesem Bereich sind Hardware- und Software-Realisierungen zuzurechnen und damit ein Großteil des kommerziellen IT-Marktes. In den interdisziplinären Fächern wird darüber hinaus untersucht, wie die Informationstechnik Probleme in anderen Wissenschaftsgebieten lösen kann, wie beispielsweise die Entwicklung von Geodatenbanken für die Geographie, aber auch die Wirtschafts- oder Bioinformatik.

Theoretische Informatik
→ Hauptartikel: Theoretische Informatik
Als Rückgrat der Informatik befasst sich das Gebiet der Theoretischen Informatik mit den abstrakten und mathematikorientierten Aspekten der Wissenschaft. Das Gebiet ist breit gefächert und beschäftigt sich unter anderem mit Themen aus der theoretischen Linguistik (Theorie formaler Sprachen bzw. Automatentheorie), Berechenbarkeits- und Komplexitätstheorie. Ziel dieser Teilgebiete ist es, fundamentale Fragen wie „Was kann berechnet werden?“ und „Wie effektiv/effizient kann man etwas berechnen?“ umfassend zu beantworten.


Automatentheorie



Berechenbarkeitstheorie



Komplexitätstheorie



Quantencomputer

Automatentheorie und Formale Sprachen
→ Hauptartikel: Automatentheorie und Formale Sprache

Ein DFA, gegeben als Zustandsübergangsdiagramm

Kellerautomat

1-Band-Turingmaschine
Automaten sind in der Informatik „gedachte Maschinen“, die sich nach bestimmten Regeln verhalten. Ein endlicher Automat hat eine endliche Menge von inneren Zuständen. Er liest ein „Eingabewort“ zeichenweise ein und führt bei jedem Zeichen einen Zustandsübergang durch. Zusätzlich kann er bei jedem Zustandsübergang ein „Ausgabesymbol“ ausgeben. Nach Ende der Eingabe kann der Automat das Eingabewort akzeptieren oder ablehnen.

Der Ansatz der formalen Sprachen hat seinen Ursprung in der Linguistik und eignet sich daher gut zur Beschreibung von Programmiersprachen. Formale Sprachen lassen sich aber auch durch Automatenmodelle beschreiben, da die Menge aller von einem Automaten akzeptierten Wörter als formale Sprache betrachtet werden kann.

Kompliziertere Modelle verfügen über einen Speicher, zum Beispiel Kellerautomaten oder die Turingmaschine, welche gemäß der Church-Turing-These alle durch Menschen berechenbaren Funktionen nachbilden kann.

Berechenbarkeitstheorie
→ Hauptartikel: Berechenbarkeitstheorie
Im Rahmen der Berechenbarkeitstheorie untersucht die theoretische Informatik, welche Probleme mit welchen Maschinen lösbar sind. Ein Rechnermodell oder eine Programmiersprache heißt Turing-vollständig, wenn damit eine universelle Turingmaschine simuliert werden kann. Alle heute eingesetzten Computer und die meisten Programmiersprachen sind Turing-vollständig, das heißt man kann damit dieselben Aufgaben lösen. Auch alternative Berechnungsmodelle wie der Lambda-Kalkül, WHILE-Programme, μ-rekursive Funktionen oder Registermaschinen stellten sich als Turing-vollständig heraus. Aus diesen Erkenntnissen entwickelte sich die Church-Turing-These, die zwar formal nicht beweisbar ist, jedoch allgemein akzeptiert wird.

Den Begriff der Entscheidbarkeit kann man veranschaulichen als die Frage, ob ein bestimmtes Problem algorithmisch lösbar ist. Ein entscheidbares Problem ist zum Beispiel die Eigenschaft eines Texts, ein syntaktisch korrektes Programm zu sein. Ein nicht-entscheidbares Problem ist zum Beispiel die Frage, ob ein gegebenes Programm mit gegebenen Eingabeparametern jemals zu einem Ergebnis kommt, was als Halteproblem bezeichnet wird.

Komplexitätstheorie
→ Hauptartikel: Komplexitätstheorie
Die Komplexitätstheorie befasst sich mit dem Ressourcenbedarf von algorithmisch behandelbaren Problemen auf verschiedenen mathematisch definierten formalen Rechnermodellen, sowie der Güte der sie lösenden Algorithmen. Insbesondere werden die Ressourcen „Laufzeit“ und „Speicherplatz“ untersucht und ihr Bedarf wird üblicherweise in der Landau-Notation dargestellt. In erster Linie werden die Laufzeit und der Speicherplatzbedarf in Abhängigkeit von der Länge der Eingabe notiert. Algorithmen, die sich höchstens durch einen konstanten Faktor in ihrer Laufzeit bzw. ihrem Speicherbedarf unterscheiden, werden durch die Landau-Notation derselben Klasse, d. h. einer Menge von Problemen mit äquivalenter vom Algorithmus für die Lösung benötigter Laufzeit, zugeordnet.

Ein Algorithmus, dessen Laufzeit von der Eingabelänge unabhängig ist, arbeitet „in konstanter Zeit“, man schreibt {\displaystyle {\mathcal {O}}(1)}{\mathcal {O}}(1). Beispielsweise wird das Programm „gib das erste Element einer Liste zurück“ in konstanter Zeit arbeiten. Das Programm „prüfe, ob ein bestimmtes Element in einer unsortierten Liste der Länge n enthalten ist“ braucht „lineare Zeit“, also {\displaystyle {\mathcal {O}}(n)}{\mathcal {O}}(n), denn die Eingabeliste muss schlimmstenfalls genau einmal gelesen werden.

Die Komplexitätstheorie liefert bisher fast nur obere Schranken für den Ressourcenbedarf von Problemen, denn Methoden für exakte untere Schranken sind kaum entwickelt und nur von wenigen Problemen bekannt (so zum Beispiel für die Aufgabe, eine Liste von Werten mit Hilfe einer gegebenen Ordnungsrelation durch Vergleiche zu sortieren, die untere Schranke {\displaystyle \Omega (n\log(n))}\Omega (n\log(n))). Dennoch gibt es Methoden, besonders schwierige Probleme als solche zu klassifizieren, wobei die Theorie der NP-Vollständigkeit eine zentrale Rolle spielt. Demnach ist ein Problem besonders schwierig, wenn man durch dessen Lösung auch automatisch die meisten anderen natürlichen Probleme lösen kann, ohne dafür wesentlich mehr Ressourcen zu verwenden.

Die größte offene Frage in der Komplexitätstheorie ist die Frage nach „P = NP?“. Das Problem ist eines der Millennium-Probleme, die vom Clay Mathematics Institute mit einer Million US-Dollar ausgeschrieben sind. Wenn P nicht gleich NP ist, können NP-vollständige Probleme nicht effizient gelöst werden.

Theorie der Programmiersprachen
Dieser Bereich beschäftigt sich mit der Theorie, Analyse, Charakterisierung und Implementierung von Programmiersprachen und wird sowohl in der praktischen als auch der theoretischen Informatik aktiv erforscht. Das Teilgebiet beeinflusst stark angrenzende Fachbereiche wie Teile der Mathematik und der Linguistik.


Typentheorie



Compilerbau



Programmiersprachen

Theorie der formalen Methoden
Die Theorie der formalen Methoden beschäftigt sich mit einer Vielzahl an Techniken zur formalen Spezifikation und Verifikation von Software- und Hardwaresystemen. Die Motivation für dieses Gebiet entstammt dem ingenieurwissenschaftlichen Denken – eine strenge mathematische Analyse hilft, die Zuverlässigkeit und Robustheit eines Systems zu verbessern. Diese Eigenschaften sind insbesondere bei Systemen, die in sicherheitskritischen Bereichen arbeiten, von großer Bedeutung. Die Erforschung solcher Methoden erfordert unter anderem Kenntnisse aus der mathematischen Logik und der formalen Semantik.

Praktische Informatik
→ Hauptartikel: Praktische Informatik
Die Praktische Informatik entwickelt grundlegende Konzepte und Methoden zur Lösung konkreter Probleme in der realen Welt, beispielsweise der Verwaltung von Daten in Datenstrukturen oder der Entwicklung von Software. Einen wichtigen Stellenwert hat dabei die Entwicklung von Algorithmen. Beispiele dafür sind Sortier- und Suchalgorithmen.

Eines der zentralen Themen der praktischen Informatik ist die Softwaretechnik (auch Softwareengineering genannt). Sie beschäftigt sich mit der systematischen Erstellung von Software. Es werden auch Konzepte und Lösungsvorschläge für große Softwareprojekte entwickelt, die einen wiederholbaren Prozess von der Idee bis zur fertigen Software erlauben sollen.

C-Quelltext		Maschinencode (schematisch)
 /**
  * Berechnung des ggT zweier Zahlen
  * nach dem Euklidischen Algorithmus
  */
int ggt(int zahl1, int zahl2) {
  int temp;
  while(zahl2 != 0) {
    temp  = zahl1%zahl2;
    zahl1 = zahl2;
    zahl2 = temp;
  }
  return zahl1;
}
→ Compiler →
 …
 0010 0100 1011 0111
 1000 1110 1100 1011
 0101 1001 0010 0001
 0111 0010 0011 1101
 0001 0000 1001 0100
 1000 1001 1011 1110
 0001 0011 0101 1001
 0111 0010 0011 1101
 0001 0011 1001 1100
 …

Skizze eines B-Baums
Ein wichtiges Thema der Praktischen Informatik ist der Compilerbau, der auch in der Theoretischen Informatik untersucht wird. Ein Compiler ist ein Programm, das andere Programme aus einer Quellsprache (beispielsweise Java oder C++) in eine Zielsprache übersetzt. Ein Compiler ermöglicht es einem Menschen, Software in einer abstrakteren Sprache zu entwickeln als in der von der CPU verwendeten Maschinensprache.

Ein Beispiel für den Einsatz von Datenstrukturen ist der B-Baum, der in Datenbanken und Dateisystemen das schnelle Suchen in großen Datenbeständen erlaubt.

Technische Informatik
→ Hauptartikel: Technische Informatik
Die Technische Informatik befasst sich mit den hardwareseitigen Grundlagen der Informatik, wie etwa Mikroprozessortechnik, Rechnerarchitektur, eingebetteten und Echtzeitsystemen, Rechnernetzen samt der zugehörigen systemnahen Software, sowie den hierfür entwickelten Modellierungs- und Bewertungsmethoden.


Wirkungsspektrum der Technischen Informatik
Mikroprozessortechnik, Rechnerentwurfsprozess
Die Mikroprozessortechnik wird durch die schnelle Entwicklung der Halbleitertechnik dominiert. Die Strukturbreiten im Nanometerbereich ermöglichen die Miniaturisierung von hochkomplexen Schaltkreisen mit mehreren Milliarden Einzelbauelementen. Diese Komplexität ist nur mit ausgereiften Entwurfswerkzeugen und leistungsfähigen Hardwarebeschreibungssprachen zu beherrschen. Der Weg von der Idee zum fertigen Produkt führt über viele Stufen, die weitgehend rechnergestützt sind und ein hohes Maß an Exaktheit und Fehlerfreiheit sichern. Werden wegen hoher Anforderungen an die Leistungsfähigkeit Hardware und Software gemeinsam entworfen, so spricht man auch von Hardware-Software-Codesign.

Architekturen
Die Rechnerarchitektur bzw. Systemarchitektur ist das Fachgebiet, das Konzepte für den Bau von Computern bzw. Systemen erforscht. Bei der Rechnerarchitektur wird z. B. das Zusammenspiel von Prozessoren, Arbeitsspeicher sowie Steuereinheiten (Controller) und Peripherie definiert und verbessert. Das Forschungsgebiet orientiert sich dabei sowohl an den Anforderungen der Software als auch an den Möglichkeiten, die sich über die Weiterentwicklung von Integrierten Schaltkreisen ergeben. Ein Ansatz ist dabei rekonfigurierbare Hardware wie z. B. FPGAs (Field Programmable Gate Arrays), deren Schaltungsstruktur an die jeweiligen Anforderungen angepasst werden kann.

Aufbauend auf der Architektur der sequentiell arbeitenden Von-Neumann-Maschine, bestehen heutige Rechner in der Regel aus einem Prozessor, der selbst wieder mehrere Prozessorkerne, Speicher-Controller und eine ganze Hierarchie von Cache-Speichern enthalten kann, einem als Direktzugriffsspeicher (Random-Access Memory, RAM) ausgelegten Arbeitsspeicher (Primärspeicher) und Ein/Ausgabe-Schnittstellen unter anderem zu Sekundärspeichern (z. B. Festplatte oder SSD-Speicher). Durch die vielen Einsatzgebiete ist heute ein weites Spektrum von Prozessoren im Einsatz, das von einfachen Mikrocontrollern, z. B. in Haushaltsgeräten über besonders energieeffiziente Prozessoren in mobilen Geräten wie Smartphones oder Tabletcomputern bis hin zu intern parallel arbeitenden Hochleistungsprozessoren in Personal Computern und Servern reicht. Parallelrechner gewinnen an Bedeutung, bei denen Rechenoperationen auf mehreren Prozessoren gleichzeitig ausgeführt werden können. Der Fortschritt der Chiptechnik ermöglicht heute schon die Realisierung einer großen Zahl (gegenwärtige Größenordnung 100…1000) von Prozessorkernen auf einem einzigen Chip (Mehrkernprozessoren, Multi/Manycore-Systeme, „System-on-a-Chip“ (SoCs)).

Ist der Rechner in ein technisches System eingebunden und verrichtet dort weitgehend unsichtbar für den Benutzer Aufgaben wie Steuerung, Regelung oder Überwachung, spricht man von einem eingebetteten System. Eingebettete Systeme sind in einer Vielzahl von Geräten des Alltags wie Haushaltsgeräten, Fahrzeugen, Geräten der Unterhaltungselektronik, Mobiltelefonen, aber auch in industriellen Systemen z. B. in der Prozessautomation oder der Medizintechnik im Einsatz. Da eingebettete Computer immerzu und überall verfügbar sind, spricht man auch von allgegenwärtigem oder ubiquitärem Rechnen (Ubiquitous computing). Immer häufiger sind diese Systeme vernetzt, z. B. mit dem Internet („Internet of Things“). Netzwerke von interagierenden Elementen mit physikalischer Eingabe von und Ausgabe zu ihrer Umwelt werden auch als Cyber-Physical Systems bezeichnet. Ein Beispiel sind drahtlose Sensornetze zur Umweltüberwachung.


Heimrouter
Echtzeitsysteme sind darauf ausgelegt, dass sie auf bestimmte zeitkritisch ablaufende Prozesse der Außenwelt mit angemessener Reaktionsgeschwindigkeit rechtzeitig antworten können. Dies setzt voraus, dass die Ausführungszeit der Antwortprozesse entsprechende vorgegebene Zeitschranken garantiert nicht überschreitet. Viele eingebettete Systeme sind auch Echtzeitsysteme.

Eine zentrale Rolle bei allen Mehrrechnersystemen spielt die Rechnerkommunikation. Diese ermöglicht den elektronischen Datenaustausch zwischen Computern und stellt damit die technische Grundlage des Internets dar. Neben der Entwicklung von Routern, Switches oder Firewalls, gehört hierzu auch die Entwicklung der Softwarekomponenten, die zum Betrieb dieser Geräte nötig ist. Dies schließt insbesondere die Definition und Standardisierung von Netzwerkprotokollen, wie TCP, HTTP oder SOAP, ein. Protokolle sind dabei die Sprachen, in denen Rechner untereinander Information austauschen.

Bei Verteilten Systemen arbeitet eine große Zahl von Prozessoren ohne gemeinsamen Speicher zusammen. Üblicherweise regeln Prozesse, die über Nachrichten miteinander kommunizieren, die Zusammenarbeit von einzelnen weitgehend unabhängigen Computern in einem Verbund (Cluster). Schlagworte in diesem Zusammenhang sind beispielsweise Middleware, Grid-Computing und Cloud Computing.

Modellierung und Bewertung
Als Basis für die Bewertung der genannten Architekturansätze sind – wegen der generellen Komplexität solcher Systemlösungen – spezielle Modellierungsmethoden entwickelt worden, um Bewertungen bereits vor der eigentlichen Systemrealisierung durchführen zu können. Besonders wichtig ist dabei zum einen die Modellierung und Bewertung der resultierenden Systemleistung, z. B. anhand von Benchmark-Programmen. Als Methoden zur Leistungsmodellierung sind z. B. Warteschlangenmodelle, Petri-Netze und spezielle verkehrstheoretische Modelle entwickelt worden. Vielfach wird insbesondere bei der Prozessorentwicklung auch Computersimulation eingesetzt.

Neben der Leistung können auch andere Systemeigenschaften auf der Basis der Modellierung studiert werden; z. B. spielt gegenwärtig auch der Energieverbrauch von Rechnerkomponenten eine immer größere, zu berücksichtigende Rolle. Angesichts des Wachstums der Hardware- und Softwarekomplexität sind außerdem Probleme der Zuverlässigkeit, Fehlerdiagnose und Fehlertoleranz, insbesondere bei sicherheitskritischen Anwendungen, von großer Bedeutung. Hier gibt es entsprechende, meist auf Verwendung redundanter Hardware- bzw. Softwareelemente basierende Lösungsmethoden.

Beziehungen zu anderen Informatikgebieten und weiteren Fachdisziplinen
Die Technische Informatik hat enge Beziehungen zu anderen Gebieten der Informatik und den Ingenieurwissenschaften. Sie baut auf der Elektronik und Schaltungstechnik auf, wobei digitale Schaltungen im Vordergrund stehen (Digitaltechnik). Für die höheren Softwareschichten stellt sie die Schnittstellen bereit, auf denen wiederum diese Schichten aufbauen. Insbesondere über eingebettete Systeme und Echtzeitsysteme gibt es enge Beziehungen zu angrenzenden Gebieten der Elektrotechnik und des Maschinenbaus wie Steuerungs-, Regelungs- und Automatisierungstechnik sowie zur Robotik.

Informatik in interdisziplinären Wissenschaften
Unter dem Sammelbegriff der Angewandten Informatik „fasst man das Anwenden von Methoden der Kerninformatik in anderen Wissenschaften … zusammen“.[1] Rund um die Informatik haben sich einige interdisziplinäre Teilgebiete und Forschungsansätze entwickelt, teilweise zu eigenen Wissenschaften. Beispiele:

Computational sciences
Dieses interdisziplinäre Feld beschäftigt sich mit der computergestützten Analyse, Modellierung und Simulation von naturwissenschaftlichen Problemen und Prozessen. Entsprechend den Naturwissenschaften wird hier unterschieden:

Die Bioinformatik (englisch bioinformatics, auch computational biology) befasst sich mit den informatischen Grundlagen und Anwendungen der Speicherung, Organisation und Analyse biologischer Daten. Die ersten reinen Bioinformatikanwendungen wurden für die DNA-Sequenzanalyse entwickelt. Dabei geht es primär um das schnelle Auffinden von Mustern in langen DNA-Sequenzen und die Lösung des Problems, wie man zwei oder mehr ähnliche Sequenzen so übereinander legt und gegeneinander ausrichtet, dass man eine möglichst optimale Übereinstimmung erzielt (sequence alignment). Mit der Aufklärung und weitreichenden Funktionsanalyse verschiedener vollständiger Genome (z. B. des Fadenwurms Caenorhabditis elegans) verlagert sich der Schwerpunkt bioinformatischer Arbeit auf Fragestellungen der Proteomik, wie z. B. dem Problem der Proteinfaltung und Strukturvorhersage, also der Frage nach der Sekundär- oder Tertiärstruktur bei gegebener Aminosäuresequenz.
Die Biodiversitätsinformatik umfasst die Speicherung und Verarbeitung von Informationen zur biologischen Vielfalt. Während die Bioinformatik sich mit Nucleinsäuren und Proteinen beschäftigt, sind die Objekte der Biodiversitätsinformatik Taxa, biologische Sammlungsbelege und Beobachtungsdaten.
Künstliches Leben (englisch Artificial life) wurde 1986 als interdisziplinäre Forschungsdisziplin etabliert.[25][26] Die Simulation natürlicher Lebensformen mit Software- (soft artificial life) und Hardwaremethoden (hard artificial life) ist ein Hauptziel dieser Disziplin.[27] Anwendungen für künstliches Leben gibt es heute unter anderem in der synthetischen Biologie, im Gesundheitssektor und der Medizin, in der Ökologie, bei autonomen Robotern, im Transport- und Verkehrssektor, in der Computergrafik, für virtuelle Gesellschaften und bei Computerspielen.[28]
Die Chemoinformatik (englisch chemoinformatics, cheminformatics oder chemiinformatics) bezeichnet einen Wissenschaftszweig, der das Gebiet der Chemie mit Methoden der Informatik verbindet und umgekehrt. Sie beschäftigt sich mit der Suche im chemischen Raum, welcher aus virtuellen (in silico) oder realen Molekülen besteht. Die Größe des chemischen Raumes wird auf etwa 1062 Moleküle geschätzt und ist weit größer als die Menge der bisher real synthetisierten Moleküle. Somit lassen sich unter Umständen Millionen von Molekülen mit Hilfe solcher Computer-Methoden in silico testen, ohne diese explizit mittels Methoden der Kombinatorischen Chemie oder Synthese im Labor erzeugen zu müssen.
Ingenieurinformatik, Maschinenbauinformatik
Die Ingenieurinformatik, englisch auch als Computational Engineering Science bezeichnet, ist eine interdisziplinäre Lehre an der Schnittstelle zwischen den Ingenieurwissenschaften, der Mathematik und der Informatik an den Fachbereichen Elektrotechnik, Maschinenbau, Verfahrenstechnik, Systemtechnik.
Die Maschinenbauinformatik beinhaltet im Kern die virtuelle Produktentwicklung (Produktionsinformatik) mittels Computervisualistik, sowie die Automatisierungstechnik.

Wirtschaftsinformatik, Informationsmanagement
→ Hauptartikel: Wirtschaftsinformatik
Die Wirtschaftsinformatik (englisch (business) information systems, auch management information systems) ist eine „Schnittstellen-Disziplin“ zwischen der Informatik und den Wirtschaftswissenschaften, besonders der Betriebswirtschaftslehre. Sie hat sich durch ihre Schnittstellen zu einer eigenständigen Wissenschaft entwickelt und kann sowohl an Wirtschafts- als auch an Informatik-Fakultäten studiert werden. Ein Schwerpunkt der Wirtschaftsinformatik liegt auf der Abbildung von Geschäftsprozessen und der Buchhaltung in relationalen Datenbanksystemen und Enterprise-Resource-Planning-Systemen. Das Information Engineering der Informationssysteme und das Informationsmanagement spielen im Rahmen der Wirtschaftsinformatik eine gewichtige Rolle. Entwickelt wurde dies an der Fachhochschule Furtwangen bereits 1971.[18] Ab 1974 richteten die damalige TH Darmstadt, die Johannes-Kepler-Universität Linz und die TU Wien einen Studiengang Wirtschaftsinformatik ein.

Sozioinformatik
Die Sozioinformatik befasst sich mit den Auswirkungen von IT-Systemen auf die Gesellschaft, wie sie z. B. Organisationen und Gesellschaft in ihrer Organisation unterstützen, aber auch wie die Gesellschaft auf die Entwicklung von sozial eingebetteten IT-Systemen einwirkt, sei es als Prosumenten auf kollaborativen Plattformen wie der Wikipedia, oder mittels rechtlicher Einschränkungen, um beispielsweise Datensicherheit zu garantieren.

Sozialinformatik
Die Sozialinformatik befasst sich zum einen mit dem IT-Betrieb in sozialen Organisationen, zum anderen mit Technik und Informatik als Instrument der Sozialen Arbeit, wie zum Beispiel beim Ambient Assisted Living.

Medieninformatik
Die Medieninformatik hat die Schnittstelle zwischen Mensch und Maschine als Schwerpunkt und befasst sich mit der Verbindung von Informatik, Psychologie, Arbeitswissenschaft, Medientechnik, Mediengestaltung und Didaktik.

Computerlinguistik
In der Computerlinguistik wird untersucht, wie natürliche Sprache mit dem Computer verarbeitet werden kann. Sie ist ein Teilbereich der Künstlichen Intelligenz, aber auch gleichzeitig Schnittstelle zwischen Angewandter Linguistik und Angewandter Informatik. Verwandt dazu ist auch der Begriff der Kognitionswissenschaft, die einen eigenen interdisziplinären Wissenschaftszweig darstellt, der u. a. Linguistik, Informatik, Philosophie, Psychologie und Neurologie verbindet. Anwendungsgebiete der Computerlinguistik sind die Spracherkennung und -synthese, automatische Übersetzung in andere Sprachen und Informationsextraktion aus Texten.

Umweltinformatik, Geoinformatik
Die Umweltinformatik beschäftigt sich interdisziplinär mit der Analyse und Bewertung von Umweltsachverhalten mit Mitteln der Informatik. Schwerpunkte sind die Verwendung von Simulationsprogrammen, Geographische Informationssysteme (GIS) und Datenbanksysteme.
Die Geoinformatik (englisch geoinformatics) ist die Lehre des Wesens und der Funktion der Geoinformation und ihrer Bereitstellung in Form von Geodaten und mit den darauf aufbauenden Anwendungen auseinander. Sie bildet die wissenschaftliche Grundlage für Geoinformationssysteme (GIS). Allen Anwendungen der Geoinformatik gemeinsam ist der Raumbezug und fallweise dessen Abbildung in kartesische räumliche oder planare Darstellungen im Bezugssystem.

Andere Informatikdisziplinen
Weitere Schnittstellen der Informatik zu anderen Disziplinen gibt es in der Informationswirtschaft, Medizinischen Informatik, Logistikinformatik, Pflegeinformatik und der Rechtsinformatik, Informationsmanagement (Verwaltungsinformatik, Betriebsinformatik), Architekturinformatik (Bauinformatik) sowie der Agrarinformatik, Archäoinformatik, Sportinformatik, sowie neue interdisziplinäre Richtungen wie beispielsweise das Neuromorphic Engineering. Die Zusammenarbeit mit der Mathematik oder der Elektrotechnik wird aufgrund der Verwandtschaft nicht als interdisziplinär bezeichnet. Mit dem Informatikunterricht, besonders an Schulen, befasst sich die Didaktik der Informatik. Die Elementarinformatik beschäftigt sich mit der Vermittlung von grundlegenden Informatikkonzepten im Vorschul- und Grundschulbereich.

Künstliche Intelligenz
→ Hauptartikel: Künstliche Intelligenz

Eine Kohonenkarte beim Lernen
Die Künstliche Intelligenz (KI) ist ein großes Teilgebiet der Informatik mit starken Einflüssen aus Logik, Linguistik, Neurophysiologie und Kognitionspsychologie. Dabei unterscheidet sich die KI in der Methodik zum Teil erheblich von der klassischen Informatik. Statt eine vollständige Lösungsbeschreibung vorzugeben, wird in der Künstlichen Intelligenz die Lösungsfindung dem Computer selbst überlassen. Ihre Verfahren finden Anwendung in Expertensystemen, in der Sensorik und Robotik.

Im Verständnis des Begriffs „Künstliche Intelligenz“ spiegelt sich oft die aus der Aufklärung stammende Vorstellung vom Menschen als Maschine wider, dessen Nachahmung sich die sogenannte „starke KI“ zum Ziel setzt: eine Intelligenz zu erschaffen, die wie der Mensch nachdenken und Probleme lösen kann und die sich durch eine Form von Bewusstsein beziehungsweise Selbstbewusstsein sowie Emotionen auszeichnet.

Die Umsetzung dieses Ansatzes erfolgte durch Expertensysteme, die im Wesentlichen die Erfassung, Verwaltung und Anwendung einer Vielzahl von Regeln zu einem bestimmten Gegenstand (daher „Experten“) leisten.

Im Gegensatz zur starken KI geht es der „schwachen KI“ darum, konkrete Anwendungsprobleme zu meistern. Insbesondere sind dabei solche Anwendungen von Interesse, zu deren Lösung nach allgemeinem Verständnis eine Form von „Intelligenz“ notwendig scheint. Letztlich geht es der schwachen KI somit um die Simulation intelligenten Verhaltens mit Mitteln der Mathematik und der Informatik; es geht ihr nicht um Schaffung von Bewusstsein oder um ein tieferes Verständnis der Intelligenz. Ein Beispiel aus der schwachen KI ist die Fuzzylogik.

Neuronale Netze gehören ebenfalls in diese Kategorie – seit Anfang der 1980er Jahre analysiert man unter diesem Begriff die Informationsarchitektur des (menschlichen oder tierischen) Gehirns. Die Modellierung in Form künstlicher neuronaler Netze illustriert, wie aus einer sehr einfachen Grundstruktur eine komplexe Mustererkennung geleistet werden kann. Gleichzeitig wird deutlich, dass diese Art von Lernen nicht auf der Herleitung von logisch oder sprachlich formulierbaren Regeln beruht – und somit etwa auch die besonderen Fähigkeiten des menschlichen Gehirns innerhalb des Tierreichs nicht auf einen regel- oder sprachbasierten „Intelligenz“-Begriff reduzierbar sind. Die Auswirkungen dieser Einsichten auf die KI-Forschung, aber auch auf Lerntheorie, Didaktik und andere Gebiete werden noch diskutiert.


Maschinelles Lernen



Bildverarbeitung



Mustererkennung



Kognitionswissenschaft



Data-Mining


Evolutionary computation



Information Retrieval



Wissensrepräsentation



Natural language processing



Robotik

Während die starke KI an ihrer philosophischen Fragestellung bis heute scheiterte, sind auf der Seite der schwachen KI Fortschritte erzielt worden.

Informatik und Gesellschaft
→ Hauptartikel: Informatik und Gesellschaft
„Informatik und Gesellschaft“ (IuG) ist ein Teilbereich der Wissenschaft Informatik und erforscht die Rolle der Informatik auf dem Weg zur Informationsgesellschaft. Die dabei untersuchten Wechselwirkungen der Informatik umfassen die unterschiedlichsten Aspekte. Ausgehend von historischen, sozialen, kulturellen Fragen betrifft dies ökonomische, politische, ökologische, ethische, didaktische und selbstverständlich technische Aspekte. Die entstehende global vernetzte Informationsgesellschaft wird für die Informatik als zentrale Herausforderung gesehen, in der sie als technische Grundlagenwissenschaft eine definierende Rolle spielt und diese reflektieren muss. IuG ist dadurch gekennzeichnet, dass eine interdisziplinäre Herangehensweise, insbesondere mit den Geisteswissenschaften, aber auch z. B. mit den Rechtswissenschaften notwendig ist.

Programmierung (von altgriechisch πρόγραμμα prógramma „öffentlich und schriftlich bekannt gemachte Nachricht, Befehl“)[1] bezeichnet die Tätigkeit, Computerprogramme zu erstellen. Dies ist ein Teilbereich der Softwareentwicklung.[2]

Computerprogramme werden mit Hilfe einer Programmiersprache formuliert („codiert“). Der Programmierer ‚übersetzt‘ dabei die vorgegebenen Anforderungen (z. B. im Pflichtenheft) und Algorithmen in eine gewünschte Programmiersprache. Teilweise werden dazu Codegeneratoren verwendet, die Teile des Programmcodes auf Basis von Modellen (die im Entwurf entstanden sind) automatisch erzeugen.

Beim Programmieren sind wesentliche Aspekte zur Softwarequalität zu berücksichtigen und durch die Gestaltung des Quellcodes umzusetzen. Siehe dazu als Beispiele: Programmierstil, Benutzerfreundlichkeit,[3] Wiederverwendbarkeit/Modularität, Wartbarkeit.

‚Programmieren‘ in erweitertem Sinn umfasst neben der Codeerstellung zahlreiche weitere Tätigkeiten, zum Beispiel das Testen (Entwicklertest) des Programms oder das Erstellen der Programmierdokumentation. Abgrenzen vom Begriff des Programmierens lassen sich andere Tätigkeiten zur Softwareentwicklung wie beispielsweise zum Projektmanagement, zur Anforderungsanalyse oder zur Datenmodellierung.

Abhängig vom Typ und der Einsatzumgebung von Software (z. B. für Systemsoftware, Spielesoftware, Standardsoftware, Grafiksoftware. usw.) können zur Entwicklung unterschiedliche Verfahren oder/und Werkzeuge (wie Programmiersprachen, Testverfahren etc.) zum Einsatz kommen und/oder von spezialisierten Entwicklern ausgeführt werden.

Je nach angewendetem Vorgehensmodell verlaufen die Aktivitäten zur Programmierung in zeitlich voneinander abgegrenzten Projektphasen, parallel oder iterativ. In der Praxis geschieht das Programmieren häufig in Teamarbeit, mit modernen Entwicklungsmethoden (wie Agile Softwareentwicklung) und Programmierwerkzeugen.

Ähnliche Bedeutungen: Umgangssprachlich bezeichnet man gelegentlich auch das Konfigurieren von Haushalts- oder anderer elektrischer Geräte als „Programmieren“. Auch Organisationseinheiten von Unternehmen, in denen Software entwickelt wird, werden oder wurden zum Teil „Programmierung“ genannt.


Inhaltsverzeichnis
1	Geschichte
2	Qualitätskriterien
2.1	Korrektheit
2.2	Robustheit
2.3	Wartbarkeit
2.4	Effizienz
3	Effiziente Programmierung
4	Arbeitsmittel
5	Siehe auch
6	Weblinks
7	Einzelnachweise
Geschichte
Siehe auch: Computerprogramm: Geschichte, Geschichte der Programmiersprachen und Programmiersprache – Geschichte
Charles Babbage beschrieb 1834 eine programmierbare Maschine, die Analytical Engine,[4] welche allerdings nie gebaut wurde. Seine, Notations of calculations for the Analytical Engine, umfasst 27 Programme. Diese sind in ‚the babbage papers‘ des Science Museums von London abrufbar. https://collection.sciencemuseumgroup.org.uk/documents/aa110000020 Die Programme enthalten bereits ‚Indirekte Adressierung‘ und ‚bedingte Ausführungen‘ (IF-THEN-ELSE-Befehle). Diese Dokumente dürften als erste Programme und Programmiersprache bezeichnet werden.

Ada Lovelace übersetzte 1843 eine ursprünglich französische Beschreibung der Analytical Engine von Luigi Federico Menabrea ins Englische und fügte eigene Notizen hinzu. Diese Anmerkungen enthielten einen tabellarischen Plan zur Berechnung der Bernoulli-Zahlen. 1941 realisierte Konrad Zuse mit dem Z3 die erste programmgesteuerte Rechenmaschine, von 1942 an entwickelte er mit Plankalkül die erste höhere Programmiersprache.[5] Die Mathematikerin Grace Hopper schuf 1949 den ersten Compiler, der Quellcode in Maschinencode übersetzt.[6]

Qualitätskriterien
→ Hauptartikel: Softwarequalität
Die Qualität von Software entsteht zu großen Teilen im Rahmen der Tätigkeiten des Programmierens, besonders die folgenden Qualitätskriterien betreffend:

Korrektheit
→ Hauptartikel: Programmfehler
Ein Programm muss die im Entwurf gemachten Vorgaben korrekt umsetzen. Dazu muss es in der Regel fehlerfrei sein, wobei beim Programmieren meist zwei verschiedene Arten von Fehlern auftreten:

Syntaxfehler: Fehlerhaft formulierter Quellcode – man verwendet Formulierungen oder Konstrukte, die so nicht in der verwendeten Programmiersprache vorkommen (Tippfehler, Unkenntnis, …). Syntaxfehler können beim Übersetzen vom Compiler/Interpreter oder Parser erkannt werden und verhindern i. d. R. die Programmausführung.
Semantische Fehler: Das Programm verhält sich nicht wie gewünscht, weil möglicherweise der Algorithmus oder seine Umsetzung fehlerhaft war. Semantische Fehler können in der Regel nicht automatisch erkannt, sondern nur durch gewissenhaftes Testen gefunden werden – beispielsweise in Form von Unittests.
Der Übergang zwischen diesen beiden Fehlerarten ist fließend. Beispielsweise wird ein Tippfehler im Code (z. B. „>“ anstatt „<“ in einem Vergleichsbefehl) zu einem gültigen ausführbaren Programm führen, das Resultat dürfte jedoch falsch sein. An anderer Stelle könnte derselbe Fehler ein Syntaxfehler sein.

Robustheit
Statistisch gesehen wird die meiste Zeit für die Entwicklung von Quelltext benötigt, um auf Fehler oder außergewöhnliche Anwendungs- oder Hardwareumgebungen zu reagieren. Ein Programmtext, der auch bei unvorhergesehenen Fehlern oder ungewöhnlichen Umgebungen sinnvoll reagiert, wird als robust bzw. portabel bezeichnet. Geübte Programmierer können die möglichen Fehler und Laufzeitumgebungen gut einschätzen und strukturieren das Programm und seinen Quelltext dementsprechend. Der Zeitdruck bei der Entwicklung von Anwendungen stellt selbst an erfahrene Programmierer immer höchste Ansprüche hinsichtlich dieses Kriteriums.

Wartbarkeit
Damit eine Software dauerhaft funktioniert, muss sie wartbar sein. Das heißt, Änderungen wie Bugfixes, Anpassungen und neue Features müssen ohne großen Aufwand eingepflegt werden können. Dies erfordert vor allem, dass der Programmierer keinen zu kurzen, „kryptischen“ Quelltext (oder Quellcode) erzeugen soll, der für andere Entwickler nicht oder nur mit hoher Einarbeitungszeit verständlich ist.

Um solche Probleme zu vermeiden, existieren häufig Namenskonventionen, in denen beispielsweise selbsterklärende (oder auch „sprechende“) Bezeichner/Namen für Variablen etc. zur Verwendung empfohlen/vorgeschrieben werden[7] – oder die Verwendung aussagefähiger Kommentare im Code. Auch eine sinnvolle Aufteilung des Codes in intuitiv verständliche Funktionen und Klassen trägt zum Verständnis und Übersichtlichkeit bei.

Siehe auch: Programmierstil
Effizienz
In der Regel stehen einem Programm nur begrenzte Ressourcen (Laufzeit, Speicherverbrauch, Bandbreite) zur Verfügung. Gute Programmierung kann dazu beitragen, unnötigen Ressourcenverbrauch zu reduzieren. Beispielsweise erfolgt dies, indem bei Verwendung großer Datenmengen an mehreren Stellen im Programm nicht jeweils der gesamte Datensatz kopiert wird, sondern nur die Adresse übertragen wird, an der die Daten gespeichert werden.

Effiziente Programmierung
Gemäß Niklaus Wirth zeichnet sich gute Programmierung[8] zum einen dadurch aus, dass die Funktionen, die die jeweils verwendete Programmierumgebung bereitstellt, möglichst effizient genutzt werden. Insbesondere geht es darum, für neue Aufgabenstellungen das Rad nicht immer wieder neu zu erfinden, wenn bestimmte Funktionen schon bereitgestellt werden (zum Beispiel durch die Programmierumgebung in Form von Programmbibliotheken). Sie zeichnet sich also vor allem dadurch aus, dass ein guter Überblick über den grundsätzlichen Funktionsumfang und die Systematik der von der Programmierumgebung bereitgestellten Funktionen (die in die zehntausende gehen können) möglich ist. Für eine definierte Aufgabenstellung kann in entsprechenden Dokumentationen dann schnell eine verfügbare Funktion ermittelt, eingesetzt und ggf. erweitert werden.

Arbeitsmittel
→ Hauptartikel: Programmierwerkzeug
Theoretisch reichen zum Programmieren ein einfacher Texteditor und ein Compiler/Interpreter für die jeweilige Programmiersprache aus. In der Praxis wird jedoch zusätzlich auf eine Reihe von Werkzeugen zurückgegriffen, die typische Programmierarbeiten vereinfachen sollen. Dazu gehören beispielsweise Texteditoren mit speziellen Features wie Syntax-Highlighting, Autovervollständigen und Refactoring – wobei der Übergang zur Integrierten Entwicklungsumgebung (IDE) fließend ist.

Daneben existieren verschiedene Werkzeuge zur Fehlersuche, sog. Debugger, sowie Programme zur Durchführung statischer und dynamischer Tests. Zur Performanzanalyse kann zusätzlich ein Profiler eingesetzt werden.

Arbeiten mehrere Entwickler an derselben Software, kommen meist Versionierungssysteme zum Einsatz, die den Code inklusive früherer Versionen auf einem zentralen Server speichern, auf den alle beteiligten Programmierer Zugriff haben.

Sprachwissenschaft, auch Linguistik (zu lateinisch lingua ‚Zunge‘, ‚Sprache‘), untersucht in verschiedenen Herangehensweisen die menschliche Sprache. Inhalt sprachwissenschaftlicher Forschung sind die Sprache als System, ihre einzelnen Bestandteile und Einheiten sowie deren Bedeutungen. Des Weiteren beschäftigt sich die Sprachwissenschaft mit Entstehung, Herkunft und geschichtlicher Entwicklung von Sprache, mit ihrem vielseitigen Gebrauch in der schriftlichen und mündlichen Kommunikation, mit dem Wahrnehmen, Erlernen und Artikulieren von Sprache sowie mit den möglicherweise damit einhergehenden Störungen.

Ein großes Teilgebiet ist die Allgemeine Sprachwissenschaft: Sie stellt die Methoden bereit, mit der beliebige Einzelsprachen beschrieben und auch miteinander verglichen werden können. Wesentliche Aspekte der Allgemeinen Sprachwissenschaft sind Grammatiktheorie, Vergleichende Sprachwissenschaft bzw. Sprachtypologie und Historische Sprachwissenschaft. Sprachsystem, Sprachgeschichte und Sprachverwendung kann auch auf bestimmte Einzelsprachen oder Sprachgruppen beschränkt untersucht werden, so in der Germanistischen Linguistik das Deutsche oder im Rahmen der Romanistik die Romanischen Sprachen.

Ein weiteres Teilgebiet der Sprachwissenschaft ist die Angewandte Linguistik. Diese kann ebenfalls Fragen behandeln, die sprachübergreifend formuliert sind, zum Beispiel wissenschaftliche Grundlagen des Sprachunterrichts im Bereich der Fremdsprachenlehr- und -lernforschung oder Sprachtherapie in der Klinischen Linguistik. Die Psycholinguistik untersucht unter anderem den Spracherwerb des Kleinkinds und die kognitiven Prozesse, die ablaufen, wenn Menschen Sprache verarbeiten. Die Korpuslinguistik und die Quantitative Linguistik sind Gebiete, die in den letzten Jahrzehnten durch die Erweiterung der technischen Möglichkeiten im Bereich der maschinellen Sprachverarbeitung stark an Bedeutung gewonnen haben. Die Soziolinguistik, Medienlinguistik und Politolinguistik behandeln den öffentlichen Sprachgebrauch und den Übergangsbereich zu den Sozialwissenschaften.

Sprachwissenschaft umfasst also zahlreiche größere und kleinere Teilgebiete, die insgesamt sowohl inhaltlich als auch methodisch uneinheitlich sind und mit einer Vielzahl anderer Wissenschaften in Kontakt stehen.


Inhaltsverzeichnis
1	Wissenschaftstypus
2	Terminologie
2.1	Die Termini Sprachwissenschaft und Linguistik
2.2	Benennung von Teildisziplinen
2.3	Fachvokabular
3	Teilbereiche
3.1	Vergleichende Sprachwissenschaft
3.2	Angewandte Sprachwissenschaft
3.3	Interdisziplinäre Teilgebiete der Linguistik
4	Interdisziplinarität
5	Geschichte der Sprachwissenschaft
6	Forschung
6.1	Forschungsparadigmen
6.2	Ansätze
6.3	Bedeutende Sprachwissenschaftler (Auswahl)
7	Populärwissenschaftliche Linguistik
7.1	Formen
7.2	Inhalte
7.2.1	Öffentlicher Sprachgebrauch, Sprachwandel und Sprachkritik
7.2.2	Etymologie und Onomastik
7.2.3	Sprachbeschreibungen, Einzelsprachen
7.2.4	Psycholinguistik
8	Fachgesellschaften
8.1	Deutschland
8.2	Internationale Dachverbände
9	Siehe auch
10	Fachliteratur
10.1	Lexika und Enzyklopädien
10.2	Allgemeine Einführungen
10.3	Anderes
11	Weblinks
12	Einzelnachweise
Wissenschaftstypus
Da unterschiedliche Lesarten des Begriffs Sprache existieren und sehr unterschiedliche Aspekte von Sprache untersucht werden, ist die Zuordnung der Sprachwissenschaft zu nur einem Wissenschaftstypus nicht möglich. So wird die Linguistik beispielsweise als Lehre vom sprachlichen System von vielen als ein Teilgebiet der Semiotik, der Lehre von den Zeichen, angesehen und lässt sich damit der Gruppe der Strukturwissenschaften und den Formalwissenschaften zuordnen. Wird aber etwa der individuelle Erwerb von Sprache und der Gebrauch von Sprache aus psychologischer oder klinischer Warte gesehen, so sind diese Teilbereiche der Sprachwissenschaft zu den Naturwissenschaften zu zählen. Bei Betrachtung von Sprache als gesellschaftlichem und kulturellem Phänomen hingegen ist die Sprachwissenschaft als Kultur- bzw. Geisteswissenschaft zu werten. Auch gibt es Teilbereiche der Sprachwissenschaft (z. B. Ethno-, Polito- oder Soziolinguistik), die als solche zu den Sozialwissenschaften zu rechnen sind.

Terminologie
Die Termini Sprachwissenschaft und Linguistik

„Institut für Sprachwissenschaft“ (vormalig) und „Fachbereich Linguistik“ (nunmehrig) als Bezeichnungen derselben universitären Einrichtung
Grundsätzlich gibt es in der Sprachwissenschaft keine strenge Regelung zur Benennung dieser Disziplin selbst. Zum einen lassen die sehr unterschiedlichen Forschungsgebiete der Linguistik, aber auch ihre Nähe zu und Spezifizierung in den verschiedenen einzelsprachlichen Philologien (wie Germanistik, Anglistik, Romanistik usw.) die Sprachwissenschaft als solche insgesamt wenig geschlossen erscheinen. Infolgedessen wird öfters selbst innerhalb wissenschaftlicher Institutionen zur Bezeichnung neben Sprachwissenschaft völlig bedeutungsgleich auch die Pluralform Sprachwissenschaften herangezogen.

Zum anderen werden mehrheitlich die Ausdrücke Sprachwissenschaft und Linguistik gleichgesetzt und auch bei Benennungen von Teildisziplinen grundsätzlich als Synonyme verstanden, wie es etwa in den Bezeichnungen Historische Sprachwissenschaft und Historische Linguistik der Fall ist. Es sind jedoch gewisse regionale Bevorzugungen zu verzeichnen. So wird zum Beispiel der Begriff Allgemeine Linguistik in Österreich weniger gebraucht und hier eher von einer Allgemeinen Sprachwissenschaft gesprochen. Auch mögen in den einzelnen örtlichen „Schulen“ bestimmte Benennungen bevorzugt werden.

Oft wird aber zwischen den beiden Bezeichnungen insofern unterschieden, als mit Sprachwissenschaft die Sprache und der Sprachgebrauch als gesellschaftliches und kulturelles Phänomen gesehen werden. Mit diesem Verständnis steht die Sprachwissenschaft der Literaturwissenschaft sowie besonders der Philologie nahe. Demgegenüber wird dann unter Linguistik die reine Systemlinguistik verstanden, also die Betrachtung der Struktur einzelner Sprachen sowie deren unterschiedlicher Funktionen wie etwa im Zuge des Erwerbs von Sprache, ihre Repräsentation im Gehirn, ihr Gebrauch abhängig von sozialen oder demografischen Faktoren usw.

Benennung von Teildisziplinen
Unabhängig davon, ob eine Benennungsdichotomie von Sprachwissenschaft und Linguistik vorliegt oder nicht, wird bei der Bezeichnung der sprachwissenschaftlichen Teildisziplinen, die andere Wissenschaftsbereiche berühren, ausschließlich der Ausdruck Linguistik verwendet. So existiert beispielsweise nur eine Soziolinguistik und keine Sozio- oder Sozialsprachwissenschaft. Auch ist terminologisch in der Regel nur eine Psycholinguistik, Computerlinguistik, Politolinguistik usw. anzutreffen.

Mitunter, jedoch in Österreich kaum, wird der Teilbereich der Allgemeinen Sprachwissenschaft auch als Theoretische Sprachwissenschaft oder Theoretische Linguistik bezeichnet.

Des Weiteren existiert die nicht restlos geklärte Frage, was man unter „angewandter“ Sprachwissenschaft zu verstehen habe. Einerseits können darunter diejenigen Teilgebiete verstanden werden, die die real angewendete Sprache untersuchen (im Gegensatz zu den theoretischen Konstrukten von sprachlichen Systemen, Grammatikmodellen usw.); andererseits kann „angewandte“ Sprachwissenschaft auch heißen, dass es sich dabei um die Anwendung der Forschungsergebnisse in der (außerhalb der Linguistik befindlichen) Praxis handelt (Sprachtherapie, Spracherkennung am Computer usw.). Dieses Problem der Grenzfälle zwischen Allgemeiner oder Theoretischer, und Angewandter Sprachwissenschaft wird innerhalb der Disziplin, ausgehend von einer Diskussion im englischsprachigen Wissenschaftsraum, auch unter der Benennungsopposition applied linguistics (für den ersteren Fall) versus linguistics applied (für den letzteren Fall) diskutiert.

Fachvokabular

Dieser Artikel oder nachfolgende Abschnitt ist nicht hinreichend mit Belegen (beispielsweise Einzelnachweisen) ausgestattet. Angaben ohne ausreichenden Beleg könnten demnächst entfernt werden. Bitte hilf Wikipedia, indem du die Angaben recherchierst und gute Belege einfügst.
klingt nach TF und einer nicht gerechtfertigen Gleichsetzung von "Das wird in der Schule behandelt" (oder eher: wird eigentlich behandelt, sollte behandelt werden o. ä.) und "Das ist der Allgemeinheit bekannt".
In der Sprachwissenschaft wird eine eigene Fachterminologie verwendet.[1] Eine ganze Reihe von Fachausdrücken erscheint auch im alltäglichen Sprachgebrauch. Grundlegende Termini sind über die schulische Ausbildung auch der Allgemeinheit verständlich. Dazu zählen insbesondere die Bezeichnungen für Wortarten (Verb, Substantiv usw.), für funktionale Satzelemente (Subjekt, Objekt usw.) und andere Ausdrücke aus der traditionellen Schulgrammatik. Außerdem existiert eine Reihe von Ausdrücken, welche Nicht-Sprachwissenschaftler intuitiv in der Grundbedeutung erfassen mögen (Textsorte, Sprecher, Sprachkorpus usw.), was mitunter zu Irrtümern führen kann, denn viele Fachausdrücke haben innerhalb der wissenschaftlichen Disziplin eine andere oder zusätzliche Bedeutung als im sprachlichen Alltag. Zudem werden von Laien Ausdrücke dieser Art aufgrund ihrer Erfahrungen im schulischen Unterricht bevorzugt unter normativem Aspekt, also dahingehend gesehen, was „richtig“ und was „falsch“ ist, während sie als Fachvokabel innerhalb der wissenschaftlichen Disziplin in der Regel eine rein deskriptive Funktion haben. Solche unscharfen Grenzen zwischen Umgangssprache und Fachsprache sind aber kein Spezifikum der Sprachwissenschaft, sondern liegen auch bei anderen Wissenschaften vor.

Neben Ausdrücken, die dem allgemeinen Sprachgebrauch nahe sind und oft auch aus dem Deutschen stammen, existiert eine ganze Reihe von Termini, die aus lateinischen oder altgriechischen Wortelementen bestehen. Neuere Fachausdrücke werden oft aus dem Englischen übernommen oder eingedeutscht. Nur ein äußerst geringer Teil des (wissenschaftsgeschichtlich früh entstandenen) Fachvokabulars stammt aus dem Französischen. In den linguistischen Randbezirken zu anderen Disziplinen spielt auch deren Fachterminologie eine wesentliche Rolle.

Siehe auch: Grammatikbegriffe im Deutschen und Deutsche Grammatik#Arten von Grammatiken
Teilbereiche
Zusätzlich zu der inhomogenen Benennungsweise der wissenschaftlichen Disziplin selbst ist auch die Trennung der Sprachwissenschaft in klar voneinander abgegrenzte Teildisziplinen uneinheitlich. Oft ist sogar überhaupt eine solche Trennung selbst umstritten, was nicht zuletzt auf den insgesamt starken interdisziplinären Charakter des wissenschaftlichen Gesamtbereiches zurückzuführen ist. Viele Forschende empfinden bereits die Abgrenzung der drei großen linguistischen Domänen

Vergleichende Sprachwissenschaft bzw. Historische Sprachwissenschaft
Allgemeine Sprachwissenschaft und
Angewandte Sprachwissenschaft
als künstlich oder unzweckmäßig. Dem entspricht auch die teils unterschiedliche Zuordnung einzelner Forschungsfelder entweder zu dem einen oder dem anderen Bereich. So besteht z. B. keine allgemeine Übereinkunft darüber, ob die Varietätenlinguistik als ein abzugrenzendes Teilgebiet der Angewandten Sprachwissenschaft oder als Teil der Soziolinguistik gelten soll.

Nicht als Teilbereich der Linguistik wird aber in der Regel die Philologie gewertet, welche einzelne Sprachen sowohl aus sprach- als auch literatur- und kulturwissenschaftlicher Sicht untersucht. Vielmehr gilt sie wissenschaftsgeschichtlich als eigene Disziplin, was sich in Deutschland vielfach in einer entsprechend getrennten Universitätsstruktur niederschlägt, auch wenn enge Verbindungen zwischen Philologien und Linguistik bestehen. In Österreich hingegen haben im Allgemeinen die entsprechenden universitären Institute (vornehmlich Germanistik, Anglistik, Romanistik und Slawistik) sowohl eine philologisch-literaturwissenschaftliche als auch eine sprachwissenschaftliche Abteilung.

Hinsichtlich der folgenden Taxonomie der linguistischen Teildisziplinen besteht weitgehend Konsens.

Die folgende Tabelle veranschaulicht Bereiche der Linguistik und deren Gegenstände.

Bereich	Gegenstand
Phonetik/Phonologie	lautliche Struktur
Morphologie	Wortstruktur
Syntax	Satzstruktur
Semantik/Pragmatik	Bedeutung
Psycho- und Neurolinguistik	Prozesse im Hirn
Soziolinguistik	soziale Variation der Sprache
Dialektologie	lokale Variation der Sprache
Vergleichende Sprachwissenschaft
→ Hauptartikel: Vergleichende Sprachwissenschaft
Die Vergleichende Sprachwissenschaft kann dahingehend in einzelne Teilgebiete gegliedert werden, ob eine diachrone oder synchrone Untersuchungsweise vorliegt. Die allgemein-vergleichenden Fächer können aber auch der Allgemeinen Sprachwissenschaft und die historisch-vergleichenden Fächer einer eigenständigen Historischen Sprachwissenschaft zugerechnet werden.

Allgemein-vergleichende Sprachwissenschaft
Arealtypologie, die synchron-vergleichende Untersuchung von Sprachen eines geographischen Raumes mit dem Ziel, Sprachbünde zu ermitteln
Kontrastive Linguistik, die synchron-vergleichende Untersuchung von meist nur zwei Sprachen mit dem Ziel, die spezifischen Unterschiede zwischen diesen zu erkennen
Sprachtypologie, die synchron-vergleichende Untersuchung von Sprachen mit dem Ziel, Sprachtypen festzustellen
Universalienforschung versucht, die allen Sprachen gemeinsamen Eigenschaften (Sprachuniversalien) aufzudecken
Varietätenlinguistik, die synchron-vergleichende Untersuchung von Einzelsprachen mit dem Ziel, Unterschiede innerhalb dieser bestimmten Sprache, also sprachliche Varietäten herauszuarbeiten, z. B. verschiedene Dialekte, Soziolekte, Fachsprachen usw. (Da diese Unterschiede großteils auf soziale Faktoren zurückzuführen sind, wird die Varietätenlinguistik auch als Teilgebiet der Soziolinguistik, einer Disziplin der Angewandten Sprachwissenschaft, behandelt.)

Franz Bopp (1791–1865), Begründer der Historisch-Vergleichenden Sprachwissenschaft
Historisch-vergleichende Sprachwissenschaft (auch Diachronie)
Historische Linguistik (im engeren Sinne), die diachron-vergleichende Untersuchung von Sprachen mit dem Ziel, Sprachfamilien herauszuarbeiten und Entwicklungslinien einer oder mehrerer Einzelsprachen im Vergleich, also Veränderungen in der Phonologie, Morphologie, Syntax, Semantik und Stilistik im Laufe der Zeit nachzuzeichnen. Sie befasst sich also mit Sprachwandel in jeglicher Hinsicht.
Weit verbreitet ist auch die Tradition, welche dieses Fach gemeinsam mit den nachfolgend gelisteten Teilgebieten zu einem einzigen Hauptfach Historische Linguistik oder Historische Sprachwissenschaft zusammenfasst. Unter dieser Annahme liegt dann also das Verständnis einer Historischen Linguistik im weiteren Sinne vor.
Etymologie, Lehre über die Entstehung und Herkunft von Wörtern und ihren Bedeutungen
Indogermanistik versucht eine Rekonstruktion der indo-europäischen (indogermanischen) Ursprache sowie durch Vergleich der Entwicklungen den Verlauf zu den heutigen indogermanischen Einzelsprachen nachzuvollziehen
Onomastik erforscht die Entstehung, Bedeutung und Verbreitung von Eigennamen (oft im Verbund mit der Etymologie behandelt)
Damit wird also zugleich eine Klassifizierung vorgenommen, welche neben der Allgemeinen Sprachwissenschaft und der Angewandten Sprachwissenschaft als drittes großes Teilgebiet statt der Vergleichenden Sprachwissenschaft die Historische Sprachwissenschaft zählt, wobei dann die allgemein-vergleichenden Fächer der Allgemeinen Sprachwissenschaft zugerechnet werden.


Ferdinand de Saussure (1857–1913), einer der bedeutendsten Vertreter des linguistischen Strukturalismus
Angewandte Sprachwissenschaft
→ Hauptartikel: Angewandte Sprachwissenschaft
Die Angewandte Sprachwissenschaft ist keineswegs als homogener Teilbereich der Linguistik zu verstehen, vielmehr subsumiert sie die Teildisziplinen, die sich in erster Linie nicht mit Sprache als abstraktem System befassen, sondern die Sprache im Zusammenhang mit ihrer „realen“ Umwelt sehen, sich also der tatsächlich angewendeten Sprache widmen. Diesem Verständnis von „angewandt“, also applied linguistics, steht die Idee der linguistics applied gegenüber, worunter die praktische Umsetzung linguistischer Forschungsergebnisse zu verstehen ist, wie sie vorliegt z. B. im Falle der Computerlinguistik (wo Erkenntnisse der Allgemeinen Linguistik in der Informatik Anwendung finden), der Klinischen Linguistik (wo Forschung im Dienste der Erarbeitung von Therapieformen steht), der Sprachlehrforschung (für die Entwicklung von Lehrmaterial) oder der Schreibforschung und Schreibdidaktik (für pädagogische Zwecke).

Des Weiteren werden häufig die Psycholinguistik, die Soziolinguistik und andere Fächer der Allgemeinen Sprachwissenschaft zugerechnet, weil sie sich der Beschreibung von Sprache als Teil des Individuums widmet und allgemeine Prinzipien und Vorgänge erkunden will – im Gegensatz zu jenen Disziplinen, die einen Bezug zum praktischen Leben herstellen und sich somit mit der „Anwendung“ von Sprache befassen.

Da die Soziolinguistik sowohl Sprache und Gesellschaft, als auch die Mehrsprachigkeit der Gesellschaft selbst untersucht, kann sie auch als Überbegriff für jene Teildisziplinen verwendet werden, die normalerweise als gleichwertig etablierte Bereiche der Angewandten Sprachwissenschaft gelten, z. B. für die Sprachlehrforschung oder die Diskursanalyse.

Vor allem aber entscheiden die Strukturen von Universitäten und Instituten darüber, wie die Disziplinen wahrgenommen werden, denn mehrheitlich behandeln die angewandten Fächer auch solche Aspekte mit, die gemäß Definition zur Allgemeinen Sprachwissenschaft gezählt werden.

Der Angewandten Sprachwissenschaft werden in der Regel folgende Teilgebiete zugerechnet:

Computerlinguistik unter den Aspekten
Künstliche Intelligenz
Spracherkennung und Prosodieerkennung mittels Computer
Softwareentwicklung (Sprachkorrekturprogramme, Lernsoftware und webbasierte Lernplattformen)
Texttechnologie und Gestaltung von Hypertext
Forensische Linguistik, Untersuchung und Diagnostik von Sprache zu kriminalistischen und gerichtlichen Zwecken
Internetlinguistik, Analyse sprachlicher Phänomene, die im und durch das Internet entstehen
Klinische Linguistik, die Erforschung des Sprachgebrauchs und der Sprachwahrnehmung bei Schädigungen des Gehirns und Erarbeitung von therapeutischen Verfahren inkl. Sprachentwicklungsdiagnostik; mit ihr stehen einige andere Fächer eng in Zusammenhang, die entweder zur Angewandten Sprachwissenschaft als applied linguistics oder auch zur Allgemeinen Sprachwissenschaft gerechnet werden. Dabei handelt es sich neben der Psycholinguistik im Besonderen auch um
Neurolinguistik, die Untersuchung der Verarbeitung von Sprache im Gehirn
Patholinguistik (auch Sprachpathologie), die Untersuchung von Problemen bei Sprachperzeption, -verarbeitung und -produktion
Lexikografie, Erstellen von Wörterbüchern (in erster Linie für den allgemeinen Gebrauch)
Sprach- und Schreibberatung, Beratung und Coaching für Institutionen, öffentliche Einrichtungen, Journalismus und Public Relations sowie für private Zwecke und Bereiche
Sprachlehr- und Sprachlernforschung und Sprachdidaktik, Untersuchung von, und Gestaltungsmaßnahmen für Sprachunterricht, Sprecherziehung, Alphabetisierung; inklusive anderer Teilgebiete wie Schreibdidaktik und Untersuchen von Lernverhalten
Sprachplanung, Untersuchung und Schaffung von politischen Rahmenbedingungen und sprachpolitischen Maßnahmen für Sprachstandardisierung oder Mehrsprachigkeit
Standardologie befasst sich mit der Standardisierung von Sprachen oder Teilsprachen (wie etwa mit dem Zusammenfassen mehreren Sprachvarietäten zu einer (nationalen) Standardsprache im Rahmen der Sprachpolitik oder mit der Vereinheitlichung von technischer und anderer Terminologie u. Ä.).
Folgende Teilgebiete verstehen sich als angewandte Fächer im Sinne einer applied linguistics und können auch zur Allgemeinen Sprachwissenschaft in einem weiteren Sinne gerechnet werden:

Computerlinguistik unter den Teilaspekten
Programmiersprachen
Mensch-Computer-Interaktion
Ethnolinguistik, Untersuchung von Sprache und Sprachkultur unter völkerkundlichen Aspekten
Psycholinguistik, die Erforschung der Sprache in Abhängigkeit von psychischen Funktionen, dabei besonders auch
die Forschung zum Spracherwerb (Erst- und Zweitspracherwerb)
Kognitive Linguistik, die Untersuchung des Zusammenhangs zwischen Sprache und Denken
Soziolinguistik beschäftigt sich „in engerem Sinne“ mit der Sprache in Abhängigkeit von gesellschaftlichen Variablen wie soziale Schicht oder Alter. „In weiterem Sinne“ werden das Verhältnis von Sprache und Gesellschaft unter verschiedenen Aspekten sowie die Mehrsprachigkeit von Gesellschaft behandelt. Dazu zählen insbesondere folgende Teilgebiete:
Feministische Linguistik, Untersuchung der Sprache und des Sprachgebrauchs in Abhängigkeit vom Geschlecht, geschlechtsneutraler Sprachgebrauch (Wird Geschlecht nicht als natürliches Geschlecht (sexus), sondern als soziales Geschlecht (gender) definiert, wird die Forschung nicht aus feministischer Perspektive allein betrieben und das Teilgebiet als Genderlinguistik gehandelt).
Forschung zu Sondersprachen (z. B. Jugendsprache, Untersuchungen jugendlicher Sprache und jugendlichen Sprachverhaltens und ihre historische Entwicklung)
linguistische Diskursanalyse untersucht Sprachäußerungen auf übertextlicher Ebene
Spracheinstellungsforschung, Untersuchung von Einstellungen (Meinungen, Haltungen) zu einzelnen Sprachen und/oder Dialekten
Interkulturelle Kommunikation, Untersuchung von sprachlichem und außersprachlichem Verhalten bei Kommunikation von Sprechern verschiedener Kulturen
Interlinguistik, die Untersuchung der internationalen Kommunikation vornehmlich unter Verwendung von Plansprachen
Medienlinguistik, Forschungen in erster Linie zur Untersuchung von sprachlichen Phänomenen in Medientexten, Mehrsprachigkeit in den Medien und zur Erfassung medialer Diskurse
Politolinguistik, Erforschung der Sprache und des Sprachverhaltens im politischen Sektor
Interdisziplinäre Teilgebiete der Linguistik
Zusätzlich zu den bereits gelisteten Fächern, deren Zuordnung definitionsabhängig ist, gibt es eine Reihe weiterer Fachgebiete, deren Bezeichnungen je nach Universität, Teildisziplin oder paradigmatischer Ausrichtung unterschiedliches Verständnis hervorrufen und die nur bedingt einem bestimmten linguistischen Teilgebiet zugeordnet werden können. Auch berühren sie zum Teil andere Wissenschaftsgebiete. Das sind:

Dialektologie
deskriptive Untersuchungen von Dialekten in der Allgemeinen wie auch in der Vergleichenden Sprachwissenschaft
Verwendung von Dialekten, also aus soziolinguistischer Perspektive
Verhältnis von Sprache und Dialekt, also in der Varietätenlinguistik
Forschung zu Fachsprachen
als systematische Beschreibung von Fach- und berufsspezifischen Sprachen Teil der Allgemeinen Sprachwissenschaft (Varietätenlinguistik)
als Beschreibung des Gebrauchs von Fachsprachen in der Kommunikation in staatlichen Institutionen und anderen Einrichtungen (Amtssprache, medizinischer Fachbereich usw.) Teilgebiet der Angewandten Sprachwissenschaft (Soziolinguistik)
Kontaktlinguistik, Untersuchung von Sprachkontaktphänomenen als Schnittstelle zwischen Allgemeiner, Angewandter und Vergleichender Sprachwissenschaft
Koloniallinguistik, Untersuchung der vielfältigen sprachlichen Aspekte, die sich in Kolonialsituationen ergeben/ergeben haben

Elektronisch gefertigte Konkordanz – Mittel der modernen Korpuslinguistik
Korpuslinguistik, Untersuchung von Sprachsystem realer schriftlicher Texte und mündlicher Sprachäußerungen anhand von repräsentativen Textkorpora entweder als neues eigenständiges Teilgebiet der Allgemeinen Sprachwissenschaft gesehen oder als Methode der Erkenntnisgewinnung in einzelnen allgemeinen und angewandten Teildisziplinen herangezogen
Paläolinguistik untersucht die Entstehung menschlicher Sprache. Sie ist nur schwer einem der Hauptgebiete der Sprachwissenschaft zuzuordnen und es bestehen Überschneidungen mit der Psychologie und der Anthropologie.
Ökolinguistik, mäßig etablierter Zweig soziolinguistischer Grundlage, der sich im Wesentlichen mit der Ökologie von Sprache und der Sprache von Ökologie widmet
Schreibforschung und Schreibdidaktik, an der Schnittstelle zwischen Textlinguistik, soziolinguistischer Institutionenforschung und Sprachlehrforschung
Schriftlinguistik ist ein Begriff, der die verschiedenen Strömungen der Linguistik zusammenfasst, die sich der Erforschung von Schrift und Schriftsystemen sowie ihrem Erwerb und gezielten Einsatz für bestimmte kommunikative Zwecke widmen
Sprachstatistik
als Statistik der Sprachen Teil der Sozio-, Varietäten- oder Interlinguistik
als Erhebung statistischer Daten zu beliebigen sprachlichen Aspekten, meist im Bereich der Allgemeinen Sprachwissenschaft, aber auch der Historischen Linguistik, Psycholinguistik, der Spracherwerbsforschung, Sprachtypologie und weiterer Disziplinen
Sprachwahrnehmung, Erforschung der akustischen Wahrnehmung von Sprache (auditive Phonetik) im Schnittpunkt zwischen Phonetik, Psycho- und Neurolinguistik
Translatologie
Interdisziplinarität
→ Hauptartikel: Interdisziplinarität
Mit der Auflistung der linguistischen Teilgebiete wird der interdisziplinäre Charakter der Sprachwissenschaft deutlich. Etliche Teildisziplinen grenzen explizit an andere Wissenschaften und teilen mit diesen bestimmte Interessengebiete. Dies betrifft hauptsächlich die Wissenschaftsbereiche:

Gender Studies (Feministische Linguistik)
Informatik (Computerlinguistik)
Kommunikationswissenschaft (Medienlinguistik, Interkulturelle Kommunikation)
medizinischer Teilbereich Neurologie (Neurolinguistik)
Pädagogik (Sprachlehrforschung)
Politikwissenschaft (Politolinguistik)
Psychologie (Psycholinguistik)
Soziologie (Soziolinguistik)
Mehrfach haben linguistische Teildisziplinen ihre fachliche Entsprechung in Teilgebieten der angrenzenden Wissenschaften, sodass beide – eigentlich fälschlicherweise, da inhaltlich und methodisch vielfach unterschiedlich – auch im akademischen Bereich fallweise miteinander gleichgesetzt werden. Dies liegt besonders in folgenden Fällen vor:

Politolinguistik – Politische Kommunikation
Psycholinguistik – Sprachpsychologie
Soziolinguistik – Sprachsoziologie
Die Sprachwissenschaft fungiert weiters als ausgewiesene Teil- und Hilfswissenschaft anderer Wissenschaftsgebiete:

Die Allgemeine Sprachwissenschaft ist mit ihrer Erforschung von sprachlichen Strukturen und mit dem Erstellen von Grammatikmodellen neben Psychologie und Neurologie integrativer Bestandteil der Kognitionswissenschaft.
Die Historische Linguistik ist besonders mit ihren Methoden des sprachlichen Vergleichs und der sprachlichen Rekonstruktion Hilfswissenschaft für die Archäologie und für die Alte Geschichte.
In Hinblick auf gewisse linguistische Forschungsfragen gelten noch weitere wissenschaftliche (Teil-)Disziplinen als der Sprachwissenschaft benachbart, so hauptsächlich:

Anthropologie
Ethnologie
Klassische Philologie und Epigraphik
Medienwissenschaft
Logopädie und Phoniatrie
Ökologie
Rechtswissenschaft
Rhetorik und Sprechwissenschaft
Semiotik und Sprachphilosophie
Übersetzungswissenschaft
Geschichte der Sprachwissenschaft
→ Hauptartikel: Geschichte der Sprachwissenschaft
Die Geschichte der Sprachwissenschaft erstreckt sich von antiken Anfängen in Indien und Griechenland, in denen die Beschäftigung mit Sprache noch anderen Zwecken – in Indien der Interpretation ritueller Texte, in Griechenland als Vorbereitung für die Philologie – untergeordnet war, bis hin zu der modernen, autonomen Wissenschaft mit vielen Subdisziplinen, die sie heute ist. Wichtige Stationen auf diesem Weg waren in der letzten Zeit insbesondere die Begründung der Indogermanistik im 19. Jahrhundert, die Etablierung der strukturalistischen Sprachbeschreibung durch Ferdinand de Saussure zu Beginn des 20. Jahrhunderts und die Entwicklung der Generativen Grammatik durch Noam Chomsky seit Mitte des 20. Jahrhunderts.

Forschung
Forschungsparadigmen
In der linguistischen Forschung sind drei grundsätzliche paradigmatische Unterschiede in der Herangehensweise zu verzeichnen. In der Konzeption von Forschungsfragen können diese klarerweise auch miteinander gekreuzt werden.

präskriptiv – deskriptiv
Präskriptive Schriften über Sprachgebrauch werden heutzutage von Wissenschaftlern weitestgehend als unwissenschaftlich abgelehnt. Normativ orientierte Arbeiten, die als wissenschaftliche angesehen werden, sind im Sinne von applied linguistics zu verstehen, aber solche Arbeiten nehmen im akademischen Bereich nur wenig Raum ein. Gerade in Bezug auf normative Schlussfolgerungen herrschen hier zum Teil sehr kontroverse Ansichten. Beispielsweise wird immer wieder heftig debattiert, inwieweit Sprachkritik überhaupt ein Gegenstand linguistischer Forschung sein und von Linguisten betrieben werden kann und soll, weil sie ja entweder leicht eine werthaltige Norm des Gebrauchs von Sprache einfließen lässt oder oft zugleich Gesellschaftskritik darstellt. Präskriptive Arbeiten werden − mit wenigen Ausnahmen wie etwa Sprachentwicklungstests, die den Sprachstand eines Kindes gemessen an einer ermittelten Entwicklungsnorm festlegen − weitestgehend nicht in der akademischen Forschung und Lehre behandelt, sondern meist von wirtschaftlicher oder privater Seite erstellt.
Beispiele einer Gegenüberstellung von präskriptiven und deskriptiven Arbeiten aus denselben Bereichen sind etwa folgende:
präskriptiv	deskriptiv
Lexikografie:
Rechtschreibungswörterbuch
rückläufiges Wörterbuch
Psycholinguistik / Klinische Linguistik:
medizinische Sprachtests
Sprachentwicklungsforschung
Soziolinguistik:
Anweisungen für geschlechtsneutralen Sprachgebrauch
Beschreibung geschlechtsspezifischen Sprachgebrauchs
diachron – synchron
Diese Sichtweisen bestimmen, ob ein sprachliches Phänomen in seiner Entwicklung über die Zeit (diachron) oder im Zustand zu einem bestimmten Zeitpunkt (synchron) beschrieben wird, wobei dieser Zeitpunkt keinesfalls nur der gerade augenblickliche sein muss. Obwohl sehr viele sprachliche Phänomene auch in einer historischen Dimension wahrgenommen werden können, haben sich in der akademischen Linguistik (zumindest bislang) nur bestimmte Sachbereiche als Gegenstand diachroner Untersuchung etabliert. So werden beispielsweise soziolinguistische Themen oder syntaktische Phänomene nur wenig aus historischer Sicht behandelt, während Laut- und Bedeutungsveränderungen von Wörtern oder Veränderungen im Wortschatz einer Sprache schon seit sehr langem ein zentrales Gebiet historischer Untersuchungen darstellen. Der Umfang und die Auswahl diachron ausgerichteter Forschungsfragen hängt aber erklärlicherweise sehr von der Existenz der vorhandenen Quellen ab.
Beispiele einer Gegenüberstellung von diachronen und synchronen Arbeiten aus denselben Bereichen sind etwa folgende:
diachron	synchron
Dialektologie:
Verschiebung deutscher Dialektgrenzen vom 16. bis zum 20. Jh.
Grenzen der deutschen Dialekte im 18. Jh.
Soziolinguistik:
Sprache verschiedener sozialer Unterschichten im zeitlichen Vergleich
Sprache der Arbeiterschaft um 1900
Semantik:
Bedeutungsentwicklung des Wortes Kunst in der Neuzeit
derzeitiges Bedeutungsspektrum des Wortes Kunst
Ansätze
Humanistische
Das Grundprinzip der humanistischen Linguistik ist, dass Sprache eine von Menschen geschaffene Erfindung ist. Eine semiotische Tradition der Sprachforschung betrachtet Sprache als Zeichensystem, das aus dem Zusammenspiel von Bedeutung und Form entsteht.[2] Die Organisation sprachlicher Ebenen gilt als rechnerisch.[3] Die Linguistik wird im Wesentlichen als sozial- und kulturwissenschaftlich orientiert gesehen, weil unterschiedliche Sprachen in der sozialen Interaktion durch die Sprachgemeinschaft geprägt werden.[4] Frameworks, die die humanistische Sicht der Sprache repräsentieren, umfassen unter anderem die Strukturlinguistik.[5]

Strukturanalyse bedeutet, jede sprachliche Ebene zu zerlegen: phonetisch, morphologisch, syntaktisch und diskursiv bis in die kleinsten Einheiten. Diese werden in Inventaren (z. B. Phonem, Morphem, lexikalische Klassen, Phrasentypen) gesammelt, um ihre Vernetzung innerhalb einer Hierarchie von Strukturen und Schichten zu untersuchen.[6] Die Funktionsanalyse fügt der Strukturanalyse die Zuweisung semantischer und anderer funktionaler Rollen hinzu, die jede Einheit haben kann. Zum Beispiel kann eine Nominalphrase als Subjekt oder Objekt des Satzes fungieren; oder der Agent oder Patient.[7]

Funktionale Linguistik oder funktionale Grammatik ist ein Zweig der strukturellen Linguistik. In der humanistischen Referenz beziehen sich die Begriffe Strukturalismus und Funktionalismus auf ihre Bedeutung in anderen Humanwissenschaften. Der Unterschied zwischen formalem und funktionalem Strukturalismus liegt in der Beantwortung der Frage, warum Sprachen die Eigenschaften haben, die sie haben. Funktionale Erklärung beinhaltet die Idee, dass Sprache ein Werkzeug für Kommunikation ist, oder dass Kommunikation die primäre Funktion von Sprache ist. Sprachliche Formen werden folglich durch einen Appell an ihren funktionalen Wert oder ihre Nützlichkeit erklärt. Andere strukturalistische Ansätze nehmen die Perspektive ein, die sich aus den inneren Mechanismen des bilateralen und vielschichtigen Sprachsystems ergibt.[8]

Biologische
Ansätze wie die kognitive Linguistik und die generative Grammatik untersuchen die sprachliche Kognition mit dem Ziel, die biologischen Grundlagen der Sprache aufzudecken. In der Generativen Grammatik werden diese Grundlagen so verstanden, dass sie angeborenes domänenspezifisches grammatikalisches Wissen beinhalten. Daher ist eines der zentralen Anliegen des Ansatzes herauszufinden, welche Aspekte des sprachlichen Wissens angeboren sind und welche nicht.[9][10]

Im Gegensatz dazu lehnt die kognitive Linguistik den Begriff der angeborenen Grammatik ab und untersucht, wie der menschliche Geist aus Ereignisschemata sprachliche Konstruktionen schafft.[11] und die Auswirkungen kognitiver Einschränkungen und Verzerrungen auf die menschliche Sprache.[12] Ähnlich wie beim neurolinguistischen Programmieren wird Sprache über die Sinne angegangen.[13][14][15] Kognitive Linguisten untersuchen die Verkörperung von Wissen, indem sie nach Ausdrücken suchen, die sich auf modale Schemata beziehen.[16]

Ein eng verwandter Ansatz ist die evolutionäre Linguistik[17] die das Studium sprachlicher Einheiten als kulturelle Replikatoren umfasst.[18][19] Es ist möglich zu untersuchen, wie sich Sprache repliziert und sich an den Verstand des Einzelnen oder der Sprachgemeinschaft anpasst.[20][21] Konstruktionsgrammatik ist ein Framework, das das Meme-Konzept auf das Studium der Syntax anwendet.[22][23][24][25]

Der generative Ansatz und der evolutionäre Ansatz werden manchmal als Formalismus versus Funktionalismus bezeichnet.[26] Diese Bezugnahme unterscheidet sich jedoch von der Verwendung der Begriffe in den Humanwissenschaften.[27]

Bedeutende Sprachwissenschaftler (Auswahl)
Leonard Bloomfield, wichtigster Vertreter des amerikanischen Strukturalismus in der Zeit zwischen den beiden Weltkriegen
Franz Bopp, Begründer der vergleichenden Sprachwissenschaft und Mitbegründer der Indogermanistik
Karl Brugmann, Mitbegründer der Indogermanistik, einer der führenden Vertreter der Junggrammatiker
Karl Bühler entwickelte das zur Grundlage gewordene Organon-Modell der Sprachfunktionen
Noam Chomsky begründete die Generative Grammatik
Joseph Greenberg führte umfangreiche Untersuchungen zu Sprachtypologie und Universalien von Sprache aus, begründete die heutige Grobklassifikation der afrikanischen Sprachen und postulierte die Makro-Sprachfamilien Amerind und Eurasiatisch
Jacob Grimm und Wilhelm Grimm gelten als Begründer der Deutschen Philologie
William Haas, Mitbegründer der englischen Linguistics Association und sozial indizierter Sprachanalyse
Zellig S. Harris, Hauptautor des amerikanischen Deskriptivismus
Louis Hjelmslev, Hauptvertreter der Kopenhagener Schule, Glossematik
Wilhelm von Humboldt begründete die Vergleichende Sprachwissenschaft
Roman Jakobson, Mitglied der Prager Schule, bahnbrechende Untersuchung zum Spracherwerb
William Labov ist einer der wichtigsten Forscherpersönlichkeiten in der Soziolinguistik
George Lakoff ist ein Vertreter der Kognitiven Linguistik
Eric Heinz Lenneberg, biologische Grundlagen der Sprache
Antoine Meillet beschäftigte sich mit den indogermanischen Sprachen, behandelte Ökonomie als Triebkraft des Sprachwandels
Hermann Osthoff, Mitbegründer der Indogermanistik, einer der führenden Vertreter der Junggrammatiker
Panini, verfasste die erste Grammatik des Sanskrit und damit die älteste erhaltene Grammatik überhaupt
Hermann Paul war ein Sprachtheoretiker, einer der führenden Vertreter der Junggrammatiker
Harm Pinkster ist der weltweit führende lateinische Linguist
Edward Sapir, Namensgeber der Sapir-Whorf-Hypothese und Forscher besonders für die Sprachtypologie
Ferdinand de Saussure, Hauptvertreter der Genfer Schule, gilt als Begründer der modernen synchronen Linguistik und prägte den zweiseitigen Zeichenbegriff
August Schleicher gilt als Begründer der Stammbaumtheorie in der Vergleichenden Sprachforschung
Johannes Schmidt gilt als Begründer der Wellentheorie
Nikolai Sergejewitsch Trubetzkoy, führender Vertreter der Prager Schule, Begründer der Phonologie
George Kingsley Zipf ist mit den Zipfschen Gesetzen bahnbrechender Forscher für die Quantitative Linguistik
Ghil'ad Zuckermann ist ein Vertreter der Sprachwiederbelebung.

Wilhelm von Humboldt



Roman Jakobson



George Lakoff



N. S. Trubetzkoy

Populärwissenschaftliche Linguistik
Formen
Publikationen populärwissenschaftlichen Charakters zeichnen sich u. a. dadurch aus, dass sie die Ergebnisse wissenschaftlicher Arbeit in allgemein verständlicher Sprache und in einer Form darbieten, die auch Nichtfachleute interessiert. Damit findet nicht nur eine Verbreitung von Fachwissen in der Öffentlichkeit statt, sondern auch eine Annäherung des Fachgebietes selbst an die nicht-akademische Bevölkerung.

Die Sprachwissenschaft gilt – gemessen etwa an etablierten naturwissenschaftlichen Disziplinen – gemeinhin als eine „kleine“ Wissenschaft und ist schon allein deshalb interessiert, sich durch Berichte in Printmedien, Beiträgen in Rundfunk und Fernsehen sowie mittels Buchpublikationen einem breiteren Publikum zu präsentieren. Einige andere wissenschaftliche Disziplinen haben diesbezüglich den Vorteil, dass sie publikumswirksam mit konkreten Gegenständen (wie etwa die Archäologie mit Grabungsfunden oder die Astrophysik mit Himmelskörpern) und mit anschaulichen Dingen (wie beispielsweise die Geschichte mit historischen Ereignissen) aufwarten können. Demgegenüber erscheinen für den Laien etliche der linguistischen Forschungsgebiete oft als zu wenig greifbar. Dennoch ist ein gewisses Interesse der Menschen an sprachlichen Angelegenheiten zu verzeichnen, was sich an den Inhalten der populärwissenschaftlichen Publikationen bestimmen lässt. Wie aus den biografischen Angaben der Autoren solcher Veröffentlichungen zu entnehmen, sind diese – zumindest im deutschsprachigen Raum – oft selbst keine akademisch ausgebildeten Sprachwissenschaftler, sondern stammen ursprünglich aus anderen Fachgebieten oder gehören anderen Berufen an. Verbreitet ist dieses Phänomen besonders auch im präskriptiven Bereich (Sprachratgeber, Stilfibeln usw.). Dazu sind etwa die Veröffentlichungen von Rupert Lay oder Wolf Schneider und vielen anderen zu zählen.

Die linguistische Fachsprache kann in vielen Teildisziplinen nahe an der im Alltag gebräuchlichen Umgangssprache angesiedelt sein und ist dann für interessierte Laien meist nur wenig unverständlich.[28] Daher liegen diesbezüglich linguistische Fachpublikationen und populärwissenschaftliche Veröffentlichungen in Einzelfällen nahe beieinander.

Sowohl die in Anspruch genommenen Medien als auch die inhaltlichen Formen populärwissenschaftlicher Linguistik sind vielfältig. Bezüglich der medialen Nutzung reichen sie heute von der klassischen Buchpublikation über spezifische Websites und Kolumnen in Tageszeitungen bis hin zu Hörbüchern und Vorträgen. An inhaltlichen Formen sind Sachbücher, aber auch in Buchform gesammelte Glossen über Sprache gängig. Neuerdings ist – nicht nur im linguistischen Bereich – auch die gestalterische Variante Wörterbuch immer wieder anzutreffen, in der ein bestimmtes Thema ausgehend von einzelnen Wörtern, Begriffen oder sprachlichen Wendungen abgehandelt wird. Mit dem Aufkommen der Neuen Medien wurde es auch ohne großen Aufwand möglich, das Publikum durch Abstimmungen (per Internet) oder Abgabe von Kommentaren (Postings auf Webseiten) in die Diskussion direkt mit einzubeziehen.

Inhalte
Hauptsächlich finden in erster Linie solche sprachwissenschaftlichen Angelegenheiten in der breiten Öffentlichkeit Anklang, die das eigene Sprachverhalten der Menschen betreffen oder mit denen sie im Alltag immer wieder konfrontiert werden. Dazu gehören im Besonderen folgende Themengebiete:

Öffentlicher Sprachgebrauch, Sprachwandel und Sprachkritik
Dieser umfassende Themenbereich verdeutlicht auch, dass populärwissenschaftliche Linguistik nicht in einem Eins-zu-eins-Verhältnis mit den akademischen Fachdisziplinen gesetzt werden kann, denn in diesem Bereich überschneiden sich historische, allgemeine und angewandte Fächer. Durch die Betrachtung der im öffentlichen Raum anzutreffenden Sprache (Massenmedien aller Art, politischer Bereich, Werbung, öffentliche Ankündigungen usw.) werden Tendenzen im aktuellen Sprachgebrauch ersichtlich. Der Vergleich von diesem mit Gewohntem und Altbekanntem lässt den stets vor sich gehenden Wandel der Sprache offenkundig werden. Die Auseinandersetzung mit diesem Vorgang und die Beurteilung aktueller Sprachverwendung auch aus der Warte anderer als sprachwissenschaftlicher Positionen hat eine lange Tradition. Hinsichtlich des Anspruchsniveaus reicht dieses Befassen mit sprachlichen Neuerungen, ihren Auswirkungen und deren Einschätzung beispielsweise von den sprachkritischen Essays Karl Kraus[29] bis hin zu rein wirtschaftlich motivierten, also verkaufsträchtig eingeschätzten, scherzhaften Dokumentationen sprachlichen Fehlgebrauchs ohne jegliche wissenschaftliche Ambition.[30]

Viele der Arbeiten, die den öffentlichen Sprachgebrauch beobachten und als Quellen zumeist die Tagespresse, aber auch Rundfunk, Fernsehen, Internet und öffentliche politische Reden und Schriften heranziehen, formulieren wiederholt werthaltige Kritik und stellen spracherhaltende Forderungen. Sie spüren zwar Neuerungen im Sprachgebrauch und im Wortschatz auf, die auch Linguisten interessieren, stellen diese Phänomene allerdings zumeist nicht in den Zusammenhang sprachwissenschaftlicher Erkenntnisse. Solche Publikationen, deren Werthaltigkeit oft schon in den Titeln zum Ausdruck kommt, sind somit nur bedingt zur eigentlichen sprachwissenschaftlichen Populärwissenschaft zu zählen.[31] Ein Thema dieses Fragenbereichs, nämlich der derzeitige Einfluss des Englischen auf die deutsche Sprache, ist wohl als eines der augenblicklich meistdiskutierten zu sehen.

Ein beträchtlicher Teil solcher Arbeiten zur Veränderung der Sprache und zum aktuellen Sprachgebrauch basiert aber auf linguistischer Methodik oder ist als rein deskriptiv zu werten und wird somit in dieser Hinsicht den Ansprüchen akademischer Linguistik gerecht. Als Ausdruck dessen werden wiederholt Ansichten solcher populärwissenschaftlicher Autoren in die linguistische Fachdiskussion eingebracht. Dazu gehören beispielsweise die Arbeiten von Dieter E. Zimmer und die dem Thema entsprechenden Veröffentlichungen von Eike Christian Hirsch. Immer wieder werden aber auch welche dieser Art von namhaften Sprachwissenschaftlern als zu normativ orientiert abgelehnt.[32]

Oft werden Beobachtungen spezifisch im politisch-gesellschaftlichen Bereich bewusst als Wörterbücher konzipiert, wobei die für die Allgemeinheit bestimmten Veröffentlichungen von einfachen und knapp gehaltenen Abrissen[33] über Beschreibungen mit professionellem politischen Background[34] bis hin zu umfangreichen interdisziplinären Arbeiten[35] reichen. Eine Klassifizierung solcher oft sehr profunden Arbeiten als populärlinguistisch kann aus unterschiedlichen Gründen erfolgen (Aufmachung, anvisiertes Zielpublikum …) und gegebenenfalls reine Ermessenssache sein.

Was den Themenbereich zu aktuellem Sprachstand und Sprachwandel angeht, werden nicht nur neue sprachliche Erscheinungen thematisiert, sondern auch ein Blick auf das aussterbende Vokabular gelenkt und dieses dokumentiert.[36]

Mit Themen aus der allgemeinen Sprachwissenschaft, aber auch hinsichtlich aktuellen Gebrauchs befassen sich weiters regelmäßige Kolumnen in Printmedien und deren Onlineausgaben. Als bekannteste sind in Deutschland der Zwiebelfisch von Bastian Sick und in Österreich die in der Wiener Zeitung erscheinende Kolumne Sedlaczek am Mittwoch des Sprachwissenschaftlers Robert Sedlaczek zu nennen. Nicht zuletzt ist auch die sprachkritische Aktion Wort des Jahres, welche – einer Hitparade gleich – die gesellschaftlich-politisch wichtigsten Begriffe eines Jahres kürt, als eine erfolgreiche populärwissenschaftliche Maßnahme der Sprachwissenschaft einzustufen.


Allgemein verständliche Erklärung der Bedeutung der Ortsnamenforschung (Schautafel eines Lehrpfades zur Geschichte eines Ortes)
Etymologie und Onomastik
Zu den Klassikern populärwissenschaftlicher Linguistik zählt der historische Teilbereich Namenkunde. An erster Stelle stehen dabei die schon seit Langem in unzähligen Veröffentlichungen und mit unterschiedlicher Qualität vorliegenden Lexika und Verzeichnisse von Vornamen und deren Bedeutungen. Die Möglichkeiten des Internets erlauben nicht nur solche online anzubieten,[37] sondern auch die Einbindung der Bevölkerung in die Forschung durch die Möglichkeit einer Abgabe von Beurteilungen einzelner Namen.[38] Anknüpfend an den Wunsch der Menschen, die Bedeutung des eigenen Namens und die eigene familiäre Herkunft und die Bedeutung der Namen in der eigenen geografischen Umgebung zu kennen, werden vermehrt etymologische Angaben zu Familiennamen (auch im Zusammenhang mit der Ahnenforschung) und Ortsbezeichnungen angeboten.[39]

Daran anschließend werden auch über andere sprachliche Elemente wortgeschichtliche Erläuterungen geboten. Beliebt sind Entstehungs- und Herkunftsbeschreibungen von auffälligen Ausdrücken oder von Redewendungen und Sprichwörtern samt deren Erklärung.[40] Als Vorbild kann dabei fallweise sowohl in der Benennung des Titels als auch inhaltlich das diesbezügliche noch immer aufgelegte Standardwerk aus dem 19. Jahrhundert Geflügelte Worte von Georg Büchmann dienen.[41] Aber auch einzelne Wörter des Alltagsvokabulars werden auf diese Weise präsentiert.[42]

Sprachbeschreibungen, Einzelsprachen
Gerade im Bereich der allgemeinen Sprachbeschreibungen oder der Sprachtypologie sind schon seit geraumer Zeit die Grenzen zwischen Fachliteratur und Populärwissenschaft oft unscharf. Allgemein verständliche Fachbücher[43] stehen so neben fundierter Populärwissenschaft.[44] Des Weiteren wird auf das Publikationsmotiv „Klärung von populären Irrtümern“ gesetzt, das auch in anderen Fachgebieten als der Linguistik anzutreffen ist. International bekannt dafür ist z. B. der Sprachwissenschaftler Geoffrey Pullum für ein Buch über weitverbreitete Falschinformationen über Sprache im Allgemeinen und bestimmte Sprachen im Einzelnen.[45] Aber auch der Bereich der Volksetymologie ist dazu zu zählen.[42]

Psycholinguistik
Auch praxisorientierte und populärwissenschaftliche Veröffentlichungen aus dem sprachpsychologischen und psycholinguistischen Bereich nehmen einen großen Raum ein. Dabei ist besonders das Gebiet der kindlichen Sprachentwicklung – gerade auch in Hinblick auf mögliche Entwicklungsstörungen – von breitem Interesse. Das Angebot reicht von deskriptiven Darstellungen des Spracherwerbs[46] bis hin zu praktischen Ratgebern für Eltern. Die Publikationen bedienen auch fachliche Bedürfnisse von Pädagogen im Ausbildungssektor (Kindergarten, Grundschule) und sind praxisbezogen.

Fachgesellschaften
In zahlreichen Staaten gibt es linguistische Fachgesellschaften, die der Förderung sprachwissenschaftlicher Forschung und der Vernetzung und Kontaktpflege zwischen Linguisten dienen. Sie veröffentlichen Publikationen und veranstalten Fachtagungen und Kongresse.

Deutschland
Gesellschaft für deutsche Sprache (GfdS)
Gegründet: 1947; Sitz: Wiesbaden.
Institut für Deutsche Sprache (IDS)
Gegründet: 1964; Sitz: Mannheim.
Gesellschaft für Angewandte Linguistik (GAL)
Gegründet: 1968; Sitz: Bayreuth.
Deutsche Gesellschaft für Sprachwissenschaft (DGfS)
Gegründet: 1978; Sitz: Düsseldorf.
Internationale Dachverbände
Association Internationale de Linguistique Appliquée (AILA)
Gegründet: 1964; Sitz: Winterthur.
Streng von wissenschaftlichen Fachgesellschaften zu unterscheiden sind Laienorganisationen, die nicht dem wissenschaftlichen Austausch dienen, sondern sich z. B. der Sprachpflege verschrieben haben.

Siehe auch
Portal: Sprache – Übersicht zu Wikipedia-Inhalten zum Thema Sprache
Fachliteratur
Lexika und Enzyklopädien
Druckausgaben:
Johannes Bergerhausen, Siri Poarangan: DecodeUnicode: Die Schriftzeichen der Welt. Schmidt, Mainz 2011, ISBN 978-3-87439-813-8.[47]
Hadumod Bußmann (Hrsg.): Lexikon der Sprachwissenschaft. 3., aktualisierte und erweiterte Auflage, Kröner, Stuttgart 2002, ISBN 3-520-45203-0.
Rudi Conrad (Hrsg.): Kleines Wörterbuch sprachwissenschaftlicher Fachausdrücke. Dausien, Hanau 1984, ISBN 3-7684-6431-8.
David Crystal: Die Cambridge Enzyklopädie der Sprache., Campus, Frankfurt am Main/New York, NY 1993, ISBN 3-593-34824-1.
Helmut Glück (Hrsg.), unter Mitarbeit von Friederike Schmöe: Metzler Lexikon Sprache. 3., neu bearbeitete Auflage. Metzler, Stuttgart/Weimar 2005, ISBN 3-476-02056-8.
Dietrich Homberger: Sachwörterbuch zur Sprachwissenschaft. Philipp Reclam jun., Stuttgart 2003, ISBN 3-15-018241-7.
Theodor Lewandowski: Linguistisches Wörterbuch. I–III, 3. Auflage. Heidelberg 1979/1980 (= Uni-Taschenbücher, 200–201 und 300).
Onlineausgaben:
Norbert Fries: Online Lexikon Linguistik, hg. v. Christiane Fries und Norbert Fries. Onlineausgabe der Beiträge von Norbert Fries im Metzler Lexikon Sprache.
Johan Kerstens u. a. (Hrsg.): Lexicon of Linguistics Online-Lexikon auf der Website der Universität Utrecht.
Justo Fernández López: Energeia (Memento vom 3. Mai 2007 im Internet Archive), in: Lexikon der Linguistik und der Nachbardisziplinen (Memento vom 12. Oktober 2007 im Internet Archive). Online-Lexikon auf der Website der Universität Innsbruck.
Glottopedia Linguistik-Wiki.
Allgemeine Einführungen
Lehr- und Studienbücher sind u. a.:

Victoria Fromkin, Robert Rodman, Nina Hymes: An Introduction to Language. 8. Auflage. Thomson Wadsworth, Boston 2008, ISBN 978-1-4130-1773-1.
Manfred Geier: Orientierung Linguistik. Was sie kann, was sie will. Rowohlt, Reinbek bei Hamburg 1998, ISBN 3-499-55602-2.
Ludger Hoffmann: Sprachwissenschaft: Ein Reader. 3. verb. Auflage. de Gruyter, Berlin 2010, ISBN 3-11-016896-0 (ausgewählte Originaltexte).
Angelika Linke, Markus Nussbaumer, Paul R. Portmann: Studienbuch Linguistik. 5. Auflage. Niemeyer, Tübingen 2004, ISBN 3-484-31121-5.
John Lyons: Die Sprache. 4. durchges. Auflage. Beck, München 1992, ISBN 3-406-36676-7.
Horst M. Müller (Hrsg.): Arbeitsbuch Linguistik. Eine Einführung in die Sprachwissenschaft. 2. überarb. u. aktualis. Auflage. Schöningh, Paderborn 2009, ISBN 978-3-506-97007-7.
William O’Grady u. a.: Contemporary Linguistics. An Introduction. 3. Auflage. (Nachdruck). Addison-Wesley Longman, London 2007, ISBN 978-0-582-24691-1.
Heidrun Pelz: Linguistik: eine Einführung. Hoffmann und Campe, Hamburg 1996, ISBN 3-455-10331-6.
Johannes Volmert (Hrsg.): Grundkurs Sprachwissenschaft. 4. Auflage. Fink, München 2000, ISBN 3-7705-3064-0.
George Yule: The study of language. Cambridge University Press, 1996, ISBN 0-521-56851-X.
Daneben existieren zahlreiche weitere Einführungswerke

in die sprachwissenschaftlichen Ausrichtungen der einzelnen Philologien Anglistik, Romanistik, Slawistik etc.
Für die Germanistik liegen u. a. vor:
Albert Busch, Oliver Stenschke: Germanistische Linguistik. Eine Einführung. 2. durchges. u. korr. Auflage. Narr, Tübingen 2008, ISBN 978-3-8233-6414-6.
Gabriele Graefen, Martina Liedke: Germanistische Sprachwissenschaft. Deutsch als Erst-, Zweit- oder Fremdsprache 2., überarb. u. erweiterte Auflage. mit CD-ROM, (UTB 8381), A. Francke, Tübingen 2012, ISBN 978-3-8252-8491-6, Online-Ressource mit Inhaltsverzeichnis.
Wilfried Kürschner: Taschenbuch Linguistik. Ein Studienbegleiter für Germanisten. 3. durchges. Auflage. Schmidt, Berlin 2007, ISBN 978-3-503-09814-9.
Jörg Meibauer: Einführung in die germanistische Linguistik. 2. Auflage. Metzler, Stuttgart 2007, ISBN 978-3-476-02141-0.
Jakob Ossner, Heike Zinsmeister (Hrsg.): Sprachwissenschaft für das Lehramt. Ferdinand Schöningh, Paderborn 2014, ISBN 978-3-8252-4083-7.
Heinz Vater: Einführung in die Sprachwissenschaft. Wilhelm Fink Verlag, München 2002, ISBN 3-8252-1799-X.
Für die Romanistik liegen u. a. vor:
Theresa Antes: Analyse linguistique de la langue française. Yale University Press, 2006, ISBN 0-300-10944-X.
Wolf Dietrich, Horst Geckeler: Einführung in die spanische Sprachwissenschaft: Ein Lehr- und Arbeitsbuch. 5., durchges. Auflage. Erich Schmidt, Berlin 2007, ISBN 978-3-503-07995-7.
Petrea Lindenbauer, Michael Metzeltin, Margit Thir: Die romanischen Sprachen. Eine einführende Übersicht. Egert, Wilhelmsfeld 1995, ISBN 3-926972-47-5.
Andreas Wesch: Grundkurs Sprachwissenschaft Spanisch. 5. Auflage. Klett, Stuttgart 2006, ISBN 3-12-939622-5.
in die einzelnen Teilgebiete der Sprachwissenschaft sowie
in die Methodenlehre.

Albert Einstein (* 14. März 1879 in Ulm; † 18. April 1955 in Princeton, New Jersey) war ein gebürtiger deutscher Physiker mit Schweizer und US-amerikanischer Staatsbürgerschaft. Er gilt als einer der bedeutendsten theoretischen Physiker der Wissenschaftsgeschichte[1] und weltweit als einer der bekanntesten Wissenschaftler der Neuzeit.[2] Seine Forschungen zur Struktur von Materie, Raum und Zeit sowie zum Wesen der Gravitation veränderten maßgeblich das zuvor geltende newtonsche Weltbild.

Einsteins Hauptwerk, die Relativitätstheorie, machte ihn weltberühmt. Im Jahr 1905 erschien seine Arbeit mit dem Titel Zur Elektrodynamik bewegter Körper, deren Inhalt heute als spezielle Relativitätstheorie bezeichnet wird. 1915 publizierte er die allgemeine Relativitätstheorie. Auch zur Quantenphysik leistete er wesentliche Beiträge. „Für seine Verdienste um die theoretische Physik, besonders für seine Entdeckung des Gesetzes des photoelektrischen Effekts“, erhielt er den Nobelpreis des Jahres 1921, der ihm 1922 überreicht wurde. Seine theoretischen Arbeiten spielten – im Gegensatz zur weit verbreiteten Meinung – beim Bau der Atombombe und der Entwicklung der Kernenergie nur eine indirekte Rolle.[3]

Albert Einstein gilt als Inbegriff des Forschers und Genies. Er nutzte seine außerordentliche Bekanntheit auch außerhalb der naturwissenschaftlichen Fachwelt bei seinem Einsatz für Völkerverständigung, Frieden und Sozialismus.[4]


Inhaltsverzeichnis
1	Staatsangehörigkeiten
2	Leben
2.1	Kindheit und Jugend
2.1.1	Vorfahren und Elternhaus
2.1.2	München und Schulausbildung bis 1894
2.2	Schweiz 1895–1914
2.2.1	Der Weg zum Studium: Matura in Aarau
2.2.2	Studium am Polytechnikum in Zürich
2.2.3	Vom Hauslehrer zum Patentamt Bern
2.2.4	Familiäre Situation
2.2.5	Von ersten Veröffentlichungen bis zur berühmten Formel E = mc² (1905)
2.2.6	Die Schritte bis zur neuen Theorie der Gravitation
2.2.7	Professur
2.3	Berliner Jahre 1914–1932
2.3.1	Berufliche Begegnungen und familiäre Einschnitte
2.3.2	Experimentelle Bestätigung der vorherberechneten Lichtablenkung (1919)
2.3.3	Verleihung des Nobelpreises (1922)
2.3.4	Bau des „Einsteinhauses“
2.3.5	Die Konfrontation mit Niels Bohr
2.4	Princeton 1932–1955
2.4.1	Reisetätigkeit und deutsche Ausbürgerung
2.4.2	Suche nach der Weltformel
2.4.3	Private Situation im Exil
2.4.4	Einsteins Unterschrift zur Atombombe
2.4.5	Emeritierung
2.4.6	Haltung zu Deutschland
2.4.7	Sorge um den Frieden
2.4.8	Tod
3	Naturwissenschaftliche Entdeckungen und Erfindungen
3.1	Physik
3.1.1	Relativitätstheorie
3.1.2	Gegenstand des Nobelpreises
3.1.3	Quantenphysik
3.1.4	Laser
3.1.5	Bose-Einstein-Kondensation
3.1.6	Einheitliche Feldtheorie
3.2	Technik
3.2.1	Einstein-de-Haas-Effekt
3.2.2	Kreiselkompass
3.2.3	Kühlmittelpumpe
3.2.4	Katzenbuckelflügel
4	Politisches Engagement
4.1	Positionsbestimmung
4.2	Pazifismus
4.3	Zionismus
4.4	Sozialismus
4.5	Schwangerschaftsabbruch, Homosexualität und Sexualerziehung
5	Einstellung zur Religion
6	Auszeichnungen
7	Darstellung Einsteins in der bildenden Kunst (Auswahl in alphabetischer Reihenfolge der Künstler)
8	Sonstiges
8.1	Auswirkungen auf Familienangehörige
8.2	Bleibende Erinnerungen an Albert Einstein
8.3	Handschrift
9	Schriften
9.1	Werkausgabe
9.2	Wissenschaftliche Aufsätze
9.3	Andere Werke
9.4	Weitere Texte
10	Literatur
10.1	Biografien
10.2	Biografische Aspekte
11	Filmdokumentationen
12	Weblinks
13	Anmerkungen
Staatsangehörigkeiten
Einstein wird wahlweise als Deutscher, Schweizer oder US-Amerikaner bezeichnet. Im Laufe seines Lebens war Einstein Staatsbürger mehrerer Länder: Durch Geburt besaß er – wie seine Eltern – die württembergische Staatsbürgerschaft. Von 1896 bis 1901 war er staatenlos, weil er in Deutschland keinen Militärdienst leisten wollte. Ab 1901 war er bis zu seinem Tode Staatsbürger der Schweiz, 1911/1912 war er in Österreich-Ungarn auch Bürger Österreichs. Von 1914 bis 1932 lebte Einstein in Berlin und war als Bürger Preußens erneut Staatsangehöriger im Deutschen Reich. Mit der Machtergreifung Hitlers gab er 1933 den deutschen Pass endgültig ab und wurde 1934 vom Deutschen Reich strafausgebürgert. Zusätzlich zu seinem Schweizer Bürgerrecht erwarb er 1940 noch die Staatsbürgerschaft der Vereinigten Staaten.

Während seines 76-jährigen Lebens besaß Einstein somit 54 Jahre lang die Schweizer Staatsbürgerschaft (1901–1955), 36 Jahre eine deutsche Staatsangehörigkeit (1879–1896 Württemberg, 1914–1933 Preußen), 15 Jahre jene der USA (1940–1955) und 2 Jahre diejenige von Österreich-Ungarn (1911/1912). Während 5 Jahren war er staatenlos (1896–1901).

Leben
Kindheit und Jugend
Vorfahren und Elternhaus

Hermann Einstein, der Vater von Albert Einstein

Pauline Einstein, geb. Koch, die Mutter von Albert Einstein
Die Eltern Hermann Einstein und Pauline Einstein entstammten beide jüdischen Familien, die schon seit Jahrhunderten im schwäbischen Raum ansässig waren. Die Großeltern mütterlicherseits hatten ihren Nachnamen Dörzbacher in Koch geändert. Die Großeltern väterlicherseits trugen noch traditionell jüdische Vornamen, Abraham und Hindel bzw. Helene Einstein. Mit den Eltern von Albert Einstein änderte sich das. Die Großeltern väterlicherseits zogen um 1870 von Buchau nach Ulm, wo schließlich alle ihre fünf von sechs Kinder lebten, mit Ausnahme von Jakob Einstein. Der von Abraham Einstein ererbte Wohlstand erlaubte Hermann Einstein um 1870 den Kauf der Teilhaberschaft der Bettfedernfabrik Israel & Levi im Haus Weinhof 19 in Ulm und damit den Besitz der Hälfte dieses Hauses.[5]

Sein Vater Hermann Einstein stammte aus der oberschwäbischen Kleinstadt Buchau, in der es seit dem Mittelalter innerhalb des Territoriums des freiweltlichen Damenstifts Buchau eine bedeutende jüdische Gemeinde gab (siehe auch: Familie Einstein in Bad Buchau). Der erste namentlich nachgewiesene Vorfahre Albert Einsteins, ein aus dem Bodenseeraum stammender Pferde- und Tuchhändler namens Baruch Moses Ainstein, wurde im 17. Jahrhundert in die Gemeinde aufgenommen.[6] Auf den Grabsteinen des Buchauer jüdischen Friedhofs sind noch heute die Namen vieler Verwandter Einsteins zu finden, so auch der des letzten Juden der Stadt, Siegbert Einstein, eines Großneffen des Physikers, der das KZ Theresienstadt überlebt hatte und zeitweise zweiter Bürgermeister Buchaus war.

Hermann Einstein übersiedelte mit seinen Brüdern um 1869 nach Ulm. In Cannstatt bei Stuttgart heiratete er 1876 Pauline Koch. Er lebte mit ihr in Ulm im Haus Bahnhofstraße 20 (B135), wo Albert Einstein am 14. März 1879 zur Welt kam.[7] Albert wuchs in einer assimilierten, nicht strenggläubigen deutsch-jüdischen Mittelstandsfamilie heran.[8] Einstein schrieb später, kurz nach seinem 50. Geburtstag, an die Ulmer Abendpost Folgendes über seine Geburtsstadt:

„Die Stadt der Geburt hängt dem Leben als etwas ebenso Einzigartiges an wie die Herkunft von der leiblichen Mutter. Auch der Geburtsstadt verdanken wir einen Teil unseres Wesens. So gedenke ich Ulm in Dankbarkeit, da es edle künstlerische Tradition mit schlichter und gesunder Wesensart verbindet.“

– 18. März 1929[9]
Zu seiner in Ulm lebenden, nur wenig älteren Cousine Lina Einstein hielt Albert Einstein den Kontakt. 1940 wurde sie im Alter von 65 Jahren zwangsweise in das jüdische Altersheim Oberstotzingen eingewiesen. Albert Einsteins Versuche, für Lina eine Ausreisegenehmigung in die USA zu beschaffen, scheiterten. 1942 wurde Lina Einstein in das KZ Theresienstadt deportiert und im selben Jahr im Vernichtungslager Treblinka ermordet.[10]

München und Schulausbildung bis 1894
Die Familie zog kurz nach der Geburt Alberts 1880 nach München, wo sein Vater und sein Onkel im Oktober 1880 einen kleinen Betrieb zur Gas- und Wasserinstallation gründeten. Da dieser wirtschaftlich zufriedenstellend lief, beschlossen sie 1885 und mit Unterstützung der gesamten Familie, eine eigene Fabrik für elektrische Geräte (Elektrotechnische Fabrik J. Einstein & Cie) ins Leben zu rufen.[11] Die Firma seines Vaters war erfolgreich und belieferte Kraftwerke in München-Schwabing, Varese und Susa (Italien).[12] Zweieinhalb Jahre nach Albert wurde seine Schwester Maja (* 18. November 1881 in München; † 25. Juni 1951 in Princeton, New Jersey, USA) geboren. Die Familie bewohnte ein Gebäude im Hinterhof der Adlzreiterstraße 12, die heute zum Anwesen Lindwurmstraße 127 im Münchener Stadtteil Isarvorstadt gehört.


Einstein als Jugendlicher, 1893
Albert Einstein begann im Alter von drei Jahren zu sprechen. 1884 begann er mit dem Violinspiel. Erst mit zwölf machte es ihm Spaß. Es blieb ihm sein Leben lang Quelle der Inspiration, auch für physikalische Einfälle.[13] Ebenfalls ab 1884 erhielt er Privatunterricht. Im Jahr darauf kam er in die Volksschule, ab 1888 besuchte er das Luitpold-Gymnasium (nach verschiedenen Standortwechseln erhielt es 1965 den Namen Albert-Einstein-Gymnasium und ist nicht zu verwechseln mit dem heutigen Luitpold-Gymnasium in München). In der Schule war er ein aufgeweckter, bisweilen gar aufrührerischer Schüler, seine Leistungen waren gut bis sehr gut, weniger gut in den Sprachen, aber herausragend in den Naturwissenschaften. Einstein las populärwissenschaftliche Bücher und verschaffte sich einen Überblick über den Forschungsstand. Besonders die Naturwissenschaftlichen Volksbücher von Aaron Bernstein gelten als prägend für sein Interesse und seine weitere Laufbahn.[14] Hierzu zählt auch[15] die Schrift von Felix Eberty Die Gestirne und die Weltgeschichte. Gedanken über Raum, Zeit und Ewigkeit,[16] zu deren Neuauflage im Jahr 1923 Einstein ein Geleitwort schrieb.[17]

Die Firma des Vaters und des geliebten Onkels wurde geschlossen und die Familie zog 1894 nach Mailand. Der zu diesem Zeitpunkt fünfzehnjährige Albert sollte bis zum Abitur am Luitpold-Gymnasium bleiben, wurde jedoch von einem seiner Lehrer herabgesetzt und geriet mit dem von Zucht und Ordnung geprägten Schulsystem des Deutschen Kaiserreiches in Konflikt – damit ging er allerdings offen um. Lehrer warfen ihm vor, dass seine Respektlosigkeit auf Mitschüler abfärbe. Trotzig entschloss sich Einstein Ende 1894, die Schule ohne Abschluss zu verlassen und seiner Familie nach Mailand zu folgen. Ein weiteres Motiv war offensichtlich, sich der Wehrpflicht zu entziehen. Wäre Einstein bis zum Alter von 17 Jahren in Deutschland geblieben, wäre er wehrpflichtig geworden – eine Aussicht, die ihn schreckte.[18]

Schweiz 1895–1914
Der Weg zum Studium: Matura in Aarau

Einsteins Maturazeugnis; in der Schweiz ist die „6“ die beste und die „1“ die schlechteste Note
Im Frühjahr und Sommer 1895 hielt sich Einstein in Pavia auf, wo seine Eltern vorübergehend lebten, und half in der Firma mit. Er machte Ausflüge in die Alpen und zum Apennin und besuchte seinen Onkel Julius Koch in Genua. In dieser Zeit schrieb der 16-jährige Einstein seine erste wissenschaftliche Arbeit, ein Essay mit dem Titel Über die Untersuchung des Ätherzustandes im magnetischen Felde,[19] und schickte sie seinem in Belgien lebenden Onkel Caesar Koch (1854–1941) zur Begutachtung. Die Arbeit wurde nie als wissenschaftlicher Beitrag in einer Zeitschrift veröffentlicht und blieb in der Form eines Diskussionsbeitrages.[20]


Denkmal an der Stelle von Einsteins Geburtshaus in Ulm

Einsteins Wohnhaus in Aarau
Dem Wunsch seines Vaters, er möge Elektrotechnik studieren, kam Einstein nicht nach. Stattdessen folgte er dem Hinweis eines Freundes der Familie und bewarb sich um einen Studienplatz an der eidgenössisch polytechnischen Schule in Zürich, der heutigen ETH Zürich. Da er noch kein Abitur beziehungsweise keine schweizerische Matura hatte, legte er auf Vermittlung von Gustav Maier im Oktober 1895 eine Aufnahmeprüfung ab,[21] die er – als jüngster Teilnehmer aller Zeiten mit 16 Jahren – jedoch nicht bestand. Er meisterte den naturwissenschaftlichen Teil mit Bravour und scheiterte an mangelnden Französischkenntnissen. Am Gewerbeinstitut Berlin, der späteren TH Berlin, wurde zu dieser Zeit ebenfalls ein Abitur als Zugangsberechtigung verlangt.

Auf Vermittlung seines Mentors Gustav Maier und des ebenfalls von ihm überzeugten Maschinenbauprofessors Albin Herzog besuchte er anschließend die Gewerbeschule an der liberal geführten aargauischen Kantonsschule in der Schweiz, um dort die Matura nachzuholen. Während dieser Zeit in Aarau kam er bei der Familie Winteler unter. Er zog dort im Oktober 1895 für ein Jahr ein; bald begann eine Liaison mit der zwei Jahre älteren Marie Winteler.[22] Anfang 1896 wurde Einstein auf Antrag seines Vaters aus der württembergischen und somit auch der deutschen Staatsbürgerschaft entlassen.[23] Er ließ sich als keiner Religionsgemeinschaft zugehörig eintragen. Die nächsten fünf Jahre blieb er staatenlos.

Auf Einsteins am 3. Oktober 1896 ausgestelltem Zeugnis der „Maturitätsprüfung“ stand fünfmal die bestmögliche Schulnote, in der Schweiz eine Sechs. Die schlechteste Note war eine Drei in Französisch. Das Gerücht, dass Einstein allgemein ein schlechter Schüler war, ist falsch: Es geht auf Einsteins ersten Biografen zurück, der das Benotungssystem der Schweiz mit dem deutschen verwechselte.[24][25]

Studium am Polytechnikum in Zürich

Publikation von Einsteins Fachlehrerdiplom
Nachdem Einstein die Matura an der Kantonsschule Aarau nachgeholt hatte, nahm er mit Beginn des akademischen Jahres 1896 sein Studium an der Schule für Fachlehrer des Eidgenössischen Polytechnikums Zürich (heute ETH Zürich) auf.[20]

Es lag Einstein nicht, nur formales Wissen auswendig zu lernen, vielmehr regten ihn theoretisch-physikalische Denkprojekte an. Mit seiner Eigenwilligkeit eckte er oftmals an. Ihm war die abstrakte mathematische Ausbildung ein Dorn im Auge, er erachtete sie als für den problemorientierten Physiker hinderlich. In den Vorlesungen fiel er dem lehrenden Professor vor allem durch seine Abwesenheit auf. Für die Prüfungen verließ er sich auf die Mitschriften seiner Kommilitonen. Diese Ignoranz verstellte ihm nicht nur Karrierechancen an seiner Hochschule, er bereute sie spätestens bei der Entwicklung der mathematisch höchst anspruchsvollen allgemeinen Relativitätstheorie. Sein Studienkollege Marcel Grossmann war ihm später dabei noch von großer Hilfe.

Einstein verließ die Hochschule 1900 mit einem Diplom als Fachlehrer in mathematischer Richtung, worunter auch die Physik fiel. Seine Diplomarbeit in Physik fertigte er bei Heinrich Friedrich Weber an. Es gelang ihm aber nicht, nach dem Studium eine Anstellung als Assistent am Polytechnikum zu erhalten.

Vom Hauslehrer zum Patentamt Bern

Akademie Olympia – Habicht, Solovine und Einstein, 1903
Seine Bewerbungen auf Assistentenstellen am Polytechnikum und anderen Universitäten wurden abschlägig beschieden. Er arbeitete als Aushilfslehrer am Technikum in Winterthur sowie als Hauslehrer in Schaffhausen und schließlich in Bern. 1901 wurde seinem Antrag auf die Schweizer Staatsangehörigkeit stattgegeben. Am 16. Juni 1902 erhielt Einstein, auf Empfehlung seines Freundes Marcel Grossmann, eine feste Anstellung: als technischer Experte 3. Klasse beim Schweizer Patentamt in Bern.

Während der Probezeit am Patentamt begannen seine regelmäßigen Treffen mit dem Philosophiestudenten Maurice Solovine und dem Mathematikstudenten Conrad Habicht, die als Akademie Olympia bezeichnet wurden und 1904 endeten.[26]

Familiäre Situation

Mileva Marić und Albert Einstein, 1912
Während des Studiums hatte Einstein seine Kommilitonin und spätere Ehefrau, Mileva Marić aus Novi Sad, kennengelernt. Nach dem Tod seines Vaters Ende 1902 heirateten die beiden am 6. Januar 1903 in Bern – gegen den Willen der Familien. Mit Marić hatte Einstein eine Tochter und zwei Söhne, Hans Albert (1904–1973) und Eduard (1910–1965). Die Tochter Lieserl war 1902 vor der Eheschließung bei den Eltern von Marić in Novi Sad geboren und starb entweder früh oder wurde 1903 zur Adoption nach Belgrad gegeben.[27] Das Schicksal des Kindes ist trotz intensiver Suche unbekannt. Die Existenz ihrer gemeinsamen Tochter wurde selbst vor den Freunden verschwiegen. Erst 1987 wurde durch die Veröffentlichung der Briefe Einsteins an Marić aus den Jahren 1897 bis 1903 bekannt, dass vor der Eheschließung die gemeinsame Tochter geboren worden war. Die Ehe wurde 1919 geschieden.[28][29]

Von Oktober 1903 bis Mai 1905 wohnten Einstein und Marić in der Berner Altstadt an der Kramgasse 49, dem heutigen Einsteinhaus Bern, in dem ein Museum untergebracht ist.

Von ersten Veröffentlichungen bis zur berühmten Formel E = mc² (1905)
→ Hauptartikel: Geschichte der speziellen Relativitätstheorie

Einsteins Dissertation, 1905

Albert Einstein auf einer deutschen Sonderbriefmarke zum Jahr der Physik 2005
Im Jahr 1905, im Alter von 26 Jahren, veröffentlichte Einstein fünf seiner wichtigsten Werke:

Am 17. März 1905 beendete er seine Arbeiten zum photoelektrischen Effekt, die er anschließend als Über einen die Erzeugung und Verwandlung des Lichts betreffenden heuristischen Gesichtspunkt[30] publizierte.
Am 30. April 1905 stellte er seine Dissertation Eine neue Bestimmung der Moleküldimensionen fertig,[31] mit der er am 20. Juli an der Universität Zürich bei den Professoren Alfred Kleiner und Heinrich Burkhardt sein Promotionsgesuch einreichte. Er wählte die Universität Zürich, da dort aufgrund eines Abkommens mit dem Polytechnikum, an dem Einstein studiert hatte, das Rigorosum (mündliche Prüfung) entfiel. In seiner Dissertation berechnete er die Größe von Zuckermolekülen in Lösung und daraus einen Wert für die Avogadro-Konstante. Sie steht in Zusammenhang mit seiner im gleichen Jahr erschienenen Arbeit über die Brownsche Molekularbewegung und stützte die damals bei führenden Physikern (Wilhelm Ostwald, Ernst Mach) noch umstrittene Atomhypothese. Die Arbeit wurde von Burkhardt und Kleiner relativ schnell akzeptiert (im Juli wurde das Promotionsverfahren abgeschlossen). Paul Drude, der Herausgeber der Annalen der Physik, an den Einstein die Arbeit geschickt hatte, war jedoch mit dem gefundenen Wert für die Avogadro-Konstante nicht zufrieden und verlangte Nachbesserungen, die Einstein auch lieferte.[32] Das führte zu einer halbjährigen Verzögerung der Publikation und Einstein wurde deshalb erst am 15. Januar 1906 formal promoviert. Vier Jahre später (1909), als Jean Perrins Versuche bekannt wurden, wandte sich Einstein an Perrin mit der Bitte um experimentelle Überprüfung, und gleichzeitig fand Ludwig Hopf, den Einstein um Überprüfung seiner Dissertation gebeten hatte, einen Fehler in seiner Dissertation, der das Ergebnis verfälscht hatte. Einstein schickte daraufhin 1911 eine Berichtigung an die Annalen.[33]
Am 11. Mai 1905 folgte seine Publikation zur brownschen Molekularbewegung: Über die von der molekularkinetischen Theorie der Wärme geforderte Bewegung von in ruhenden Flüssigkeiten suspendierten Teilchen.[34]
Am 30. Juni 1905 reichte Einstein seine Abhandlung Zur Elektrodynamik bewegter Körper ein.[35] Kurz darauf lieferte Einstein seinen Nachtrag Ist die Trägheit eines Körpers von seinem Energieinhalt abhängig?[36] Letzterer enthält implizit zum ersten Mal die wohl berühmteste Formel der Welt, E = mc² (Energie ist gleich Masse mal Lichtgeschwindigkeit zum Quadrat, Äquivalenz von Masse und Energie). Beide Arbeiten zusammen werden heute als spezielle Relativitätstheorie bezeichnet.
Das Jahr 1905 war somit ein äußerst fruchtbares Jahr, man spricht auch vom Annus mirabilis (Wunderjahr). Carl Friedrich von Weizsäcker schrieb dazu später:

„1905 eine Explosion von Genie. Vier Publikationen über verschiedene Themen, deren jede, wie man heute sagt, nobelpreiswürdig ist: die spezielle Relativitätstheorie, die Lichtquantenhypothese, die Bestätigung des molekularen Aufbaus der Materie durch die ‚brownsche Bewegung‘, die quantentheoretische Erklärung der spezifischen Wärme fester Körper.“

– Carl Friedrich von Weizsäcker[37]
Die Schritte bis zur neuen Theorie der Gravitation
Als Einstein 1907 den langen Weg von der speziellen zur allgemeinen Relativitätstheorie antrat, war er noch ein weithin unbekannter Angestellter im Berner Patentamt. Am Ende des Weges, 1915, war er ein in Fachkreisen schon hochangesehener Professor in Berlin, der, wie Max Planck später sagte, nur „an den Leistungen Johannes Keplers und Isaac Newtons gemessen“ werden könne.[38]

Der Weg zur allgemeinen Relativitätstheorie begann 1907 zum einen mit dem Geistesblitz, den Einstein als „den glücklichsten Gedanken meines Lebens“[39] bezeichnete, zum anderen mit einer Einschränkung seiner bisherigen Arbeiten zur Relativität, die grundsätzlicher Natur war. Die Letztere war die Einsicht, dass die Lichtgeschwindigkeit unter dem Einfluss der Gravitation keine Konstante ist, die spezielle Relativitätstheorie demnach nur unter der Bedingung gültig sein konnte, dass keine Schwerkraft vorhanden sei, wie Einstein in einem Aufsatz von 1911 wiederholte: „Die Relativitätstheorie hat ergeben, daß die träge Masse eines Körpers mit dem Energieinhalt desselben wächst. (…) Das so befriedigende Resultat der Relativitätstheorie, nach dem der Satz von der Erhaltung der Masse in dem Satz von der Erhaltung der Energie aufgeht, wäre nicht aufrecht zu erhalten.“[40]

Der Geistesblitz dagegen betraf die Äquivalenz zwischen träger und schwerer Masse, also die Übereinstimmung der konstanten Beschleunigung eines Bezugssystems und der Schwerkraft: „Ich saß auf meinem Sessel im Berner Patentamt, als mir plötzlich folgender Gedanke kam: ‚Wenn sich eine Person im freien Fall befindet, dann spürt sie ihr eigenes Gewicht nicht‘. Ich war verblüfft. Dieser einfache Gedanke machte auf mich einen tiefen Eindruck. Er trieb mich in Richtung einer Theorie der Gravitation.“[41]

Bis zur ersten Schrift, in der dieser Geistesblitz zu einer näheren physikalischen Formulierung führte, sollten allerdings noch über drei Jahre vergehen, denn „Einstein äußerte sich vom Dezember 1907 bis zum Juni 1911 (…) nicht über Fragen der Gravitation“, so sein Freund und Biograph Abraham Pais.[42]

Im Jahr 1908 kam es aber zu einer bahnbrechenden Neuerung, der Einstein zunächst skeptisch gegenüberstand und die er sogar als „überflüssige Gelehrsamkeit“[43] abtat: der mathematischen Formulierung der Raumzeit durch seinen ehemaligen Lehrer Hermann Minkowski, dessen Urheberschaft dieser revolutionären Konzeption später von Einstein ausdrücklich anerkannt und gewürdigt wurde.[44]

Im Minkowski-Raum kann das relative Verhältnis der Größen von Raum und Zeit in der speziellen Relativitätstheorie durch die Setzung einer imaginären Zeiteinheit anschaulich als Drehung dargestellt werden. Erst 1912 ließ sich Einstein von den Vorzügen des Minkowski-Raums überzeugen.

Einige der wichtigsten Aufsätze der späteren allgemeinen Relativitätstheorie im Überblick:

Über das Relativitätsprinzip und die aus demselben gezogenen Folgerungen.
Über den Einfluß der Schwerkraft auf die Ausbreitung des Lichtes. Noch gemäß dem Huygensschen Prinzip stellt Einstein hier nur eine Abweichung der Lichtstrahlen von Fixsternen in der Nähe der Sonne von 0,83 Bogensekunden fest,[45] der nach den Feldgleichungen von 1915 errechnete Wert lag bei 1,7 Bogensekunden.[46]
Entwurf einer verallgemeinerten Relativitätstheorie und einer Theorie der Gravitation. I. Physikalischer Teil von Albert Einstein. II. Mathematischer Teil von Marcel Grossmann.[47]
Nordströmsche Gravitationstheorie vom Standpunkt des allgemeinen Differentialkalküls. Mit A. D. Fokker.[48] Eine Reaktion auf Gunnar Nordströms alternative Gravitationstheorie und eine „Publikation, die für die Geschichte der allgemeinen Relativität von beträchtlichem Interesse ist, weil sie Einsteins erste Behandlung der Gravitationstheorie darstellt, in der die allgemeine Kovarianz streng gültig ist“.[49]
Zur allgemeinen Relativitätstheorie. 4. November 1915.
Da die noch konventionelle Definition des Abstands im flachen (nicht gekrümmten) Minkowski-Raum nicht gleichermaßen in der gekrümmten Raumzeit gilt, musste sie dort durch einen abstrakteren Ausdruck ersetzt werden, wie auch eine Geometrie erforderlich war, mit der die Flächentheorie von Gauß auf gekrümmte Räume in vier Dimensionen erweitert werden konnte. Einsteins damalige mathematische Kenntnisse reichten dafür nicht aus, und so wandte er sich 1912 an seinen ehemaligen Kommilitonen Marcel Grossmann, der nun in Zürich Professor für Mathematik war. Einstein habe „ihn gebeten, in der Bibliothek nachzusehen, ob es eine geeignete Theorie zur Behandlung derartiger Fragen gäbe. Am nächsten Tag sei Grossmann gekommen (…) und habe gesagt, es gebe tatsächlich eine derartige Geometrie, nämlich die Riemannsche Geometrie.“[50]

In der Folge suchte Grossmann nicht nur die Arbeiten von Riemann hervor, sondern auch jene von Christoffel, Ricci und dessen Schüler Levi-Civita, die mit den Forschungen zum absoluten Differentialkalkül in gekrümmten Räumen, der Formulierung der Christoffelsymbole zur Tensoranalysis und der kovarianten Ableitung teils bereits im 19., teils erst im 20. Jahrhundert das mathematische Instrumentarium entwickelt hatten, das sich nun zur Formulierung der allgemeinen Relativitätstheorie als unverzichtbar erwies.[51][52]

Es dauerte aber noch etwa drei Jahre, um den Gedanken eines Gravitationsfeldes, in dem die Metrik des vierdimensionalen, gekrümmten raumzeitlichen Kontinuums und die Faktoren der Energie und des Impulses sich wechselseitig bedingen, in eine Formel zu fassen, was Einstein am 4. November 1915 gelang.

Professur

Denkmal in Prag in der Nähe des Jan-Hus-Platzes
Einsteins Antrag auf Habilitation 1907 an der Berner Universität wurde zunächst, da er seine Habilitationsschrift nicht miteingereicht hatte,[53] abgelehnt, erst im folgenden Jahr war er damit erfolgreich. 1909 berief man ihn zum Dozenten[54] für theoretische Physik an der Universität Zürich, bald zum außerordentlichen Professor. Im Januar 1911 wurde er, wie Unterrichtsminister Stürgkh kundmachte, von Kaiser Franz Joseph I. zum ordentlichen Professor der theoretischen Physik an der deutschen Universität Prag ernannt.[55] Damit wurde er österreichischer Staatsbürger.[56] Im Oktober 1912 kehrte er nach Zürich zurück, um an der Eidgenössischen Technischen Hochschule zu forschen und zu lehren; er kehrte also als Professor an seinen Studienort zurück.[57] Einstein empfand ein Leben lang Zürich als seine Heimatstadt und die Schweiz als das Land, dem er zugewandt war.[58]

Berliner Jahre 1914–1932

Berliner Gedenktafel am Haus Ehrenbergstraße 33 in Berlin-Dahlem
Berufliche Begegnungen und familiäre Einschnitte
1913 gelang es Max Planck, Einstein als hauptamtlich besoldetes Mitglied für die Preußische Akademie der Wissenschaften in Berlin zu gewinnen, wo er im April 1914 eintraf. Seine Frau kam mit den Kindern nach, kehrte jedoch alsbald wegen privater Differenzen nach Zürich zurück, weil Einstein sie dazu nötigte.[59] Einstein erhielt die Lehrberechtigung an der Berliner Universität, aber ohne Verpflichtung dazu. Von allen Lehrtätigkeiten befreit, fand Einstein in Berlin Zeit und Ruhe, sein großes Werk, die allgemeine Relativitätstheorie, zu Ende zu bringen. Er konnte sie 1916, zusammen mit einer Arbeit über den Einstein-de-Haas-Effekt, veröffentlichen. Am 1. Oktober 1917 wurde er Direktor des Kaiser-Wilhelm-Instituts für Physik und blieb in dieser Position bis 1933. Von 1923 bis 1933 war Einstein auch Mitglied des Senats der Kaiser-Wilhelm-Gesellschaft.


Elsa Löwenthal und Albert Einstein, um 1921

Einstein eröffnet die Funkausstellung in Berlin 1930
Zwischen 1917 und 1920 pflegte seine Cousine Elsa Löwenthal (geb. Einstein; 1876–1936) den kränkelnden Einstein. Infolgedessen zog Einstein 1917 förmlich in der Haberlandstr. 5 in Elsas Wohnung ein. Als Albert Einstein 1918 einen Ruf aus Zürich erhielt, entschied er sich wegen der ausgezeichneten Wissenschaftlerkontakte dafür, in Berlin zu bleiben, obwohl er im Sommerurlaub 1918 betonte, dass Zürich seine „wirkliche Heimat“ sei und die Schweiz das Land, dem er allein mit seiner Neigung zugetan sei.[60] 1919 lotete Einstein ein Angebot aus Zürich aus, offenbar um in Berlin Bleibegelder zu erwirken. Fritz Haber besorgt diese Gelder.[61]

Einstein ließ sich Anfang 1919 von Mileva scheiden, wenig später, am 2. Juni 1919, heiratete er Elsa.[62] Sie brachte zwei Töchter mit in die Ehe. Jene Zeit war mit weiteren Einschnitten verbunden: Die politische Situation nach Ende des Ersten Weltkrieges verhinderte den Kontakt zu seinen Söhnen in der Schweiz. Anfang 1919 erkrankte Einsteins Mutter Elsa Einstein erneut schwer an Krebs. Einstein holte sie Ende 1919 zu sich nach Berlin. Sie stirbt am 20. Februar 1920 in seinem Arbeitszimmer.[63] Außerdem gelang es Kurt Blumenfeld gerade jetzt, Einstein für den Zionismus zu interessieren. Vollends für den Zionismus gewann Einstein 1921 Chaim Weizmann, der ihn zu einer Reise in die USA überredete, auf der Einstein Spenden für die Hebrew University in Jerusalem warb.[64]

Die Berliner Jahre waren auch durch einen regen Kontakt zu Max Wertheimer, dem Begründer der Gestalttheorie, gekennzeichnet. Es kam zu einem fruchtbaren Austausch zwischen den beiden Wissenschaftlern. So verfasste Einstein beispielsweise eine Einleitung zu Wertheimers Aufsätzen über Wahrheit, Freiheit, Demokratie und Ethik. Zunehmend begann er, sich auch politischen Fragestellungen zu öffnen (siehe hierzu den Abschnitt Politisches Engagement).

Zusammen mit Leopold Infeld gehörte er zu den häufigen Besuchern der Familie der Antonie „Toni“ Mendel († 1956), der Tante und Schwiegermutter von Bruno Mendel, mit der er eine enge Freundschaft pflegte. Diese hatte er etwa Anfang der 1920er Jahre über die gemeinsame Mitgliedschaft im pazifistischen Bund Neues Vaterland kennengelernt.[65]

Experimentelle Bestätigung der vorherberechneten Lichtablenkung (1919)
Während der Sonnenfinsternis vom 29. Mai 1919 bestätigten Beobachtungen Arthur Eddingtons, dass die Ablenkung des Lichts eines Sterns durch das Schwerefeld der Sonne näher an dem von der allgemeinen Relativitätstheorie vorhergesagten Wert lag als an dem der newtonschen Korpuskeltheorie. Joseph John Thomson, Präsident der Royal Society, kommentierte den Befund wie folgt:

„Dieses Resultat ist eine der größten Errungenschaften des menschlichen Denkens.“[66]

Die experimentelle Bestätigung der damals kurios anmutenden Vorhersage Einsteins machte weltweit Schlagzeilen. Die plötzliche Bekanntheit sorgte fortan dafür, dass sich Einsteins Vorträge größter Beliebtheit erfreuten. Jeder wollte den berühmten Wissenschaftler in persona erleben. In den Jahren von 1920 bis 1924 entstand auf Initiative von Erwin Freundlich, einem langjährigen Mitstreiter, der Einsteinturm in Potsdam. Er diente seither astronomischen Beobachtungen, nicht zuletzt zu dem Zweck, Einsteins Theorie weiteren Überprüfungen zu unterziehen.

Verleihung des Nobelpreises (1922)
Der Nobelpreis für Physik des Jahres 1921 wurde erst am 9. November 1922 vergeben: an Albert Einstein „für seine Verdienste um die theoretische Physik, besonders für seine Entdeckung des Gesetzes des photoelektrischen Effekts“.[67] Einstein hatte sich am 7. Oktober in Marseille zu einer Vortragsreise nach Japan eingeschifft, wo er am 17. November eintraf, und konnte deshalb an der Verleihungszeremonie in Stockholm am 10. Dezember 1922 nicht teilnehmen.[68][69][70] Dort übernahm es der Gesandte des Deutschen Reiches Rudolf Nadolny, „seinen Preis aus den Händen S. M. des Königs zu empfangen“ und beim abendlichen Bankett im Grand Hôtel Stockholm „auch in seinem Namen“ Dankesworte zu sprechen.[71][72] Das Preisgeld überließ Einstein, wie es in der Scheidungsurkunde bereits festgelegt worden war, Mileva Marić und ihren gemeinsamen Söhnen[73].

Bau des „Einsteinhauses“

Sommerhaus von Albert Einstein in Caputh bei Potsdam
Anlässlich Einsteins 50. Geburtstag im Jahr 1929 sah sich die Stadt Berlin gefordert, ihrem berühmten Bürger ein angemessenes Geschenk zu überreichen. Oberbürgermeister Gustav Böß regte an, ihm ein Haus zu vermachen. Die Presse griff die Geschichte auf. Mit der Zeit weitete sich die Diskussion jedoch zu einer offenen Kontroverse aus. Einstein und Elsa, mittlerweile auf der Suche nach einem geeigneten Grundstück in der Waldstraße 7 im Dorf Caputh bei Potsdam fündig geworden, verzichteten kurzerhand auf das Geschenk und finanzierten das heute Einsteinhaus genannte Haus aus eigener Tasche. Der Architekt Konrad Wachsmann wurde beauftragt, das zweistöckige Holzhaus am Hang oberhalb des Sees zu errichten. Es wurden teilweise vorgefertigte Holzelemente verwendet.[74] Das Sommerhaus in Caputh war der Ausgangspunkt für viele Touren mit dem Segelboot während der Sommermonate bis 1932. Dieses Boot (ein Geburtstagsgeschenk von Freunden) war ein „20er Jollenkreuzer“ mit dem Namen Tümmler, der 1933 mit Einsteins übrigem Besitz von den Nationalsozialisten konfisziert wurde.[75]

Die Konfrontation mit Niels Bohr
1930 konfrontierte Albert Einstein Niels Bohr bei der sechsten Solvay-Konferenz überraschend mit seinem Gedankenexperiment der Photonenwaage, mit dem er die Unvollständigkeit der Quantentheorie belegen wollte. Nur einen Tag später konnte Bohr zusammen mit Pauli und Heisenberg Einstein unter Hinzuziehen von Überlegungen aus der allgemeinen Relativitätstheorie jedoch widerlegen.

Princeton 1932–1955
Reisetätigkeit und deutsche Ausbürgerung
Seine zunehmende Bekanntheit nutzte Einstein für etliche Reisen: Mit Genehmigung des preußischen Kultusministeriums hielt er Vorlesungen auf der ganzen Welt. 1921 unternahm er seine erste Reise in die USA mit mehrmonatigem Aufenthalt.[76] Zahlreiche Ehrendoktorwürden wurden ihm zuteil, darunter die der Princeton University, wo er später lehrte. Alsbald plante er, fortan die Hälfte des Jahres in Princeton, New Jersey, die andere in Berlin zu verbringen. In Berlin war er wegen seiner pazifistischen Haltung zunehmend zum Gegenstand politischer Debatten geworden. Im Dezember 1932 reiste er erneut nach Pasadena (Kalifornien). Einstein reiste nach der Machtübernahme des NS-Regimes (30. Januar 1933) im März/April 1933 nach Europa; er gab in der deutschen Botschaft in Brüssel seinen Reisepass zurück.[77]

Der Preußischen Akademie der Wissenschaften, der er 19 Jahre lang angehört hatte, teilte er am 28. März 1933 schriftlich (mit Bedauern) seinen Austritt mit und würdigte die Anregungen und menschlichen Beziehungen dort. Damit kam er einem Ausschluss zuvor, der sich nach der Veröffentlichung einer nicht für die Presse bestimmten pazifistischen Erklärung abzeichnete.[78] Ferner waren zu dieser Zeit bereits zwei weitere Unterzeichner des gegen die Machtübernahme des NS-Regimes gerichteten Dringenden Appells (Heinrich Mann und Käthe Kollwitz) zum Verlassen der Akademie gezwungen worden. Am 20. März hatte man Einsteins Haus in Caputh durchsucht, im April auch seine Stadtwohnung in der Berliner Haberlandstraße 5 (heute Neubau, Nr. 8). Am 4. April 1933 stellte Einstein einen Antrag auf Ausbürgerung (Entlassung aus dem preußischen Staatsverbund). Ein vierseitiger Brief vom 28. März 1933 an Einsteins Schwester Maja, in dem Einstein und seine Gattin ihren Wunsch nach Ausbürgerung mitteilen, wurde im Jahre 2018 versteigert.[79] Der Antrag wurde abgelehnt; ihm wurde die Staatsangehörigkeit per Strafausbürgerung (am 24. März 1934) aberkannt, und er wurde auf die zweite Ausbürgerungsliste des Deutschen Reichs gesetzt.[80]

Am 8. April 1933 wandte sich die Bayerische Akademie der Wissenschaften an ihn und bat ihn um eine Erklärung bezüglich seiner Haltung zur Bayerischen Akademie, in die er 1927 als korrespondierendes Mitglied aufgenommen worden war. Einstein antwortete am 21. April aus dem belgischen Ferienort De Haan, die Gründe für sein Ausscheiden aus der Preußischen Akademie würden an und für sich nicht eine Lösung seiner Beziehungen zur Bayerischen Akademie bedingen. Dennoch wünsche er, aus der Mitgliederliste gestrichen zu werden. Die Deutsche Akademie der Naturforscher Leopoldina hatte Einstein bereits Anfang 1933 mit einem Bleistifteintrag in ihren Matrikelbüchern als Mitglied gestrichen.[81] Am 10. Mai 1933 proklamierte der Propagandaminister Joseph Goebbels: „Jüdischer Intellektualismus ist tot“[82] und ließ im Rahmen der öffentlichen Verbrennung „undeutschen Schrifttums“ symbolisch auch Schriften von Einstein verbrennen. Einstein fand auch heraus, dass sein Name auf einer Attentatsliste mit Kopfgeld von 5000 Dollar stand.[82] Eine deutsche Zeitschrift setzte seinen Namen auf eine Liste der Feinde der deutschen Nation mit dem Kommentar: „noch nicht gehängt“.[82]

Suche nach der Weltformel
1933 wurde Einstein Mitglied des Institute for Advanced Study, eines kurz zuvor in der Nähe der Princeton University gegründeten privaten Forschungsinstituts. Es gelang ihm, fast seinen gesamten Besitz, darunter seinen Flügel, von Berlin nach Princeton transportieren zu lassen, weil Frankreichs Botschafter André François-Poncet ihn als Diplomatengepäck nach Frankreich bringen ließ.[83] Vom August 1935 bis zu seinem Tod lebte Einstein im Haus Mercer Street 112 in Princeton. Es war das erste eigene Haus, das ganzjährig bewohnbar war, das Albert und Elsa Einstein besaßen.[84] Die Stadt Princeton bildete damals einen Mikrokosmos der modernen Forschung. Einstein befasste sich bald mit der Suche nach einer einheitlichen Feldtheorie, die seine Feldtheorie der Gravitation (die allgemeine Relativitätstheorie) mit der des Elektromagnetismus vereinigen sollte. Bis zu seinem Tode mühte er sich vergeblich, eine Weltformel zu finden – was bis heute auch keinem anderen Forscher gelungen ist.

Private Situation im Exil

Einwanderungsurkunde von Januar 1936

Am 1. Oktober 1940 erhielt Einstein von Richter Phillip Forman die amerikanische Einbürgerungsurkunde
Seine letzte Auslandsreise außerhalb der USA nach seiner Übersiedlung dorthin unternahm Einstein 1935 auf die zu Großbritannien gehörenden Bermudainseln, ein Zwangsaufenthalt aus formalen Gründen, da er damals noch nicht US-Staatsbürger war.[85]

Im Jahr 1936 starb Einsteins Ehefrau Elsa. 1939 kam seine Schwester Maja nach Princeton, allerdings ohne ihren Mann Paul, der keine Einreisegenehmigung erhalten hatte. Sie wohnte bis zu ihrem Tod 1951 bei ihrem Bruder.

Im Jahr 1938 half er zusammen mit Thomas Mann dem Schriftsteller Hermann Broch, der im zuvor „angeschlossenen“ Österreich kurze Zeit inhaftiert worden war, ebenfalls in die Vereinigten Staaten zu emigrieren. Beide blieben im Exil miteinander befreundet. Wie diesem verhalf Einstein auch seinem Caputher Architekten Konrad Wachsmann und zahlreichen weiteren bedrohten jüdischen Künstlern und Wissenschaftlern durch Empfehlungsschreiben und Gutachten zur Ausreise aus Deutschland und zur Einreise in die USA.[86]

Am 15. Dezember 1938 trat er aus der Accademia Nazionale dei Lincei in Rom aus, nachdem diese zuvor alle 27 jüdischen italienischen Mitglieder ausgeschlossen hatte.[87]

Am 1. Oktober 1940 erhielt Einstein die US-amerikanische Staatsbürgerschaft. Die schweizerische Staatsbürgerschaft (Bürgerort Zürich) behielt er zeitlebens.

Einsteins Unterschrift zur Atombombe
Die Entdeckung der Kernspaltung im Dezember 1938 durch Otto Hahn und Fritz Straßmann in Berlin beschwor in der Wissenschaftsgemeinde die Erkenntnis einer nuklearen Bedrohung herauf. Im August 1939, kurz vor Beginn des Zweiten Weltkriegs, unterzeichnete Einstein einen von Leó Szilárd verfassten Brief[88] an den amerikanischen Präsidenten Franklin D. Roosevelt, der vor der Gefahr einer „Bombe neuen Typs“ warnte, die Deutschland möglicherweise entwickle und gar bald besitzen könne.[89] Angesichts von Geheimdienstberichten um entsprechende deutsche Anstrengungen fand der Appell Gehör, und zusätzliche Forschungsgelder wurden bereitgestellt: Das Manhattan-Projekt mit dem erklärten Ziel der Entwicklung einer Atombombe war aus der Taufe gehoben.

In seinen Memoiren vertritt Einstein die Auffassung, dass er sich zu leichtfertig von der Notwendigkeit der Unterzeichnung dieses Briefes überzeugen ließ. Am 16. November 1954 sagte er zu seinem Freund Linus Pauling:

“I made one great mistake in my life — when I signed the letter to President Roosevelt recommending that atom bombs be made; but there was some justification — the danger that the Germans would make them.”

„Ich habe einen schweren Fehler in meinem Leben gemacht – als ich den Brief an Präsident Roosevelt mit der Empfehlung zum Bau von Atombomben unterzeichnete; aber es gab eine gewisse Rechtfertigung dafür – die Gefahr, dass die Deutschen welche bauen würden.“

– Albert Einstein: Aufzeichnung Linus Paulings[90]
An den Arbeiten war Einstein jedoch gänzlich unbeteiligt. Er wurde zwar von Vannevar Bush im Dezember 1941 zu einem Problem, das in Zusammenhang mit der Isotopentrennung stand, um Rat gefragt, wurde aber für das FBI und offizielle Stellen in Washington unter anderem wegen seiner unverhüllten Sympathien für den Kommunismus als Sicherheitsrisiko eingestuft und von den US-amerikanischen Geheimdiensten beobachtet. Er durfte deshalb nicht näher in technische Einzelheiten des Manhattan-Projekts eingeweiht werden und durfte sogar offiziell keine Kenntnis der Existenz des streng geheimen Projekts erhalten. Er war aber an einer Zusammenarbeit mit dem US-Militär interessiert und beriet ab Mai 1943 die US-Navy über Sprengstoffe und Torpedos.[91] Als Beitrag zu den Kriegsanstrengungen stiftete er sein Originalmanuskript über die spezielle Relativitätstheorie von 1905, das in Kansas City im Februar 1944 für 6,5 Millionen US-Dollar versteigert wurde, die in Kriegsanleihen der USA investiert wurden.

1945 trat Leó Szilárd erneut an ihn heran, diesmal zur Verhinderung des Einsatzes von Atomwaffen nach der Kapitulation Deutschlands, und Einstein schrieb ein wegen Roosevelts Tod folgenlos gebliebenes Empfehlungsschreiben für Szilárd an den Präsidenten, damit Szilárd bei diesem seine Bedenken vortragen konnte. Nach dem Abwurf der Atombombe wurde Einstein, der zunächst schwieg, zur Stellungnahme gedrängt, nachdem sein Schreiben an Roosevelt von 1939 durch den Smyth Report bekannt geworden war. In einem Interview mit einem Journalisten der New York Times sprach er sich im September 1945 für eine Weltregierung aus, um künftig Kriege zu verhüten, kam darauf auch im Rahmen einer Nobel-Gedenkrede im Dezember 1946 in New York zurück und engagierte sich in dem von Szilárd ins Leben gerufenen Emergency Committee of Atomic Scientists, setzte sein Engagement für internationale Rüstungskontrolle aber auch nach dessen Ende 1948 fort. Über seine eigene Beteiligung bei der Initiierung des Manhattan-Projekts urteilte er im März 1947 in einem Newsweek-Interview, dass er dies nicht getan hätte, wenn er vom geringen Fortschritt der Deutschen in deren Atombombenprojekt gewusst hätte, und dass die Entwicklung im Übrigen auch ohne ihn erfolgt wäre.[92]

Emeritierung

Albert Einstein und Robert Oppenheimer, um 1950
Nach dem Krieg prägte sich der Öffentlichkeit das Bild des alten, sich nachlässig kleidenden Professors in Princeton ein. Er wurde häufig um Stellungnahmen ersucht und von hohen Staatsgästen besucht wie Jawaharlal Nehru. Auch nach seiner Emeritierung 1946 arbeitete er weiter mit Assistenten am Institute for Advanced Study an seiner Vereinheitlichten Feldtheorie. Seine letzten Jahre waren durch den Tod seiner Schwester Maja 1951 und anderer Freunde getrübt. Im Mai 1953 nahm er in einem in der New York Times veröffentlichten Brief gegen die McCarthy-Ausschüsse Stellung und rief zur Aussageverweigerung auf. 1954 unterstützte er Robert Oppenheimer in dessen Sicherheitsanhörungen.

Haltung zu Deutschland
Die von Deutschen betriebene Vernichtung der Juden während der Zeit des Nationalsozialismus war für Einstein der Grund dafür, die gegenüber Arnold Sommerfeld im Dezember 1945 brieflich bekundete allgemeine Ablehnung bis zu seinem Lebensende aufrecht zu erhalten: „Nachdem die Deutschen meine jüdischen Brüder in Europa hingemordet haben, will ich nichts mehr mit Deutschen zu tun haben, auch nichts mit einer relativ harmlosen Akademie.“[93] Er fügte auf Sommerfeld und einige andere bezogen hinzu: „Anders ist es mit den paar Einzelnen, die in dem Bereich der Möglichkeit standhaft geblieben sind.“[94]

Auch Jahre nach dem Krieg sah er kein ausgeprägtes Reue- oder Schuldgefühl in Deutschland und vermied weiter jegliche Einlassung mit den dortigen öffentlichen Institutionen. Ein Ansinnen von Otto Hahn, Mitglied der Max-Planck-Gesellschaft zu werden, wies er brüsk mit ebenso deutlichen Worten zurück wie jenes von Sommerfeld, ihn wieder in die Bayerische Akademie der Wissenschaften aufzunehmen, oder das von Theodor Heuss bezüglich des Ordens Pour le Mérite. Er wollte auch nicht, dass seine Bücher künftig in Deutschland erscheinen.[95] Auf die Nachricht, dass sein Freund Max Born zurück nach Deutschland ziehen wollte, reagierte er mit Unverständnis. Seine Abneigung gegen Deutschland übertrug er allerdings nicht generell auf einzelne Personen oder Kollegen, insbesondere nicht, wenn sie wie Sommerfeld, Max Planck und Max von Laue Distanz zu den Nationalsozialisten bewahrt hatten.[96]

Sorge um den Frieden
Trotz seiner Gebrechen fand er auch noch kurz vor seinem Tod die nötige Kraft, um für seine Vision vom Weltfrieden einzutreten. So unterzeichnete er am 11. April 1955 zusammen mit zehn weiteren namhaften Wissenschaftlern das sogenannte Russell-Einstein-Manifest zur Sensibilisierung der Menschen für die Abrüstung.[97] Die letzten Notizen von Einstein betreffen eine Rede, die er zum Jahrestag der israelischen Unabhängigkeit halten wollte. An dem Entwurf arbeitete er noch am 13. April 1955 zusammen mit dem israelischen Konsul. Am Nachmittag desselben Tages brach Einstein zusammen und wurde zwei Tage später ins Princeton Hospital gebracht.[97]

Tod
Einstein starb am 18. April 1955 im Alter von 76 Jahren in Princeton an inneren Blutungen, die durch die Ruptur eines Aortenaneurysmas verursacht worden waren. Einstein lehnte die (seinerzeit experimentelle) operative Behandlung ab, mit den Worten:

“I want to go when I want. It is tasteless to prolong life artificially. I have done my share; it is time to go. I will do it elegantly.”

„Ich werde gehen, wenn ich möchte. Es ist geschmacklos, das Leben künstlich zu verlängern. Ich habe meinen Teil getan; es ist Zeit zu gehen. Ich werde dies elegant tun.“

– J. R. Cohen, L. M. Graver: The ruptured abdominal aortic aneurysm of Albert Einstein. In: Surgery, Gynecology & Obstetrics. Band 170, Nr. 5, Mai 1990, ISSN 0039-6087, S. 455–458, PMID 2183375 (nih.gov [abgerufen am 17. Oktober 2021]).
An dem Aneurysma hatte Einstein schon seit Jahren gelitten. Es wurde bei einer Laparotomie Ende 1948 entdeckt und stabilisiert[98], nachdem sich Einstein immer wieder über Bauchschmerzen beklagt hatte. Aufgrund von Gesundheitsproblemen hatte er schon seit Ende der 1940er Jahre Princeton kaum noch verlassen.[99] Die Nachtschwester Alberta Rozsel des Princeton Hospital war bei Einstein, als er starb. Sie berichtete, dass er kurz vor seinem Tod etwas auf Deutsch gemurmelt habe.[100] Der Pathologe Thomas Harvey nahm nach der Obduktion das Gehirn und die Augen von Albert Einstein an sich. Seine Intention war vor allem, das Gehirn für weitere Untersuchungen seiner womöglich einzigartigen Struktur der Nachwelt zu erhalten. Die Hinterbliebenen gaben ihm rückwirkend ihre Einwilligung dazu. Der größte Teil des Gehirns befindet sich heute konserviert im National Museum of Health and Medicine in Chicago, die Augen in New York. Einsteins Wunsch entsprechend, wurde sein Körper verbrannt und die Asche an einem unbekannten Ort verstreut.[101]

Naturwissenschaftliche Entdeckungen und Erfindungen
Physik
Relativitätstheorie
Albert Einstein begründete die physikalische Relativitätstheorie, die er (nach wichtigen Vorarbeiten von Hendrik Antoon Lorentz und Henri Poincaré) 1905 als spezielle Relativitätstheorie und erstmals 1915 als allgemeine Relativitätstheorie veröffentlichte. Einsteins Werke führten zu einer Revolution der Physik; die spezielle und die allgemeine Relativitätstheorie gehören bis heute zu den Grundpfeilern der modernen Physik. Zur einfacheren Formulierung führte er 1916 die einsteinsche Summenkonvention ein, durch die Tensorprodukte kompakter geschrieben werden können.

Gegenstand des Nobelpreises

Nobelpreis 1921, am 10. Dezember 1922 überreicht

Einsteins Vorlesung am 11. Juli 1923 in Göteborg
Einstein war ab 1910 mit zunehmender Häufigkeit für den Nobelpreis vorgeschlagen worden, besonders auch ab 1919 nach der öffentlichen Sensation der richtigen Vorhersage der Lichtablenkung durch Gravitation. Das stieß im Nobelpreiskomitee aber auf anhaltenden Widerstand, der auch dazu führte, dass der Preis für das Jahr 1921 nicht termingerecht vergeben wurde, sondern erst ein Jahr später zusammen mit dem Preis für 1922. Viele Mitglieder des Nobelpreiskomitees neigten eher zur Experimentalphysik als zur theoretischen Physik und beargwöhnten die theoretischen Entwicklungen zur Quantennatur des Lichts und zu den beiden Relativitätstheorien als zu spekulativ. Während Einsteins Gesetz des photoelektrischen Effekts inzwischen durch Messungen belegt war, wurde die 1919 von Arthur Stanley Eddington bei Sonnenfinsternisbeobachtungen berichtete Beobachtung einer von der allgemeinen Relativitätstheorie vorhergesagten Ablenkung des Lichts von Sternen nahe der Sonne (Gravitationslinseneffekt) wegen mangelnder Messgenauigkeit weiter bezweifelt. Besonders Allvar Gullstrand, der auch verschiedene Fehler in Einsteins Theorien gefunden zu haben glaubte, verhinderte entgegen stärkster internationaler Befürwortung noch 1921 die Nominierung Einsteins.

So erhielt Einstein zwar den für das Jahr 1921 bestimmten Physik-Nobelpreis, aber erst ein Jahr später und dabei weder für eine seiner Relativitätstheorien noch für die Lichtquantenhypothese, mit der er das Gesetz des photoelektrischen Effekts gefunden hatte, sondern lediglich für die Entdeckung dieses Gesetzes.[102][103] Für seine Nobelpreisrede erhielt er die Auflage, sich nicht zur Relativitätstheorie zu äußern. Wegen eines Aufenthalts in Japan nahm Einstein nicht am offiziellen Staatsakt im Dezember 1922 teil, sondern nahm den Preis am 11. Juli 1923 auf der 17. Nordischen Naturforscherversammlung (17:e Skandinaviska Naturforskarmötet) in Göteborg entgegen und hielt – zum Gefallen des anwesenden schwedischen Königs und weiterer tausend Zuhörer – seine Rede mit dem Titel Grundgedanken und Probleme der Relativitätstheorie.[104][105] Antisemitische Physiker aus Deutschland, darunter Philipp Lenard, der Nobelpreisträger 1905, hatten zuvor noch vergeblich protestiert.

Quantenphysik

Albert Einstein mit Niels Bohr 1930 in Brüssel,
Fotografie von Paul Ehrenfest

Von Robert Berks geschaffene Statue Einsteins im Hof der Israelischen Akademie der Wissenschaften
Bemerkenswert ist Einsteins Verhältnis zu einem weiteren Pfeiler der modernen Physik, der Quantenphysik: einerseits, weil einiges von seiner Arbeit, wie die Erklärung des photoelektrischen Effekts, deren Grundlage bildete; andererseits, weil er später viele Ideen und Deutungen der Quantenmechanik ablehnte. Eine berühmte Diskussion verbindet Einstein mit dem Physiker Niels Bohr. Gegenstand war die unterschiedliche Auslegung der neuen Quantentheorie, die Heisenberg, Schrödinger und Dirac ab 1925 entwickelten. Einstein stand insbesondere dem Begriff der Komplementarität Bohrs kritisch gegenüber.

Einstein glaubte, dass die zufälligen Elemente der Quantentheorie sich später als nicht wirklich zufällig beweisen lassen würden. Diese Einstellung veranlasste ihn, erstmals im Streit mit Max Born, zu der berühmt gewordenen Aussage, dass der Alte (bzw. Herrgott) nicht würfle:[106]

„Die Quantenmechanik ist sehr achtunggebietend. Aber eine innere Stimme sagt mir, daß das noch nicht der wahre Jakob ist. Die Theorie liefert viel, aber dem Geheimnis des Alten bringt sie uns kaum näher. Jedenfalls bin ich überzeugt, daß der Alte nicht würfelt.“

Er stützte seine Überlegungen mit verschiedenen Gedankenexperimenten, unter anderem mit dem viel diskutierten Einstein-Podolsky-Rosen-Experiment oder mit der Photonenwaage. Im Diskurs jedoch blieben Bohr und seine Anhänger zumeist siegreich; auch aus heutiger Sicht sprechen die experimentellen Belege gegen Einsteins Standpunkt.

Laser
1916 postulierte er die stimulierte Emission von Licht.[107] Dieser quantenmechanische Vorgang ist die physikalische Grundlage des Lasers, der erst 1960 – also nach seinem Tod – erfunden wurde. Neben dem Transistor zählt der Laser zu den bedeutendsten technischen Erfindungen des 20. Jahrhunderts, die auf die Quantenphysik zurückgehen.

Bose-Einstein-Kondensation
1924 sagte er zusammen mit Satyendranath Bose einen quantenmechanischen, aber dennoch makroskopischen Materiezustand voraus, der bei extrem tiefen Temperaturen eintreten sollte. Der später als Bose-Einstein-Kondensation bezeichnete Phasenübergang konnte 1995 erstmals im Labor beobachtet werden. Im August 2005 wurde an der Universität Leiden ein 16-seitiges Manuskript von Einstein entdeckt, das sich mit seiner letzten großen Entdeckung, der Bose-Einstein-Kondensation, beschäftigt.

Einheitliche Feldtheorie
In seinen späten Jahren beschäftigte sich Einstein mit der Frage nach einer einheitlichen Feldtheorie aller Naturkräfte auf Grundlage seiner allgemeinen Relativitätstheorie; ein Unterfangen, das allerdings nicht von Erfolg gekrönt war und noch heute ungelöst ist.

Häufig wird Einstein als einer derjenigen genannt, die einen hypothetischen Äther ablehnten und abschaffen wollten; das war jedoch nur einschränkend der Fall, wie in einer seiner Reden deutlich wird, gehalten am 5. Mai 1920 an der Reichs-Universität zu Leiden:

„Zusammenfassend können wir sagen: Nach der allgemeinen Relativitätstheorie ist der Raum mit physikalischen Qualitäten ausgestattet; es existiert also in diesem Sinne ein Äther. Gemäß der allgemeinen Relativitätstheorie ist ein Raum ohne Äther undenkbar; denn in einem solchen gäbe es nicht nur keine Lichtfortpflanzung, sondern auch keine Existenzmöglichkeit von Maßstäben und Uhren, also auch keine räumlich-zeitlichen Entfernungen im Sinne der Physik. Dieser Äther darf aber nicht mit der für ponderable Medien charakteristischen Eigenschaft ausgestattet gedacht werden, aus durch die Zeit verfolgbaren Teilen zu bestehen; der Bewegungsbegriff darf auf ihn nicht angewendet werden.“[108]

Einstein lässt im Sinne dieser Zusammenfassung weiterhin nur einen von der Elektrodynamik unabhängigen, gravitativen Äther zu, nicht jedoch den elektromagnetischen Äther des 19. Jahrhunderts mit seinen erforderlichen Bewegungszuständen, die – wie schon 1905 – nach wie vor ausdrücklich ausgeschlossen werden. Diese Tatsache kommt in der oft zitierten Rede von 1920, etwas vor obiger Zusammenfassung, ebenfalls deutlich zum Ausdruck.[109]

„Betrachten wir das Gravitationsfeld und das elektromagnetische Feld vom Standpunkt der Ätherhypothese, so besteht zwischen beiden ein bemerkenswerter prinzipieller Unterschied. Kein Raum und auch kein Teil des Raumes ohne Gravitationspotentiale; denn diese verleihen ihm seine metrischen Eigenschaften, ohne die er überhaupt nicht gedacht werden kann. Die Existenz des Gravitationsfeldes ist an die Existenz des Raumes unmittelbar gebunden. Dagegen kann ein Raumteil sehr wohl ohne elektromagnetisches Feld gedacht werden.“

Siehe auch:

Einheitliche Feldtheorie
Äther (Physik), insbesondere Gravitationsäther
Einsteinsche Summenkonvention
Einsteinkoeffizienten
Technik
Einstein ist als theoretischer Physiker weltberühmt. Einem umfassenden Bild seiner wissenschaftlichen Persönlichkeit fehlt aber eine Facette, wenn man seine Leistungen als Experimentalphysiker und Ingenieur nicht berücksichtigt.

Einstein-de-Haas-Effekt
1915 führte Einstein zusammen mit Wander Johannes de Haas ein schwieriges Experiment durch. Durch den heute als Einstein-de-Haas-Effekt bekannten Effekt bestimmte er indirekt das gyromagnetische Verhältnis oder den Landé-Faktor des Elektrons. Da damals der Spin noch nicht bekannt war, glaubte man, der Ferromagnetismus beruhe auf dem Umlauf der Elektronen um den Atomkern (ampèresche Molekularströme), was einen Landé-Faktor von 1 bedeutet hätte. Die Schwierigkeit des Experiments verursachte größere statistische und systematische Fehler; jedoch kam eine Messreihe dem vorhergesagten Wert 1 sehr nahe und wurde von Einstein und de Haas als experimenteller Nachweis des Modells angesehen und veröffentlicht. Spätere Experimente mit höherer Genauigkeit zeigen jedoch, dass sich ein Landé-Faktor von ungefähr 2 ergibt, wie er nicht für den Umlauf des Elektrons, sondern für seinen Spin gilt. Dies zeigt, dass der Ferromagnetismus nicht vom Bahndrehimpuls der Elektronen herrührt.

Kreiselkompass
Zur Technik des Kreiselkompasses trug Einstein durch seine Erfindungen der elektrodynamischen Lagerung und des elektrodynamischen Antriebs für die Kreisel bei. Einschlägige Fachkenntnisse hatte Einstein erworben, als er 1914 in einer patentrechtlichen Auseinandersetzung zwischen Hermann Anschütz-Kaempfe und Elmer Ambrose Sperry als Gutachter bestellt worden war. Mechanische Kreiselkompasse werden auch heute noch mit Einsteins patentierter Technik gebaut.

Kühlmittelpumpe

Der Einstein-Kühlschrank
Es wird berichtet, dass Einstein und sein Kollege Leó Szilárd durch ein tragisches Unglück mit den damals üblichen giftigen Kältemitteln motiviert wurden, im Hinblick auf sichere Kühlschränke zu forschen. Eines der von Einstein und Szilárd angemeldeten Patente betraf eine elektrodynamische Pumpe für ein leitendes Kältemittel. In den Vereinigten Staaten erhielten beide für den Kühlschrank das US-Patent Nummer 1.781.541 am 11. November 1930 zugebilligt.[110] Obwohl Einstein mehrere seiner Patente verkaufen konnte, unter anderem an AEG und Electrolux, wurden seine Kühlschränke nie gebaut, da 1929 das Kältemittel Freon eingeführt wurde und somit die einsteinschen Patente mit einem Schlag obsolet waren. An einer Stelle hat Einsteins Erfindung dennoch überlebt: Die Pumpen für das Kühlmittel in schnellen Brutreaktoren, nämlich für flüssiges Natrium, werden immer noch nach Einsteins Prinzip konstruiert.

Katzenbuckelflügel
Vermutlich angeregt durch Ludwig Hopf beschäftigte sich Einstein zu Beginn des Ersten Weltkrieges mit den Strömungseigenschaften von Flugzeugtragflächen und entwarf um 1916 ein Tragflächenprofil, bei dem er durch Verzicht auf den Anstellwinkel den Luftwiderstand verringern wollte. In dem Zusammenhang veröffentlichte er im August 1916 die Arbeit Elementare Theorie der Wasserwellen und des Fluges. Die Luftverkehrsgesellschaft in Berlin-Johannisthal setzte Einsteins Konstruktionsvorschläge um, und die Tragflächen wurden aufgrund ihrer wenig eleganten Form als Katzenbuckelflügel bezeichnet. Ein Testflug zeigte dann jedoch, dass die Konstruktion aufgrund ihrer schlechten Flugeigenschaften unbrauchbar war. Der Testpilot Paul G. Ehrhardt hatte große Mühe gehabt, das Flugzeug wieder zu landen und bezeichnete es als eine „schwangere Ente“. Einstein selbst war später, wohl auch im Hinblick auf mögliche militärische Anwendungen, froh, dass sich seine Vorschläge als unbrauchbar erwiesen hatten, und schämte sich seiner „Narretei aus jenen Tagen“.[111][112][113][114]

Politisches Engagement
Positionsbestimmung
Einstein empfand bereits als Neunzehnjähriger während der Ära des Wilhelminismus zum ausgehenden 19. Jahrhundert solchen Abscheu vor dem Militarismus und der Autoritätshörigkeit in der Gesellschaft des Kaiserreichs, dass er seine deutsche Staatsbürgerschaft ablegte.[115]

Der Beginn des Ersten Weltkrieges bewirkte eine intensive Beschäftigung mit politischen Problemen. Einstein trat dem Bund Neues Vaterland (der späteren Deutschen Liga für Menschenrechte) bei und unterstützte dessen Forderungen nach einem baldigen, gerechten Frieden ohne Gebietsforderungen und der Schaffung einer internationalen Organisation, die künftige Kriege verhindern sollte. An seinen Kollegen Paul Ehrenfest schrieb er 1914:

„Die internationale Katastrophe lastet schwer auf mir internationalem Menschen. Man begreift schwer beim Erleben dieser «großen Zeit», daß man dieser verrückten, verkommenen Spezies angehört, die sich Willensfreiheit zuschreibt. Wenn es doch irgendwo eine Insel der Wohlwollenden und Besonnenen gäbe! Da wollte ich auch glühender Patriot sein.“[116]

1918 gehörte Albert Einstein zu den Unterzeichnern des Aufrufs zur Gründung der linksliberalen Deutschen Demokratischen Partei (DDP). Später trat er jedoch nicht mehr öffentlich für diese Partei auf, dafür näherte er sich immer stärker einem humanistisch geprägten sozialistischen Gedankengut an. Im Verlauf der Weimarer Republik engagierte er sich weiterhin in der Deutschen Liga für Menschenrechte, in der er sich für politische Gefangene einsetzte. In diesem Zusammenhang arbeitete er auch zeitweilig für die kommunistisch dominierte Rote Hilfe.

Als Aushängeschild Deutschlands wird Einstein zusammen mit Max Planck am 28. Juni 1931 in die Reichskanzlei eingeladen, als es darum ging, den englischen Premierminister Ramsay MacDonald gewogen zu stimmen. In einem Brief vom 3. Oktober 1931 an Reichskanzler Brüning wirbt Einstein für die strukturelle Nichtangriffsfähigkeit Deutschlands gegenüber Frankreich, allerdings ohne Erfolg, weil Brüning die Verständigungspolitik gegenüber Frankreich nicht mehr betrieb.[117]

1932 trat er als Unterzeichner des Dringenden Appells zusammen mit Heinrich Mann, Ernst Toller, Käthe Kollwitz, Arnold Zweig und anderen für ein antifaschistisches Linksbündnis aus SPD, KPD und Gewerkschaften ein, um den Untergang der Weimarer Republik und die drohende Herrschaft des Nationalsozialismus noch zu verhindern.

Pazifismus
Nachdem Einstein bereits während des Ersten Weltkriegs durch seine kriegsablehnende Position aufgefallen war, war er von 1922 an Mitglied der Kommission für geistige Zusammenarbeit beim damaligen Völkerbund, auf deren Anregung hin er später über die Frage Warum Krieg? mit Sigmund Freud im September 1932 in einen Briefwechsel trat, der 1933 veröffentlicht wurde. Überhaupt griff er immer wieder zum Mittel des Briefschreibens, um Wirkung zu erzielen:

Im Mai 1931 beispielsweise machte er gemeinsam mit Heinrich Mann in einem offenen Brief an die New York Times auf die Ermordung des kroatischen Intellektuellen Milan Šufflay aufmerksam.[118] 1935 beteiligte er sich an der (erfolgreichen) internationalen Kampagne für die Verleihung des Friedensnobelpreises an den im KZ einsitzenden Carl von Ossietzky; 1953 forderte er in einem öffentlichen Brief die Verteidigung der Bürgerrechte gegenüber dem McCarthy-Ausschuss ein.

Anfang März 1933 überließ er während eines Aufenthaltes in den USA der Liga zur Bekämpfung des Antisemitismus eine nach seiner eigenen Aussage nicht für die Presse bestimmte Erklärung, die große Aufmerksamkeit in der internationalen Presse nach sich zog. Darin schrieb er:

„Solange mir eine Möglichkeit offensteht, werde ich mich nur in einem Land aufhalten, in dem politische Freiheit, Toleranz und Gleichheit aller Bürger vor dem Gesetz herrschen. Zur politischen Freiheit gehören die Freiheit der mündlichen und schriftlichen Äußerung politischer Überzeugung, zur Toleranz die Achtung vor jeglicher Überzeugung eines Individuums. Diese Bedingungen sind gegenwärtig in Deutschland nicht erfüllt. … Ich hoffe, daß in Deutschland bald gesunde Verhältnisse eintreten werden und daß dort in Zukunft die großen Männer wie Kant und Goethe nicht nur von Zeit zu Zeit gefeiert werden, sondern daß sich auch die von ihnen gelehrten Grundsätze im öffentlichen Leben und im allgemeinen Bewußtsein durchsetzen.“[87]

Gleichzeitig modifizierte er seine pazifistische Haltung:

„Bis 1933 habe ich mich für die Verweigerung des Militärdienstes eingesetzt. Als aber der Faschismus aufkam, erkannte ich, dass dieser Standpunkt nicht aufrechtzuerhalten war, wenn nicht die Macht der Welt in die Hände der schlimmsten Feinde der Menschheit geraten soll. Gegen organisierte Macht gibt es nur organisierte Macht; ich sehe kein anderes Mittel, so sehr ich es auch bedaure.“[119]

Auch der Brief an Präsident Franklin D. Roosevelt, der der Entwicklung der Atombombe vorausging, entsprang dieser Haltung:

„Ich glaubte, wir müssten die Möglichkeit Deutschlands vermeiden, unter Hitler im alleinigen Besitz dieser Waffe zu sein. Das war die wirkliche Gefahr dieser Zeit.“[120]

Entsprechend engagierte er sich nach der Niederlage NS-Deutschlands vielfältig für internationale Rüstungskontrolle und Zusammenarbeit im Sinne des Titels einer Rede, die er 1945 bei einem Nobel-Gedenkdinner in New York hielt: The war is won, but peace is not. So rief er ein Emergency Committee of Atomic Scientists ins Leben und schlug die Bildung einer Weltregierung vor.

Einstein stand auch Gewalt gegenüber Tieren ablehnend gegenüber und sympathisierte mit der Idee des Vegetarismus. Vermutlich ernährte er sich aber erst gegen Ende seines Lebens selbst vegetarisch.[121][122]

Zionismus

Einstein zusammen mit führenden Vertretern des Zionismus (zweiter von links: Chaim Weizmann), 1921

Einstein bei seinem einzigen Besuch des Technions in Haifa, Februar 1923

Israelische 5-Pfund-Banknote
Bei der Berufung zur Karls-Universität Prag (1911) bezeichnete sich Einstein zunächst als „konfessionslos“. Erst auf Druck der österreichisch-ungarischen Verwaltung zur Erklärung seiner Glaubensrichtung bekannte er sich als Angehöriger des Judentums. Später zeigte Einstein jedoch, betroffen von der Lage osteuropäischer jüdischer Flüchtlinge nach dem Ersten Weltkrieg, ein vermehrtes Engagement für einen Staat Israel. Dokumentiert ist 1918 seine Teilnahme an einem vorläufigen Komitee zur Vorbereitung eines jüdischen Kongresses in Deutschland. Zu jener Zeit erlebte das Deutsche Reich bereits eine zunehmende Durchdringung mit Antisemitismus.

Er unterstützte weitgehend die zionistischen Ideale, ohne jedoch jemals einer zionistischen Organisation beizutreten. Nachdem er zunächst als Jugendlicher aus der jüdischen Religionsgemeinschaft ausgetreten war, wurde er 1924 Mitglied der jüdischen Gemeinde in Berlin, wobei er dies jedoch nicht aus religiösen Gründen tat, sondern um seine Solidarität mit dem Judentum zu demonstrieren.[123] Sein Name ist außerdem stark mit der Hebräischen Universität in Jerusalem verbunden. Seine erste USA-Reise diente unter anderem dem Zweck, Spenden für eine solche Universität zu sammeln. 1923 reiste er zur Grundsteinlegung in das damalige Palästina – während dieser Reise wurde ihm auch die erste Ehrenbürgerschaft der Stadt Tel Aviv verliehen. 1925 wurde er zum Mitglied des Verwaltungsrats der Universität berufen. Schließlich verfügte Einstein in seinem Testament die Übereignung seines schriftlichen Nachlasses an die Hebräische Universität.

Einsteins Beziehung zum Judentum war offenbar nicht religiöser Natur. So schrieb er 1946:

„Obgleich ich so etwas wie ein jüdischer Heiliger bin, habe ich seit so langer Zeit keine Synagoge mehr besucht, dass ich fürchten muss, Gott würde mich nicht mehr erkennen. Wenn er es aber täte, wäre es wohl schlimmer.“[124]

Als Menachem Begin kurz nach der Unabhängigkeit des Staates Israel New York besuchte, um dort für seine neugegründete Cherut-Partei Spenden zu sammeln, gehörte Albert Einstein am 4. Dezember 1948 zu den Unterzeichnern eines Leserbriefes an die New York Times, der in scharfen Formulierungen vor der Cherut-Partei (die 1973 im heutigen Likud aufging) warnte.[125]

Nach dem Tod Chaim Weizmanns erhielt Einstein 1952 das Angebot, der zweite Staatspräsident des neu gegründeten Staates Israel zu werden, was er aber ablehnte.[126]

Im Dezember 1982 erhielt die Hebräische Universität in Jerusalem das Privatarchiv Albert Einsteins. Das Material stammt aus der Zeit von 1901 bis 1955 und umfasst 50.000 Seiten und bis 1982 rund 33 unveröffentlichte Manuskripte.

Sozialismus
Einstein verfasste 1949 seinen wenig bekannten Essay Why Socialism? („Warum Sozialismus?“),[127] in dem er seine politische Einstellung darlegte: Obwohl er einräumt, kein Experte auf dem Gebiet der Wirtschaft zu sein, hält er eine Stellungnahme für statthaft:

„[…] wir sollten nicht davon ausgehen, dass Experten die einzigen sind, die ein Recht darauf haben, sich zu Fragen zu äußern, die die Organisation der Gesellschaft betreffen.“

Er betonte die Abhängigkeit des Einzelnen von der Gesellschaft und die Möglichkeit, die Gesellschaft zu gestalten:

„Das Gedächtnis, die Kapazität, Neues zu versuchen und die Möglichkeit, mündlich zu kommunizieren haben für den Menschen Entwicklungen möglich gemacht, die nicht von biologischen Gegebenheiten diktiert wurden. Solche Entwicklungen manifestieren sich in Traditionen, Institutionen und Organisationen, in der Literatur, in wissenschaftlichen und technischen Errungenschaften, in künstlerischen Arbeiten. Das erklärt, weshalb der Mensch in einem gewissen Sinne sein Leben selbst beeinflussen kann und dass in diesem Prozess bewusstes Denken und Wollen eine Rolle spielt.“

Am Kapitalismus kritisierte er, dass er der Gesellschaft in ihren Bedürfnissen an die Wirtschaft nicht gerecht werde:

„Die Produktion ist für den Profit da – nicht für den Bedarf. Es gibt keine Vorsorge dafür, dass all jene, die fähig und bereit sind zu arbeiten, immer Arbeit finden können.“

Dies habe Einfluss bis hinein ins Bildungssystem:

„Unbegrenzte Konkurrenz führt zu einer riesigen Verschwendung von Arbeit und zu dieser Lähmung des sozialen Bewusstseins von Individuen, die ich zuvor erwähnt habe. Diese Lähmung der Einzelnen halte ich für das größte Übel des Kapitalismus. Unser ganzes Bildungssystem leidet darunter. Dem Studenten wird ein übertriebenes Konkurrenzstreben eingetrichtert und er wird dazu ausgebildet, raffgierigen Erfolg als Vorbereitung für seine zukünftige Karriere anzusehen […] Nach meiner Überzeugung gibt es nur einen Weg zur Beseitigung dieser schweren Übel, nämlich die Etablierung der sozialistischen Wirtschaft, vereint mit einer auf soziale Ziele eingestellten Erziehung: Die Arbeitsmittel werden Eigentum der Gesellschaft und werden von dieser planwirtschaftlich verwendet.“

Er forderte aber auch, dass der erstrebte Sozialismus die Rechte des Individuums respektieren müsse:

„Eine Planwirtschaft als solche kann mit der totalen Versklavung des Individuums einhergehen. Sozialismus erfordert die Lösung einiger äußerst schwieriger sozio-politischer Probleme: Wie ist es angesichts weitreichender Zentralisierung politischer und ökonomischer Kräfte möglich, eine Bürokratie daran zu hindern, allmächtig und maßlos zu werden? Wie können die Rechte des Einzelnen geschützt und dadurch ein demokratisches Gegengewicht zur Bürokratie gesichert werden? […] Klarheit über die Ziele und Probleme des Sozialismus ist für unsere Zeit des Überganges von größter Bedeutung. Leider ist bei dem jetzigen Zustand der Gesellschaft die freie Diskussion dieser Dinge durch ein mächtiges Tabu erschwert.“

Damit warf er auch Fragen auf, die im Ostblock ihre Aktualität zeigten (Stalinismus). Anders als bei seinen anderen Idealen blieb eine solche Diskussion zu Zeiten des Kalten Krieges im Westen unbeachtet, weshalb der Text außerhalb sozialistischer Kreise kaum Verbreitung fand. In den USA wurde Einstein wegen seiner politischen Ansichten vom FBI überwacht.[128] Agenten hörten nicht nur sein Telefon ab und sahen seine Post ein, sondern durchsuchten auch seinen Müll. Die FBI-Akte mit sog. „belastenden Informationen“ gegen Einstein umfasst insgesamt 1800 Seiten.[129]

Einstein war Mitglied der Gesellschaft der Freunde des neuen Rußland, die die Freundschaft zwischen Deutschland und der Sowjetunion propagierte. Außerdem war er Ehrenpräsident der Sowjetisch-deutschen Gesellschaft „Kultur und Technik“.[130]

Schwangerschaftsabbruch, Homosexualität und Sexualerziehung
Die Neue Generation, Organ des Deutschen Bundes für Mutterschutz, zitierte 1929 einen Brief Einsteins vom 6. September 1929 an die Weltliga für Sexualreform, Institut für Sexualwissenschaft, Berlin:

„Ich verfüge nicht über eine so reiche menschliche Erfahrung, daß ich berechtigt wäre, mich zu diesen schwierigen sozialen Fragen öffentlich zu äußern. Das Gefühl einer gewissen Sicherheit habe ich nur in folgendem Punkt: Abtreibung bis zu einem gewissen Stadium der Schwangerschaft soll auf Wunsch der Frau erlaubt sein. Homosexualität sollte bis auf den notwendigen Schutz Jugendlicher straffrei sein. Bezüglich der Sexualerziehung keine Geheimniskrämerei.“[131][132][133]

Später gehörte Einstein zu den Unterstützern oder Sympathisanten eines Komitees für Selbstbezichtigung gegen § 218, siehe Schwangerschaftsabbruch#Erste Hälfte 20. Jahrhundert.

Einstellung zur Religion
Einstein entstammt einer jüdischen Familie. Bei seiner Verzichtserklärung auf die deutsche Staatsbürgerschaft im Jahre 1896 vermerkte sein Vater jedoch, vermutlich auf seinen Wunsch, „keine religiöse Zugehörigkeit“, was er in den folgenden zwei Jahrzehnten mehrmals wiederholte.[134]

Bis ins 21. Jahrhundert gibt es verschiedene Interpretationen zu Einsteins Haltung zur Religion, da er sich vielfach widersprüchlich äußerte, unter anderem mit dem Aphorismus: „Wissenschaft ohne Religion ist lahm, Religion ohne Wissenschaft ist blind.“[135] Im Jahre 2008 wurde jedoch ein bis dahin in Privatbesitz befindlicher Brief von Einstein an den Esoteriker Erich Gutkind veröffentlicht, den er am 3. Januar 1954 verfasst hatte. In diesem bezieht sich Einstein auf seine nichtreligiöse Haltung.[136] Er distanziert sich dabei mit deutlichen Worten von der biblischen Vorstellung eines persönlichen Gottes, die er als „kindlichen Aberglauben“ bezeichnet:

„Das Wort Gott ist für mich nichts als Ausdruck und Produkt menschlicher Schwächen, die Bibel eine Sammlung ehrwürdiger, aber doch reichlich primitiver Legenden.“

„Für mich ist die unverfälschte jüdische Religion wie alle anderen Religionen eine Inkarnation des primitiven Aberglaubens. Und das jüdische Volk, zu dem ich gern gehöre und mit dessen Mentalität ich tief verwachsen bin, hat für mich doch keine andersartige Qualität als alle anderen Völker. So weit meine Erfahrung reicht, ist es auch um nichts besser als andere menschliche Gruppierungen, wenn es auch durch Mangel an Macht gegen die schlimmsten Auswüchse gesichert ist. Ansonsten kann ich nichts ‚Auserwähltes‘ an ihm wahrnehmen.“

In einem anderen Brief schreibt er 1954:

„Es war natürlich eine Lüge, was Sie über meine religiösen Überzeugungen gelesen haben, eine Lüge, die systematisch wiederholt wird. Ich glaube nicht an einen persönlichen Gott und ich habe dies niemals geleugnet, sondern habe es deutlich ausgesprochen. Falls es in mir etwas gibt, das man religiös nennen könnte, so ist es eine unbegrenzte Bewunderung der Struktur der Welt, so weit sie unsere Wissenschaft enthüllen kann.“[135]

In einem von insgesamt 27 persönlichen Briefen Einsteins, die im Juni 2015 vom Auktionshaus Profiles in History in Los Angeles versteigert wurden, antwortet Einstein dem Geschichtslehrer Guy Raner im Jahr 1949 auf die Frage nach seinem Glauben, dass er wiederholt gesagt habe, dass die Idee eines persönlichen Gottes seiner Meinung nach eine kindliche ist. Man könne ihn als Agnostiker bezeichnen, aber er teile nicht den kämpferischen Geist des Atheismus, sondern bevorzuge eine demütige Haltung entsprechend der Schwäche unserer intellektuellen Erkenntnis der Natur und unseres eigenen Daseins:

“I have repeatedly said that in my opinion the idea of a personal God is a childlike one, […]. You may call me an agnostic, but I do not share the crusading spirit of the professional atheist … I prefer an attitude of humility corresponding to the weakness of our intellectual understanding of nature and of our own being.”

„Ich habe mehrfach gesagt, dass meiner Meinung nach die Vorstellung eines persönlichen Gottes eine kindliche ist, […]. Sie können mich einen Agnostiker nennen, aber ich teile nicht den Kampfgeist eines professionellen Atheisten … Ich bevorzuge eine demütige Einstellung, was die Schwäche unseres intellektuellen Verständnisses der Natur und unseres Wesens betrifft.“[137]

Die Wissenschaftstheorie (auch Wissenschaftsphilosophie, Wissenschaftslehre oder Wissenschaftslogik[1]) ist ein Teilgebiet der Philosophie, das sich mit den Voraussetzungen, Methoden und Zielen von Wissenschaft und ihrer Form der Erkenntnisgewinnung beschäftigt. Begrifflich wird zwischen der Erkenntnisfähigkeit, dem Erkennen und den Erkenntnissen (den Resultaten des Erkennens) unterschieden, wobei beim allgemeinen Begriff der Erkenntnis anhand des Kontextes entschieden werden muss, was gemeint ist.

Kernfragen der Wissenschaftstheorie lauten:

Welche Charakteristika weist wissenschaftliche Erkenntnis auf und was soll sie leisten? (z. B. abstrakt, mathematisch oder "trocken" zu sein; als Leistungen kommen in Frage: Erklärung, Vorhersage von experimentellen Ergebnissen, Verstehen von Texten)
Durch welche Methoden kann sie erreicht werden? (Methodologie)
Gibt es überhaupt einen wissenschaftlichen Fortschritt?
Was unterscheidet Wissenschaft von der Pseudowissenschaft?
Welchen erkenntnistheoretischen Status haben wissenschaftliche Theorien und die von ihnen postulierten Entitäten? Ist Wissenschaft eine Form von Wahrheitsfindung oder muss wissenschaftliche Erkenntnis pragmatischer konzipiert werden?
Welchen Einfluss haben ästhetische Faktoren auf wissenschaftliche Erkenntnisse und auf die Entwicklung der Wissenschaften?
Wie soll das Verhältnis der Wissenschaft zur Ethik gestaltet sein?
Die Beschäftigung mit wissenschaftstheoretischen Problemen, vor allem solchen, die die Struktur und Entwicklung wissenschaftlicher Kenntnisse und Methoden betreffen, reicht in ihren Anfängen bis in die Antike zurück (Aristoteles). Weiterführende Untersuchungen zu Teilproblemen der Wissenschaftstheorie finden sich bei Philosophen wie Francis Bacon, René Descartes, Gottfried Wilhelm Leibniz, Jean Baptiste le Rond d’Alembert, Denis Diderot, Immanuel Kant, Johann Gottlieb Fichte, Georg Wilhelm Friedrich Hegel, später Bernard Bolzano. Wissenschaft wird in diesen Untersuchungen vorwiegend als System wissenschaftlicher Erkenntnisse verstanden und Wissenschaftstheorie ist in diesem Sinne eng mit Erkenntnistheorie und Methodologie verbunden, also der Reflexion der konkret verwendeten Methoden.

Die allgemeine Wissenschaftstheorie stützt sich auf die formale Logik und die Ergebnisse von Untersuchungen zur Wissenschaft, die aus der Sicht der einzelnen Disziplinen gewonnen werden, z. B. Ökonomie, Soziologie, Psychologie u. a., erarbeitet – davon ausgehend – ihr eigenständiges Begriffssystem, verallgemeinert auf dieser Grundlage die disziplinären Erkenntnisse und versucht so ihrerseits zum einheitlichen theoretischen Fundament aller einzelner Forschungsdisziplinen zu werden.


Inhaltsverzeichnis
1	Realistische Theorien
1.1	Wissenschaftlicher Realismus
1.2	Struktureller Realismus
1.3	Entitätenrealismus
1.4	Raffinierter Falsifikationismus
2	Nicht-Realistische Theorien
2.1	Positivismus
2.2	Konventionalismus
2.3	Instrumentalismus
2.4	Pragmatismus
2.5	Historizismus
2.6	Relativismus
2.7	Sozialkonstruktivismus
2.8	Radikaler Konstruktivismus
2.9	Konstruktiver Empirismus
2.10	Konstruktiver Realismus
3	Gesellschaftskritische Theorien
3.1	Marxistische Wissenschaftstheorie
3.2	Kritische Theorie
4	Methodische Programme
4.1	Logischer Empirismus
4.2	Kritischer Rationalismus
4.3	Analytische Philosophie
4.4	Erlanger oder Methodischer Konstruktivismus
5	Theorie und Evidenz
6	Erklärungsmodelle
7	„Context of discovery“ und „context of justification“
8	Zwei Sichtweisen in Bezug auf Theorie und Modell
9	Modellkonstruktion und Analogien
10	Geschichte der Wissenschaftstheorie
11	Siehe auch
12	Literatur
12.1	Standardwerke
12.2	Einführungen
12.3	Nachschlagewerke und Handbücher
12.4Kritik an Wissenschaftstheorien
12.5	Zeitschriften
13	Weblinks
13.1	Überblicksartikel
13.2	Vorlesungsmaterial
13.3	Wissenschaftliche Zentren und Datenbanken
13.4	Bibliographien
14	Einzelnachweise
Realistische Theorien
→ Hauptartikel: Realismus (Philosophie)
Wissenschaftlicher Realismus
→ Hauptartikel: Wissenschaftlicher Realismus
Hauptvertreter: Ernan McMullin, Stathis Psillos, ihrem Selbstverständnis nach auch Hilary Putnam und Richard Boyd, obwohl Putnams interner Realismus und Boyds Konstruktivismus bezüglich natürlicher Arten etwas von den klassischen Doktrinen abweichen.
Der Wissenschaftliche Realismus lässt sich auf zwei Hauptaussagen bringen:

Die Begriffe einer wissenschaftlichen Theorie beziehen sich auf reale Entitäten, das heißt auf Objekte, die in der Wirklichkeit existieren. (Die Bedeutung von Begriffen wie „Elektron“ besteht in der Bezugnahme auf solche Teilchen in der wirklichen Welt.)
Die Geschichte der Wissenschaften ist als eine Annäherung an die Wahrheit zu verstehen. Wissenschaftliche Arbeiten bestätigen dabei, im Erfolgsfall, die entsprechenden Theorien.
U.a. unter dem Titel "Wissenschaftlicher Realismus" (aber auch: "Kritischer Realismus" oder "Transzendentaler Realismus") firmiert die britische Schule des Realismus um Roy Bhaskar. Zentrale Thesen sind: (1) die These von der erkenntnistheoretischen Sackgasse ("epistemic fallacy"), die darin besteht, sich in der Wissenschaftstheorie primär auf die Erkenntnis zu beziehen anstatt auf das Erkannte und zu Erkennende; (2) eine von der Struktur des Experiments abgeleitete, hermeneutische Begründung der objektiven Realität gesetzmäßiger Zusammenhänge; (3) die These von der Wandelbarkeit gesellschaftlicher Verhältnisse im menschlichen Handeln.[2] Vorläufer dieser Schule sind Mary Hesse[3] und Rom Harre.[4] William Outwaite arbeitete die Konsequenzen des Transzendentalen Realismus für die Sozialwissenschaften heraus und ordnete sie in die Hauptströmungen der Philosophie ein.[5]

Struktureller Realismus
Hauptvertreter: John Worrall
Dem Strukturellen Realismus zufolge ist Wissenschaft nicht in der Lage, den Inhalt der Realität zu erkennen. Wissenschaft beschreibt vielmehr die Struktur der Realität. Nicht auf die in Theorieformulierungen erwähnten Objekte (Elektronen, Äther etc.) kommt es an, sondern die mathematischen Gesetzmäßigkeiten entsprechen (wenn eine Theorie wahr ist) der Ordnung der Natur.

In Structural Realism argumentiert Worrall dafür u. a. so: Die mathematischen Gleichungen, die Fresnel durch Theoretisierungen über den lichttragenden Äther gewann, stehen in Kontinuität zu den maxwellschen Gleichungen, die die Eigenschaften von elektromagnetischen Feldern beschreiben. Der Äther wurde verworfen, aber die Gleichungen gelten heute noch.

Die These des epistemischen strukturellen Realisten lautet: Bezüglich der strukturellen Aussagen unserer Theorien sind wir epistemisch besser gestellt als bezüglich der nicht-strukturellen. Kritiker wenden meist ein, dass diese Unterscheidung nicht trennscharf gezogen werden könne. Eine mögliche Antwort liegt in der Analyse mathematischer theoretischer Strukturen.[6]

Entitätenrealismus
→ Hauptartikel: Entitätsrealismus
Hauptvertreter: Ian Hacking, Nancy Cartwright
Der „Entitätenrealismus“ hält wissenschaftliche Theorien nicht für wahr und lehnt oft sogar die Metapher von Theorien als eindeutigen Abbildungen der Welt ab. Theorien und insbesondere die in ihnen erwähnten Naturgesetze sind in dieser Position lediglich nützliche Hilfsmittel. Dennoch glaubt der Entitätenrealist an viele Entitäten, die in den Wissenschaften postuliert werden, beispielsweise Zellorganellen und Elektronen. Er glaubt allerdings nicht an die Realität aller in der Formulierung einer Theorie erwähnten Entitäten, sondern nur an diejenigen, mit denen man über Experimente kausal interagieren kann. Intervention und Manipulierbarkeit sind aus seiner Sicht geeignete Rechtfertigungen für das Wissen über die Dinge der Welt. Dies drückt sich insbesondere in Ian Hackings berühmtem Zitat über Elektronen aus: „If you can spray them, then they are real.“[7]

Raffinierter Falsifikationismus
Imre Lakatos, der an die Signifikanz der Wissenschaftsgeschichte glaubte, sie jedoch gegen Kuhns Unterstellung eines irrationalen Moments verteidigen wollte, verwarf die Auffassung von Kuhn zugunsten einer Modifikation von Poppers Methode. Die wesentliche Änderung ist die Aufgabe von Poppers Verbot der konventionalistischen Wendung („Immunisierung“) durch Ad-hoc-Hypothesen. Theorien müssen bei ihm nicht durch bessere ersetzt werden, wenn sie falsifiziert, d. h. von experimentellen oder empirischen Resultaten widerlegt werden, sondern dürfen unter gewissen Bedingungen mit einem Schutzgürtel aus Ad-hoc-Hypothesen versehen werden. Dieser muss dazu dienen, bewusste oder auch unbewusste Grundüberzeugungen im Kern der Theorie zu schützen, die ein sogenanntes Forschungsprogramm bilden und den Paradigmen bei Kuhn entsprechen. Nur die über diesen Kern hinausgehenden Zusatzannahmen werden modifiziert. Die Grundüberzeugungen, die den Kern eines Forschungsprogramms ausmachen, können und sollen nach Lakatos erst dann aufgegeben werden, wenn das Forschungsprogramm sich degenerativ entwickelt und durch ein besseres Forschungsprogramm ersetzt werden kann.

Die Sichtweise von Lakatos ist jedoch kein Teil des kritischen Rationalismus geworden, weil die Wissenschaftsgeschichte dort nicht als wesentlich angesehen wird.

Nicht-Realistische Theorien
Positivismus
→ Hauptartikel: Positivismus
Der Positivismus ist eine philosophische Position, welche nur mittels Interpretation naturwissenschaftlicher Beobachtung gegebene Befunde (Basissätze, Protokollsätze) akzeptiert. Dazu müssen die Untersuchungsbedingungen exakt definiert und protokolliert werden. Nur diejenigen Begriffe, die eine Entsprechung in Beobachtungen haben, haben Sinn und Bedeutung; alle übrigen Begriffe seien bedeutungslos. Soweit Theorien auf Beobachtungssprache reduzierbar sind, könnten sie als Interpretationen realer Sachverhalte angesehen werden und wahr oder falsch sein.

Vertreten wurde diese Position besonders im 19. und frühen 20. Jahrhundert von Emil du Bois-Reymond, Ernst Mach und Richard Avenarius und war eine der bedeutendsten Richtungen seiner Zeit, welche die Entwicklung der modernen Naturwissenschaft stark beeinflusste. Albert Einstein erwähnt z. B. die außerordentlich wichtigen Impulse, die er von Machs Philosophie für die Entwicklung seiner Relativitätstheorie erhielt.[8] Trotz dieses großen Einflusses entsprach die Relativitätstheorie letztlich aber nicht den Erwartungen Machs. Nach dem Ersten Weltkrieg wurde die Tradition des Positivismus vom Wiener Kreis und dem Logischen Empirismus aufgegriffen, welche aber wichtige Positionen des ursprünglichen Positivismus aufgaben.

Oft wird auch der Logische Empirismus selbst als Neopositivismus oder Logischer Positivismus bezeichnet, obwohl dies nach Wolfgang Stegmüller eine Fehlbezeichnung ist, sofern man den Begriff „Positivismus“ in seiner ursprünglichen Bedeutung versteht. Zwar sahen die Logischen Empiristen sich selbst durchaus in der Tradition von Ernst Mach, verwendeten aber den Begriff „Positivismus“ in einem viel weiteren Sinn. Die logischen Empiristen bezeichneten alle philosophischen Richtungen als Positivismus, in denen die Bewertung von wissenschaftlichen Theorien maßgeblich (aber nicht ausschließlich) durch Konfrontation mit empirischen Beobachtungen erfolgte.

Konventionalismus
→ Hauptartikel: Konventionalismus
Hauptvertreter: Henri Poincaré, Ernst Mach
Ernst Mach betrachtete wissenschaftliche Theorien als möglichst einfache, neutrale und pragmatische Beschreibungen der Welt. Diese These wird auch als Denkökonomie bezeichnet. Da er jede wissenschaftliche Theorie immer in einem konkreten, empirischen Gesamtzusammenhang sah, lehnte er jeden allgemeinen Wahrheitsanspruch ab. Wissenschaft wird bei Mach so zu einer nützlichen Konvention, die auch psychologische Komponenten berücksichtigen muss.

Siehe auch: Gestalttheorie
Instrumentalismus
Theorien können, dieser Position zufolge, nicht wörtlich genommen werden und auch nicht wahr oder falsch sein. Die in Theorieformulierungen erwähnten Begriffe (die sog. theoretischen Terme) sind lediglich nützliche Hilfsmittel, um die beobachteten oder in Experimenten gefundenen Sachverhalte zu verallgemeinern und zu strukturieren. Dass eine Theorie „Atome“ erwähnt, legt diese daher keinesfalls auf die wirkliche Existenz kleinster Teilchen fest.

Siehe auch: Instrumentalismus (Wissenschaftstheorie)
Pragmatismus
→ Hauptartikel: Pragmatismus
Historizismus
In der historizistischen Wissenschaftstheorie wird die Auffassung vertreten, dass wissenschaftliches Arbeiten nur aufgrund von Festsetzungen möglich ist, die sich vor allem aus den historisch gewordenen Grundpositionen der Erkenntnistheorie, den wissenschaftlichen Traditionen, den historisch gewordenen Persönlichkeiten der Wissenschaft und aus der gesamten historischen Situation erklären lassen. Der Hauptvertreter der historizistischen Wissenschaftstheorie ist Kurt Hübner durch sein grundlegendes Werk Kritik der wissenschaftlichen Vernunft.[9] Der wissenschaftstheoretische Historizismus hat viele Beziehungen zum Konventionalismus, zum Instrumentalismus und vor allem zum Relativismus.

Relativismus
→ Hauptartikel: Relativismus
Als Hauptvertreter des wissenschaftstheoretischen Relativismus gilt Paul Feyerabend. Oft wird auch Thomas S. Kuhn als Relativist bezeichnet, obwohl er selbst diese Bezeichnung immer abgelehnt hat.

Zentral für Feyerabend ist der Inkommensurabilitätsbegriff. Wissenschaftliche Paradigmen könnten vollständig oder teilweise inkommensurabel sein, also unvergleichbar, genauer: es gebe kein gemeinsames Maß, das es erlaubt, Sätze des einen Paradigmas mit solchen eines anderen zu vergleichen. Von Wahrheit könne man deswegen immer nur unter Bezugnahme auf ein bestimmtes Paradigma sprechen.

Sowohl Kuhn als auch Feyerabend waren mit zahlreichen früheren Kritikern einer strengen Trennung zwischen Theorie- und Beobachtungssprache der Meinung, Beobachtungen seien grundsätzlich „theoriegeladen“ ('theory-laden').

Sozialkonstruktivismus
→ Hauptartikel: Sozialkonstruktivismus
Hauptvertreter: David Bloor, Harry Collins, Trevor Pinch, Karin Knorr-Cetina
Sozialkonstruktivisten behaupten, dass auch scheinbar objektive naturwissenschaftliche Tatsachen tatsächlich das Ergebnis von Prozessen der sozialen Konstruktion und abhängig von der sozialen Situation des Labors, der Forschungseinrichtung etc. sind.

Radikaler Konstruktivismus
→ Hauptartikel: Radikaler Konstruktivismus
Hauptvertreter: Ernst von Glasersfeld, Jean Piaget
Die Kernaussage des radikalen Konstruktivismus ist, dass eine Wahrnehmung kein Abbild einer bewusstseinsunabhängigen Realität liefere, sondern dass Realität für jedes Individuum immer eine Konstruktion aus Sinnesreizen und Gedächtnisleistung darstelle. Deshalb sei Objektivität im Sinne einer Übereinstimmung von wahrgenommenem (konstruiertem) Bild und Realität unmöglich; jede Wahrnehmung sei vollständig subjektiv.

Konstruktiver Empirismus
→ Hauptartikel: Konstruktiver Empirismus
Hauptvertreter: Bas van Fraassen
Vertreter des Konstruktiven Empirismus sind agnostisch gegenüber theoretischen Begriffen einer Theorie (Atom, Gen o. ä.). Entscheidend sei nicht, wovon eine Theorie spricht, sondern ob sie sich an den Beobachtungen bestätigt. „Beobachtungen“ kann üblicherweise die Zuhilfenahme von Instrumenten einschließen. Das Ziel von Wissenschaft ist nach dieser Auffassung empirische Adäquatheit.

Konstruktiver Realismus
→ Hauptartikel: Konstruktiver Realismus
Vertreter: Friedrich Wallner
Friedrich Wallner unterscheidet in seiner Ontologie zwischen der Wirklichkeit – dem menschlichen Bewusstsein gegenüberstehend –, der konstruierten Realität mit ihren (sub)disziplinären Mikrowelten und der Lebenswirklichkeit – kulturspezifisch tradierte Systeme von Regeln und Überzeugungen.

Das Ziel ist die Darstellung des Zirkels von Gegenstand und Methode in der Forschung und dessen Berücksichtigung bei der Deutung der Wissenschaft. Wie der Solipsismus ist er sich der Ungewissheit des Gegenstandes bewusst, erkennt aber, dass es einer Vielzahl von Handlungen bedarf, um zu einem inhaltlichen Sinn zu kommen. Als Methode der (Selbst)-Erkenntnis wird die Verfremdung angeboten.

Nach Kurt Greiner bietet die CR-Wissenschaftsphilosophie eine „epistemologische Serviceleistung an die Wissenschaft … und adäquates Handwerkszeug“, das Wissenschaftler, Forscher und Anwender in die Lage versetzen soll, ihre disziplinären Handlungs- und Aktivitätsweisen sinnvoll zu reflektieren. Sie stellt jedoch fest, dass das geschaffene Wissen zwar gangbare „Handlungsmöglichkeiten in Form von Satzsystemen darstellt, die sich durch technische Verwertbarkeit legitimieren …“, aber nicht als objektive Wirklichkeit, sondern als „Weltenkonstruktion… im Erfahrungsrahmen der reziproken Objekt-Methode-Relation“ zu verstehen ist.[10]

Gesellschaftskritische Theorien
Marxistische Wissenschaftstheorie
In der marxistischen Wissenschaftstheorie wird davon ausgegangen, dass Marx und Engels mit dem dialektischen und historischen Materialismus und Lenin mit der dialektisch-materialistischen Widerspiegelungstheorie die philosophisch-theoretischen Grundlagen für die Erforschung der Wissenschaft und ihrer Entwicklung schufen. In der politischen Ökonomie wird das grundlegende Instrument der Wissenschaftstheorie zur Erforschung der produktiven Funktion und der Rolle der Wissenschaft in der materiellen Produktion und im gesellschaftlichen Reproduktionsprozess gesehen. Die so verstandene Wissenschaftstheorie widmet ihre Untersuchungen drei Komponenten der Wissenschaft:

dem wissenschaftlichen Arbeitsprozess[11] (Wesen und Spezifik, soziale Determiniertheit und Arten der wissenschaftlichen Tätigkeit, Bedingungen und Faktoren wissenschaftlichen Schöpfertums, Produktivität und Effektivität der wissenschaftlichen Tätigkeit, Planung, Leitung und rationelle Organisation wissenschaftlicher Arbeitsprozesse u. a.);
dem Wissenschaftspotential als der Gesamtheit der materiellen und ideellen Voraussetzungen wissenschaftlicher Arbeitsprozesse (Komponenten, Struktur und Entwicklung des Wissenschaftspotentials, optimale Proportionen der personellen, finanziellen u. a. Potentialkomponenten usw.);
dem System wissenschaftlicher Erkenntnisse als dem Produkt der wissenschaftlichen Tätigkeit (Klassifikation der Wissenschaften, Gesetzmäßigkeiten der Entstehung und Entwicklung von sowie der Beziehung zwischen einzelnen Wissenschaftsdisziplinen, Begriffs-, Hypothesen- und Theorienbildung in der Wissenschaft, methodisches Vorgehen in der Forschung, relative Eigengesetzlichkeit der Erkenntnisentwicklung u. a.).
Darüber hinaus ergibt sich eine Vielzahl von Problemen, die die Entwicklung der Wissenschaft als Ganzes betreffen: Entwicklungsgesetzmäßigkeiten der Wissenschaft, Triebkräfte der Wissenschaftsentwicklung, Stellung und Funktion der Wissenschaft in konkret-historischen Gesellschaftsordnungen, Verhältnis von Wissenschaft, Technik und Produktion bzw. generell von Wissenschaft und Gesellschaft in Geschichte und Gegenwart, wissenschaftlich-technischer Fortschritt u. a.

Da wissenschaftliche Erkenntnis nur im wissenschaftlichen Arbeitsprozess erzeugt wird und in ihm reproduziert, vermittelt und angewendet wird, ist der Begriff der wissenschaftlichen (allgemeinen) Arbeit (Marx) der für einen logisch konsistenten Aufbau der Wissenschaftstheorie grundlegende Begriff. Er gestattet, sowohl die positivistische Enge der Wissenschaftsauffassung zu überwinden als auch die Determiniertheit der Wissenschaft nach den drei genannten Komponenten im Rahmen konkreter ökonomischer Gesellschaftsordnungen zu begründen. Für die Arbeitsweise der Wissenschaftstheorie ist die Einheit von theoretischer und empirischer sowie von disziplinärer und interdisziplinärer Forschung kennzeichnend.

Kritische Theorie
→ Hauptartikel: Kritische Theorie
Die Kritische Theorie ist eine deutsche Sonderentwicklung der Wissenschaftstheorie im Umfeld der Frankfurter Schule, die der Wissenschaft die Kritik der Gesellschaft als Hauptaufgabe zuweist. Zeitweise war ihr Hauptvertreter Jürgen Habermas mit dem Werk Erkenntnis und Interesse.

Methodische Programme
Logischer Empirismus
→ Hauptartikel: Logischer Empirismus
Der logische Empirismus ist eine der bedeutendsten wissenschaftstheoretischen Richtungen des 20. Jahrhunderts, zu deren Exponenten etwa der Wiener Kreis gehörte, sowie Vertreter der mathematischen Logik (in der Tradition von Bertrand Russell und Gottlob Frege). Führende Vertreter sind u. a. Rudolf Carnap und Otto Neurath. Wichtige Kernpunkte des logischen Empirismus sind das Toleranzprinzip (methodischer Neutralismus) und das Programm der Einheitswissenschaft, in welcher alle empirischen Wissenschaften in einer physikalistischen Sprache formuliert werden sollten.

Der logische Empirismus, in der Form wie sie durch R. Carnap verkörpert wurde, war bis in die 1960er die dominante wissenschaftstheoretische Richtung; besonders im angelsächsischen Raum. Besonders die Kritik von W. Quine an den Grundlagen des logischen Empirismus trug maßgeblich dazu bei, dass diese Dominanz an den methodischen Naturalismus abgegeben wurde. Trotzdem bilden die Resultate des logischen Empirismus bis heute einen wichtigen Unterbau der Wissenschaftstheorie und viele moderne wissenschaftstheoretische Richtungen beziehen sich in ihrem Ausgangspunkt auf eine Analyse der Stärken und Schwächen des Logischen Empirismus.

Kritischer Rationalismus
→ Hauptartikel: Kritischer Rationalismus
Der maßgeblich von Karl Popper entwickelte Kritische Rationalismus beinhaltet eine Wissenschaftstheorie (Falsifikationismus), der zufolge sicheres oder rechtfertigbares Wissen nicht möglich ist und daher auch nicht das Ziel der Wissenschaft sein kann. Stattdessen fasst der Kritische Rationalismus Wissenschaft als methodisches Vorgehen durch Versuch und Irrtum auf, bei dem Theorien mehr oder weniger gut geprüfte Hypothesen sind,[12] die sich beständig durch weitere Überprüfungen bewähren müssen. Der Forscher versucht seine Hypothesen zu verallgemeinern, zu verfeinern und sie durch Experimente in Frage zu stellen, um ihre Schwächen herauszufinden, so dass sie durch neue, verbesserte Hypothesen ersetzt werden können („trial and error“). Im Unterschied zu positivistischen Richtungen geht der Kritische Rationalismus auch bei nachhaltiger Bewährung einer Theorie nicht davon aus, dass dies ein Argument dafür ist, die Theorie für wahr, gesichert oder begründet zu halten. Er ist jedoch der Auffassung, dass durch die ständige Fehlerkorrektur eine Annäherung an die Wahrheit möglich ist und die Wahrheit sogar erreicht werden kann, der Forscher jedoch nicht sicherstellen kann, dass dies der Fall ist. Trotz dieses Eingeständnisses behält der Kritische Rationalismus den absoluten Wahrheitsbegriff der Korrespondenztheorie bei und distanziert sich vom Relativismus.

Analytische Philosophie
→ Hauptartikel: Analytische Philosophie
Die Analytische Philosophie ist anfangs als eine philosophische Richtung aus dem logischen Empirismus hervorgegangen. Die heutige analytische Philosophie zeichnet sich jedoch dadurch aus, dass sie eigentlich keine philosophische Position ist, sondern aus teilweise recht unterschiedlichen Strömungen mit sehr unterschiedlichen Grundvoraussetzungen besteht. Diese haben jedoch methodisch gemeinsam, dass Probleme in einer möglichst klaren exakten Sprache verfasst werden und mit Hilfe formaler Instrumentarien (wie der mathematischen Logik oder z. B. semantischer und formal-ontologischer Hilfsmittel) bearbeitet werden. Dementsprechend gibt es auch sehr unterschiedliche wissenschaftstheoretische Positionen, die von analytischen Philosophen vertreten werden. Die zeitgenössische Wissenschaftstheorie wird in großen Teilen von analytisch geschulten Philosophen betrieben und umfasst ganz unterschiedliche Themenfelder. Dazu gehören etwa Theorien über die Struktur wissenschaftlicher Theorien, über deren ontologische Verpflichtungen, über die Erklärung ihrer Begriffe, über die Natur, Reichweite und Kriterien wissenschaftlicher Erkenntnis usw. Philosophen, die in einem der Punkte gleichartige Positionen verteidigen, können an anderen Punkten gegensätzlicher Auffassung sein. Trotzdem lassen sich teilweise geteilte Gesamtauffassungen und Schulbildungen benennen, deren heutige Ausarbeitung und Modifikation aber oft stark divergiert. Zu derartigen Gesamtbildern über das Wesen der Wissenschaft könnte man etwa den von W. Quine vertretenen Naturalismus zählen oder das Strukturalistische Theorienkonzept, welches u. a. von J.D.Sneed und Wolfgang Stegmüller vertreten wurde.

Erlanger oder Methodischer Konstruktivismus
→ Hauptartikel: Erlanger Konstruktivismus
Hauptvertreter: Paul Lorenzen und Wilhelm Kamlah, sowie Jürgen Mittelstraß, Kuno Lorenz, Peter Janich, Friedrich Kambartel, Christian Thiel und Harald Wohlrapp, einst auch Oswald Schwemmer.
Der wissenschaftskritische Ansatz Erlanger Ursprungs zielt auf die methodisch einwandfreie Re-Konstruktion der Wissenschaftssprache im Allgemeinen und der einzelwissenschaftlichen Terminologien im Besonderen, der Logik in Form einer dialogischen Argumentationslehre, der konstruktiv begründbaren Mathematik im engeren (Arithmetik, Analysis) wie im weiteren Sinn (Wahrscheinlichkeitstheorie, Geometrie und Kinematik), der protophysikalischen Messlehre sowie der ethischen Prinzipien und darauf gründenden politischen Wissenschaft mit dem Ziel einer „Theorie der technischen und politischen Vernunft“. Kern des Erlanger Konstruktivismus ist die allgemein lehr- und lernbare und damit von jedermann nachvollziehbare Konstruktion von Begriffen als Grundelemente aller theoriegestützten Praxis.

Theorie und Evidenz

Dieser Artikel oder Abschnitt bedarf einer Überarbeitung. Näheres sollte auf der Diskussionsseite angegeben sein. Bitte hilf mit, ihn zu verbessern, und entferne anschließend diese Markierung.
Bis in das 16. Jahrhundert dominierte das Aristotelische Wissenschaftskonzept mit seinem induktiv-axiomatisch-deduktiven Aufbau wissenschaftstheoretische Debatten. Mit der Entstehung der experimentellen Naturwissenschaften erhielt die Empirie eine weitere Aufgabe in der Theoriebildung: die Überprüfung. Francis Bacon prägte den Begriff des Experimentum crucis, das nach Karl Popper nicht die Richtigkeit einer Theorie beweisen kann, sondern nur deren Falschheit (Falsifikation).

Diese falsifikationistische Wissenschaftsauffassung wurde anhand zweier Problembereiche herausgefordert: dem Holismus und der „theoriegeladenen Beobachtung“. Die Duhem-Quine-These besagt, dass eine Theorie immer als Ganzes und nicht bloß eine einzelne Aussage der Theorie bestätigt bzw. falsifiziert wird. In der empirischen Überprüfung steht immer ein Komplex aus Theorie, Hilfshypothesen und Randbedingungen zur Debatte. Norwood Russell Hanson und Thomas S. Kuhn waren der Ansicht, Beobachtungen seien grundsätzlich „Theorie-beladen“ ('theory-laden'). Fakten sind in diesem Sinne niemals 'nackt' und eine fundamentalistische Erkenntniskonzeption, nach der sich unser Wissen auf neutrale Beobachtungen zurückführen lässt, daher inadäquat.

Erklärungsmodelle
Das bekannteste Modell für wissenschaftliche Erklärungen ist das Deduktiv-nomologische Erklärungsmodell von Carl Gustav Hempel. Dieses Modell hat viele Kritiker. In jüngerer Zeit hat besonders Nancy Cartwright es als unzutreffend kritisiert und ihm ihr Simulacrum-Erklärungsmodell entgegengesetzt.

Eine weitere aktuell diskutierte Erklärungsart ist der Schluss auf die beste Erklärung (Inference to Best Explanation, kurz IBE), eine Form der Abduktion.

„Context of discovery“ und „context of justification“
Der logische Empirist Hans Reichenbach führte diese Unterscheidung 1938 ein.[13]

Entdeckungszusammenhang: Reichenbach zufolge braucht der Wissenschaftsphilosoph bei der rationalen Rekonstruktion und der Erklärung von Wissenschaft singuläre und subjektive Einflüsse, denen ein Forscher ausgesetzt ist (Entdeckungszusammenhang), nicht zu berücksichtigen.
Begründungszusammenhang: Alles, worauf es ankommt, ist, wie der Wissenschaftler seine Behauptungen – normalerweise in der Form von mathematischen Gleichungen und mittels Logik – rechtfertigt (Rechtfertigungszusammenhang, Begründungszusammenhang, Erklärungszusammenhang).
Karl Popper übernahm diese Trennung unter diesen Bezeichnungen. Da sich der Kritische Rationalismus jedoch gegen Begründung stellte, wird heute das Wort Analysezusammenhang statt Begründungszusammenhang verwendet. Diese Unterscheidung will also zufällige Bedingungen (besonders soziologischer und psychologischer Art) aus wissenschaftlichen (Kausal-)Erklärungen und Begründungen ausschließen.

Dass „zufällige“ Bedingungen in diesem Sinne irrelevant für die Begründung wissenschaftlicher Theorien seien und von „eigentlichen“ Faktoren streng unterscheidbar sind, wurde – ähnlich wie zuvor von Ludwik Fleck[14] – von Thomas Samuel Kuhn angefochten.[15] Jede Rechtfertigung sei vielmehr an ein „Paradigma“ gebunden, das u. a. bestimmte Begriffsschemata und normative Bedingungen einschließt. Bestätigungen einer bestimmten Theorie fänden immer nur innerhalb eines solchen Paradigmas statt, die Evidenz konkurrierender Theorien sei daher, wenn diese einem gravierend andersgearteten Paradigma zugehören, überhaupt erst sichtbar, nachdem man zu jenem Paradigma gleichsam konvertiert werde. Innerhalb welchen Paradigmas man sich befindet, sei damit wesentlich auch zufällig und zunächst selbst nicht nochmals rational gerechtfertigt. Diese Thesen wurden in jüngerer Zeit verstärkt kritisiert von praktisch sämtlichen Anhängern eines wissenschaftlichen Realismus.

Zwei Sichtweisen in Bezug auf Theorie und Modell
Syntaktische Sicht bzw. logiko-linguistische Sicht (assoziiert mit Rudolf Carnap und Richard Bevan Braithwaite)
Theorien sind axiomatisch-deduktive Kalküle bestehend aus Symbolen und Regeln. Bedeutung gewinnen die Terme der Theorie durch Referenz auf Beobachtungen bzw. durch Korrespondenzregeln. Modelle haben lediglich heuristische und pädagogische Funktion (Carnap zufolge). Braithwaite jedoch versteht Modelle als weitere mögliche Interpretationen des Kalküls. Die Syntaktische Sicht hält man in der heutigen Diskussion ebenso wie den Logischen Empirismus, auf dem die syntaktische Sicht beruht, für überholt. (Es ist anzumerken, dass der Term „syntaktische Sicht“ nicht von deren Proponenten benutzt wurde, sondern eine retrospektive Bezeichnung von Vertretern der sogenannten „semantischen Sicht“ ist.)
Semantische Sicht bzw. modell-theoretische Sicht (assoziiert mit Patrick Suppes, der sich auf Alfred Tarski bezieht. Weitere wichtige Vertreter: Frederick Suppe, Bas van Fraassen, Wolfgang Stegmüller, Carlos Ulises Moulines, Ronald Giere)
Theorien werden als Mengen von Modellen definiert. Modelle sind grundsätzlich nicht-linguistische Entitäten und werden als Realisierungen von Theorien entsprechend Modellen in der Modelltheorie der Mathematischen Logik verstanden. Realisierungen sind konkrete Verknüpfungen und Objekte, die von der Theorie abstrakt formuliert werden. Ein Beispiel für das mathematische Vorbild dieser Sichtweise ist die mathematische Gruppentheorie.
Dem Wechsel zur semantischen, modellorientierten Sicht entspricht häufig ein Fokus auf deren Hauptproblemfeld der Repräsentation.

Modellkonstruktion und Analogien
Modelle werden oft durch einen Analogieschluss mit anderen Systemen konstruiert. Mary Hesse unterscheidet positive, negative und neutrale Analogien. Aspekte zwischen Modell und System sind ähnlich (positiv), verschieden (negativ), oder nicht determinierbar (neutral). Neutrale Analogien motivieren weitere Untersuchungen der Eigenschaften des realen Systems, das durch das Modell repräsentiert werden soll.

Geschichte der Wissenschaftstheorie
Herkömmliche Bezeichnungen der Disziplin sind auch „Wissenschaftslogik“, „Wissenschaftslehre“ und „Methodologie“.

Die Beschäftigung mit der Frage der richtigen und exakten Erkenntnisgewinnung ist eine der zentralen Fragen der Philosophie und wird seit Jahrtausenden von den größten Denkern der Menschheit bearbeitet. Vorläufer der heutigen Wissenschaftstheorie sind v. a. einzelne Fachwissenschaftler des 19. und 20. Jahrhunderts, die sich jeweils mit grundlegenden methodischen Fragen der Wissensgewinnung unter Blickwinkel ihres Faches auseinandersetzten. Man verwendete damals den Begriff „Induktive Philosophie“ dafür. Ein erster Lehrstuhl wurde 1870 an der Universität Zürich eingerichtet, der jedoch ohne größeren Einfluss blieb. Erst als Ernst Mach 1895 auf die Professur für „Geschichte und Theorie der induktiven Wissenschaften“ an der Universität Wien berufen wurde, gewann das Fach an Bedeutung. Von der „Wissenschaftstheorie“ als eigenständigem Begriff kann man erst ab den 1920er Jahren reden. Damals gründete sich der Wiener Kreis, der Ausgangspunkt des Neopositivismus. Viele Themen und Positionen die in diesem Kreis geäußert wurden, bestimmen auch heute noch einen Teil der fachinternen Diskussion der Wissenschaftstheorie. Zwar mit dem Wiener Kreis in Austausch stehend, dessen Ansichten aber größtenteils ablehnend, entwickelte Karl Popper seine falsifikationistische Herangehensweise des Kritischen Rationalismus, die er erstmals 1935 in Logik der Forschung präsentierte.

Den abstrakten Betrachtungen über das 'Wesen' der Wissenschaft setzte Ludwik Fleck ebenfalls 1935 eine Analyse der sozialen Konstruktion von Wissenschaft anhand einer Fallstudie entgegen. Sein Buch Entstehung und Entwicklung einer wissenschaftlichen Tatsache wurde jedoch lange Zeit wenig beachtet. Eine Wende zu einer stärker historisch ausgerichteten Diskussion brachte erst Die Struktur wissenschaftlicher Revolutionen (Original 1962) von Thomas S. Kuhn. Einen Generalangriff auf Grundannahmen des logischen Positivismus unternahm Paul Feyerabend mit Against Method.

In Frankreich gibt es keine strikte Trennung zwischen Wissenschaftstheorie und Wissenschaftsgeschichte. Die französische Tradition der historischen Epistemologie (Épistémologie) geht auf Gaston Bachelard und Georges Canguilhem zurück.

Paul Hoyningen-Huene gliedert die Geschichte der Wissenschaftstheorie – verstanden als die Antworten auf die Frage, was Wissenschaft ist –, schematisch in vier Phasen:[16]

Antike (Plato, Aristoteles) bis Beginn 17. Jahrhundert: Wissenschaft wird verstanden als absolut sicheres Wissen. Die Sicherheit des wissenschaftlichen Wissens wird durch seine Ableitung (Deduktion) aus evidenten Axiomen (deren Wahrheit aus ihnen selbst "herausleuchtet") etabliert.
17. Jhdt. bis Mitte/Ende 19. Jhdt.: Diese zweite Phase stimmt mit der ersten hinsichtlich der verlangten absoluten Sicherheit des wissenschaftlichen Wissens überein, jedoch werden zu dessen Etablierung nicht mehr nur deduktive Schlüsse, sondern allgemeiner "die wissenschaftliche Methode" zugelassen, was insbesondere induktive Verfahren umfasst. Die wissenschaftliche Methode (oder "wissenschaftliche Methoden") werden als strikt zu befolgende Regeln verstanden.
Ende 19. Jhdt. bis spätes 20. Jhdt.: Diese dritte Phase stimmt mit der zweiten hinsichtlich der Verwendung der wissenschaftliche(n) Methode(n) zur Gewinnung wissenschaftlichen Wissens überein, gibt aber die Forderung nach absoluter Sicherheit des Wissens auf. Wissenschaftliches Wissen wird jetzt als "fallibel", d. h. als nicht endgültig und daher prinzipiell revidierbar angesehen.
Spätes 20. Jhdt. bis heute: Der Glaube an die Existenz einer wissenschaftlichen Methode als ein für die wissenschaftliche Arbeit strikt bindendes Regelwerk erodiert. Damit verschwindet neben der absoluten Sicherheit des Wissens nun auch das zweite konstitutive Merkmal wissenschaftlichen Wissens. Das verleiht der allgemeinen Frage, was das wissenschaftliche Wissen im Kontrast zu anderen Wissensarten eigentlich auszeichnet, erneute Aktualität.
Carlos Ulises Moulines unterteilt die Entwicklung der Wissenschaftstheorie seit 1885 in fünf Phasen:[17]

Aufkeimen (ca. 1885 bis zum Ersten Weltkrieg)
Entfaltung (1918 bis 1935)
klassische Phase (ca. 1935 bis 1970)
historizistische Phase (ca. 1960 bis 1985)
modellistische Phase (ab den 1970er Jahren)
Siehe auch
Stammbaum der Wissenschaften und Sieben Freie Künste, Geschichte der Wissenschaft.
Wissenschaftsforschung, Wissenschaftssoziologie, Wissenschaftssprache und Szientometrie, wissenschaftliche Beschäftigung mit der Wissenschaft
Parawissenschaft und Pseudowissenschaft, bestimmte Arten und Auffassungen von „Wissenschaft“ und „Wissenschaftlichkeit“
Gesellschaft für Wissenschaftsphilosophie
Korrespondenzprinzip
Feministische Wissenschaftstheorie
Politische Theorie, Wissenschaftstheorie der Politikwissenschaft
Wissenschaftstheorie der Theologie
Künstlerische Forschung
Bayesianische Erkenntnistheorie
Empirische Evidenz
Literatur
Standardwerke
Rudolf Carnap: Einführung in die Philosophie der Naturwissenschaft. Nymphenburger, München 1989. [1966]
Rudolf Carnap, Hans Hahn, Otto Neurath: Wissenschaftliche Weltauffassung – Der Wiener Kreis. Artur Wolf, Wien 1979. [1929]. Abgedruckt in Rainer Hegselmann (Hrsg.): Otto Neurath: Wissenschaftliche Weltauffassung, Sozialismus und Logischer Empirismus. Suhrkamp, Frankfurt 1979, S. 81–101.
Wolfgang Deppert: Theorie der Wissenschaft. Band 1–4, Springer VS, Wiesbaden 2019, ISBN 978-3-658-14023-6 (Band 1), ISBN 978-3-658-14042-7 (Band 2), ISBN 978-3-658-15119-5 (Band 3), ISBN 978-3-658-15123-2 (Band 4)
Pierre Duhem: Ziel und Struktur der physikalischen Theorien. Meiner, Hamburg 1978 [1906].
Paul Feyerabend: Wider den Methodenzwang. 7. Auflage. Suhrkamp, Frankfurt am Main 1999, ISBN 3-518-28197-6.
Ludwik Fleck: Entstehung und Entwicklung einer wissenschaftlichen Tatsache. 1935. Hrsg. von L. Schäfer, Th. Schnelle, Suhrkamp, 1980, ISBN 3-518-27912-2.
Bas van Fraassen: The Scientific Image. Clarendon Press, Oxford 1980, ISBN 0-19-824424-X.
Carl Gustav Hempel: Philosophy of natural science. Prentice-Hall, Englewood Cliffs, N.J. 1966. (dt.: Philosophie der Naturwissenschaften. Deutscher Taschenbuch-Verlag, München 1974)
Paul Hoyningen-Huene: Systematicity: The Nature of Science. (= Oxford studies in philosophy of science). 2. Auflage. Oxford University Press, New York 2015.
Kurt Hübner: Kritik der wissenschaftlichen Vernunft. 1. Auflage. Alber Verlag, Freiburg/ München 1978, ISBN 3-495-47384-X. (3. Aufl. 2002, ISBN 3-495-48077-3)
Thomas S. Kuhn: Die Struktur wissenschaftlicher Revolutionen, 2., rev. und um das Postskriptum von 1969 erg. Auflage. Suhrkamp, Frankfurt am Main 1997, ISBN 3-518-27625-5.
Imre Lakatos: The Methodology of Scientific Research Programmes. (= Philosophical Papers. Volume 1). Cambridge University Press, Cambridge 1977, ISBN 0-521-28031-1.
Karl R. Popper: Logik der Forschung. Hrsg. von Herbert Keuth. 11., durchges. u. erg. Auflage. Mohr Siebeck, Tübingen 2005, ISBN 3-16-148111-9.
Gerhard Schurz: Philosophy of Science: A Unified Approach. Routledge, New York 2014. ISBN 978-0-415-82936-6.
Wolfgang Stegmüller: Aufsätze zur Wissenschaftstheorie. Wiss. Buchges., Darmstadt 1990, ISBN 3-534-05565-9.
Wolfgang Stegmüller: Probleme und Resultate der Wissenschaftstheorie und Analytischen Philosophie Band 1–4. Springer Verlag. 1969–1985.
Einführungen
Wolfgang Balzer: Die Wissenschaft und ihre Methoden. Grundsätze der Wissenschaftstheorie. Ein Lehrbuch. 2. Auflage. Alber, Freiburg/ München 2002, ISBN 3-495-47853-1.
Alexander Bird: Philosophy of science. (= Fundamentals of philosophy). UCL Pr., London 1998, ISBN 1-85728-681-2.
Martin Carrier: Wissenschaftstheorie zur Einführung. 3. Auflage. Junius, Hamburg 2011, ISBN 978-3-88506-653-8.
Alan F. Chalmers: Wege der Wissenschaft: Einführung in die Wissenschaftstheorie. 6. Auflage. Springer, Berlin u. a. 2007, ISBN 978-3-540-49490-4.
Peter Godfrey-Smith: Theory and reality: an introduction to the philosophy of science. University of Chicago Press, Chicago 2003, ISBN 0-226-30063-3.
Hartmut Kliemt: Grundzüge der Wissenschaftstheorie – Eine Einführung für Mediziner und Therapeuten, Gustav Fischer Verlag, Stuttgart, New York 1986, ISBN 3-437-11098-5.
Stephan Kornmesser, Wilhelm Büttemeyer: Wissenschaftstheorie. Eine Einführung. Metzler, Stuttgart 2020; ISBN 978-3-476-04742-7.
James Ladyman: Understanding philosophy of science. Routledge, London 2002, ISBN 0-415-22157-9.
Karel Lambert, Gordon G. Britten jr.: Eine Einführung in die Wissenschaftsphilosophie. Aus dem Amerikanischen übersetzt von Joachim Schulte. Berlin/ New York 1991.
B. Lauth, J. Sareiter: Wissenschaftliche Erkenntnis: Eine ideengeschichtliche Einführung in die Wissenschaftstheorie. 2. Auflage. Mentis 2005, ISBN 3-89785-555-0.
Klaus Niedermair: Eine kleine Einführung in Wissenschaftstheorie und Methodologie: für Sozial- und Erziehungswissenschaftler/innen. Studia Universitätsverlag, Innsbruck 2010, ISBN 978-3-902652-18-8.
Samir Okasha: Philosophy of Science: A Very Short Introduction. Oxford University Press, Oxford 2002, ISBN 0-19-280283-6.
David Papineau: The philosophy of science. Oxford University Press, Oxford u. a. 1996, ISBN 0-19-875165-6.
Hans Poser: Wissenschaftstheorie: Eine philosophische Einführung. Reclam, Stuttgart 2001, ISBN 3-15-018125-9.
Alex Rosenberg: Philosophy of science: a contemporary introduction. (= Routledge contemporary introductions to philosophy). 2. Auflage. Routledge, New York 2005.
Johann August Schülein, Simon Reitze: Wissenschaftstheorie für Einsteiger. 4. Auflage. UTB, Wien 2016, ISBN 978-3-8252-2351-9.
Gerhard Schurz: Einführung in die Wissenschaftstheorie. Wissenschaftliche Buchgesellschaft, Darmstadt 2006.
Helmut Seiffert: Einführung in die Wissenschaftstheorie. 11. Auflage. Beck, München 1991, ISBN 3-406-34622-7.
Harald A. Wiltsche: Einführung in die Wissenschaftstheorie. Vandenhoeck & Ruprecht, Göttingen 2013, ISBN 978-3-8252-3936-7.
Nachschlagewerke und Handbücher
Jürgen Mittelstraß u. a. (Hrsg.): Enzyklopädie Philosophie und Wissenschaftstheorie (1980–1996), Bände 1–4, Metzler, Stuttgart 1995. (Sonderausgabe 2004, 2., neubearb. und wesentlich erg. Aufl. 2005)
Helmut Seiffert, Gerard Radnitzky (Hrsg.): Handlexikon zur Wissenschaftstheorie. 2., unv. Auflage. dtv, Berlin 1992, ISBN 3-423-04586-8.
Andreas Bartels, Manfred Stöckler (Hrsg.): Wissenschaftstheorie. Ein Studienbuch. mentis, Paderborn 2007.
Dominique Lecourt (Hrsg.): Dictionnaire d'histoire et philosophie des sciences. P.U.F., Paris 1999. (als TB 2006, ISBN 2-13-054499-1)
R. Boyd, P. Gasper, J. D. Trout (Hrsg.): The Philosophy of Science. MIT Press, Cambridge 1991.
Martin Curd, J. A. Cover (Hrsg.): Philosophy of science: the central issues. Norton, New York/ London 1998, ISBN 0-393-97175-9.
Marc Lange (Hrsg.): Philosophy of science: an anthology. (= Blackwell philosophy anthologies. 25). Blackwell, Malden, Mass. 2007.
Peter Machamer (Hrsg.): The Blackwell guide to the philosophy of science. (= Blackwell philosophy guides. 7). Blackwell, Malden, Mass. 2002, ISBN 0-631-22108-5.
W. H. Newton-Smith (Hrsg.): A companion to the philosophy of science. (= Blackwell companions to philosophy. 18). Blackwell, Malden, Mass. 2000, ISBN 0-631-17024-3.
Kritik an Wissenschaftstheorien
Geoffroy de Lagasnerie: Denken in einer schlechten Welt. Übers. Felix Kurz. Matthes & Seitz, Berlin 2018, ISBN 978-3-95757-527-2.
Zeitschriften
British Journal for the Philosophy of Science
Erkenntnis – An International Journal for Analytical Philosophy
International Studies in the Philosophy of Science
Journal for General Philosophy of Science
Perspectives on Science
Philosophy of Science
Semina Scientiarum
Studies in History and Philosophy of Science
Synthese
Siehe auch: Philosophiebibliographie: Wissenschaftstheorie – Zusätzliche Literaturhinweise zum Thema